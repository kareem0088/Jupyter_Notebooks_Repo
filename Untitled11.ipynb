{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6e7b5e-c367-4ec6-bba2-6e972c0c0672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Time      Open      High       Low     Close    Volume  \\\n",
      "0 2021-08-03 00:00:00.179  0.857201  0.857143  0.856793  0.856793  0.090748   \n",
      "1 2021-08-03 00:00:00.704  0.857201  0.857551  0.857609  0.857609  0.053222   \n",
      "2 2021-08-03 00:00:03.581  0.858017  0.858776  0.858425  0.859241  0.068917   \n",
      "3 2021-08-03 00:00:05.006  0.858425  0.859184  0.858833  0.859649  0.054284   \n",
      "4 2021-08-03 00:00:11.714  0.859241  0.859184  0.858833  0.858833  0.137951   \n",
      "\n",
      "   EMA_10  EMA_20  RSI_10  ATR_10  Target_Price  Signal  seconds_since_start  \\\n",
      "0     NaN     NaN     NaN     NaN           NaN       0                0.000   \n",
      "1     NaN     NaN     NaN     NaN           NaN       0                0.525   \n",
      "2     NaN     NaN     NaN     NaN           NaN       0                3.402   \n",
      "3     NaN     NaN     NaN     NaN           NaN       0                4.827   \n",
      "4     NaN     NaN     NaN     NaN           NaN       0               11.535   \n",
      "\n",
      "   normalized_time  \n",
      "0     0.000000e+00  \n",
      "1     1.736138e-07  \n",
      "2     1.125017e-06  \n",
      "3     1.596255e-06  \n",
      "4     3.814542e-06  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# قراءة ملف CSV\n",
    "file_path = r'C:\\Users\\Access\\Downloads\\nor\\train\\train.csv'  # استبدل 'your_file.csv' باسم ملفك\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# تحويل عمود 'Time' إلى طابع زمني كامل (بما في ذلك التاريخ والوقت)\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%d.%m.%Y %H:%M:%S.%f')\n",
    "\n",
    "# حساب الفرق الزمني من أول قيمة\n",
    "df['seconds_since_start'] = (df['Time'] - df['Time'].min()).dt.total_seconds()\n",
    "\n",
    "# تطبيق النورمليزيشن\n",
    "scaler = MinMaxScaler()\n",
    "df['normalized_time'] = scaler.fit_transform(df[['seconds_since_start']])\n",
    "\n",
    "# حفظ الملف المعدل\n",
    "df.to_csv(r'C:\\Users\\Access\\Downloads\\nor\\train\\train1.csv', index=False)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f37ceb2-4ef4-4b12-b14c-0d685a29af81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>ATR_10</th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Signal</th>\n",
       "      <th>seconds_since_start</th>\n",
       "      <th>normalized_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-08-03 00:00:00.179</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.090748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-03 00:00:00.704</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857551</td>\n",
       "      <td>0.857609</td>\n",
       "      <td>0.857609</td>\n",
       "      <td>0.053222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>1.736138e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-03 00:00:03.581</td>\n",
       "      <td>0.858017</td>\n",
       "      <td>0.858776</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.402</td>\n",
       "      <td>1.125017e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-03 00:00:05.006</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.054284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4.827</td>\n",
       "      <td>1.596255e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-08-03 00:00:11.714</td>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.137951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11.535</td>\n",
       "      <td>3.814542e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340289</th>\n",
       "      <td>2021-09-06 23:58:44.989</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.856735</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.042365</td>\n",
       "      <td>0.857822</td>\n",
       "      <td>0.857365</td>\n",
       "      <td>0.500293</td>\n",
       "      <td>0.059947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3023924.810</td>\n",
       "      <td>9.999904e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340290</th>\n",
       "      <td>2021-09-06 23:58:52.835</td>\n",
       "      <td>0.855161</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>0.857463</td>\n",
       "      <td>0.857260</td>\n",
       "      <td>0.396903</td>\n",
       "      <td>0.064466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3023932.656</td>\n",
       "      <td>9.999930e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340291</th>\n",
       "      <td>2021-09-06 23:58:54.129</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.855569</td>\n",
       "      <td>0.052514</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.857243</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.064783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3023933.950</td>\n",
       "      <td>9.999935e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340292</th>\n",
       "      <td>2021-09-06 23:58:58.415</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.855161</td>\n",
       "      <td>0.855569</td>\n",
       "      <td>0.056880</td>\n",
       "      <td>0.857199</td>\n",
       "      <td>0.857228</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.061318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3023938.236</td>\n",
       "      <td>9.999949e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340293</th>\n",
       "      <td>2021-09-06 23:59:13.928</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.854694</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.088388</td>\n",
       "      <td>0.856878</td>\n",
       "      <td>0.857098</td>\n",
       "      <td>0.381124</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3023953.749</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340294 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Time      Open      High       Low     Close  \\\n",
       "0      2021-08-03 00:00:00.179  0.857201  0.857143  0.856793  0.856793   \n",
       "1      2021-08-03 00:00:00.704  0.857201  0.857551  0.857609  0.857609   \n",
       "2      2021-08-03 00:00:03.581  0.858017  0.858776  0.858425  0.859241   \n",
       "3      2021-08-03 00:00:05.006  0.858425  0.859184  0.858833  0.859649   \n",
       "4      2021-08-03 00:00:11.714  0.859241  0.859184  0.858833  0.858833   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "340289 2021-09-06 23:58:44.989  0.856793  0.856735  0.855977  0.855977   \n",
       "340290 2021-09-06 23:58:52.835  0.855161  0.855102  0.854753  0.854753   \n",
       "340291 2021-09-06 23:58:54.129  0.854345  0.855102  0.854753  0.855569   \n",
       "340292 2021-09-06 23:58:58.415  0.854753  0.855102  0.855161  0.855569   \n",
       "340293 2021-09-06 23:59:13.928  0.854753  0.854694  0.854345  0.854345   \n",
       "\n",
       "          Volume    EMA_10    EMA_20    RSI_10    ATR_10  Target_Price  \\\n",
       "0       0.090748       NaN       NaN       NaN       NaN           NaN   \n",
       "1       0.053222       NaN       NaN       NaN       NaN           NaN   \n",
       "2       0.068917       NaN       NaN       NaN       NaN           NaN   \n",
       "3       0.054284       NaN       NaN       NaN       NaN           NaN   \n",
       "4       0.137951       NaN       NaN       NaN       NaN           NaN   \n",
       "...          ...       ...       ...       ...       ...           ...   \n",
       "340289  0.042365  0.857822  0.857365  0.500293  0.059947           NaN   \n",
       "340290  0.081072  0.857463  0.857260  0.396903  0.064466           NaN   \n",
       "340291  0.052514  0.857318  0.857243  0.476291  0.064783           NaN   \n",
       "340292  0.056880  0.857199  0.857228  0.476291  0.061318           NaN   \n",
       "340293  0.088388  0.856878  0.857098  0.381124  0.065700           NaN   \n",
       "\n",
       "        Signal  seconds_since_start  normalized_time  \n",
       "0            0                0.000     0.000000e+00  \n",
       "1            0                0.525     1.736138e-07  \n",
       "2            0                3.402     1.125017e-06  \n",
       "3            0                4.827     1.596255e-06  \n",
       "4            0               11.535     3.814542e-06  \n",
       "...        ...                  ...              ...  \n",
       "340289       0          3023924.810     9.999904e-01  \n",
       "340290       0          3023932.656     9.999930e-01  \n",
       "340291       0          3023933.950     9.999935e-01  \n",
       "340292       0          3023938.236     9.999949e-01  \n",
       "340293       0          3023953.749     1.000000e+00  \n",
       "\n",
       "[340294 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55db4c27-63cf-441e-8eb4-be04e2e8d0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>ATR_10</th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.090748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.736138e-07</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857551</td>\n",
       "      <td>0.857609</td>\n",
       "      <td>0.857609</td>\n",
       "      <td>0.053222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.125017e-06</td>\n",
       "      <td>3.402</td>\n",
       "      <td>0.858017</td>\n",
       "      <td>0.858776</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.596255e-06</td>\n",
       "      <td>4.827</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.054284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.814542e-06</td>\n",
       "      <td>11.535</td>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.137951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340289</th>\n",
       "      <td>9.999904e-01</td>\n",
       "      <td>3023924.810</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.856735</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.042365</td>\n",
       "      <td>0.857822</td>\n",
       "      <td>0.857365</td>\n",
       "      <td>0.500293</td>\n",
       "      <td>0.059947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340290</th>\n",
       "      <td>9.999930e-01</td>\n",
       "      <td>3023932.656</td>\n",
       "      <td>0.855161</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>0.857463</td>\n",
       "      <td>0.857260</td>\n",
       "      <td>0.396903</td>\n",
       "      <td>0.064466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340291</th>\n",
       "      <td>9.999935e-01</td>\n",
       "      <td>3023933.950</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.855569</td>\n",
       "      <td>0.052514</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.857243</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.064783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340292</th>\n",
       "      <td>9.999949e-01</td>\n",
       "      <td>3023938.236</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.855161</td>\n",
       "      <td>0.855569</td>\n",
       "      <td>0.056880</td>\n",
       "      <td>0.857199</td>\n",
       "      <td>0.857228</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.061318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340293</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3023953.749</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.854694</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.088388</td>\n",
       "      <td>0.856878</td>\n",
       "      <td>0.857098</td>\n",
       "      <td>0.381124</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340294 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date         Time      Open      High       Low     Close  \\\n",
       "0       0.000000e+00        0.000  0.857201  0.857143  0.856793  0.856793   \n",
       "1       1.736138e-07        0.525  0.857201  0.857551  0.857609  0.857609   \n",
       "2       1.125017e-06        3.402  0.858017  0.858776  0.858425  0.859241   \n",
       "3       1.596255e-06        4.827  0.858425  0.859184  0.858833  0.859649   \n",
       "4       3.814542e-06       11.535  0.859241  0.859184  0.858833  0.858833   \n",
       "...              ...          ...       ...       ...       ...       ...   \n",
       "340289  9.999904e-01  3023924.810  0.856793  0.856735  0.855977  0.855977   \n",
       "340290  9.999930e-01  3023932.656  0.855161  0.855102  0.854753  0.854753   \n",
       "340291  9.999935e-01  3023933.950  0.854345  0.855102  0.854753  0.855569   \n",
       "340292  9.999949e-01  3023938.236  0.854753  0.855102  0.855161  0.855569   \n",
       "340293  1.000000e+00  3023953.749  0.854753  0.854694  0.854345  0.854345   \n",
       "\n",
       "          Volume    EMA_10    EMA_20    RSI_10    ATR_10  Target_Price  Signal  \n",
       "0       0.090748       NaN       NaN       NaN       NaN           NaN       0  \n",
       "1       0.053222       NaN       NaN       NaN       NaN           NaN       0  \n",
       "2       0.068917       NaN       NaN       NaN       NaN           NaN       0  \n",
       "3       0.054284       NaN       NaN       NaN       NaN           NaN       0  \n",
       "4       0.137951       NaN       NaN       NaN       NaN           NaN       0  \n",
       "...          ...       ...       ...       ...       ...           ...     ...  \n",
       "340289  0.042365  0.857822  0.857365  0.500293  0.059947           NaN       0  \n",
       "340290  0.081072  0.857463  0.857260  0.396903  0.064466           NaN       0  \n",
       "340291  0.052514  0.857318  0.857243  0.476291  0.064783           NaN       0  \n",
       "340292  0.056880  0.857199  0.857228  0.476291  0.061318           NaN       0  \n",
       "340293  0.088388  0.856878  0.857098  0.381124  0.065700           NaN       0  \n",
       "\n",
       "[340294 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# حذف عمود 'Time'\n",
    "df.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "# إعادة تسمية 'normalized_time' إلى 'time'\n",
    "df.rename(columns={'normalized_time': 'Date'}, inplace=True)\n",
    "df.rename(columns={'seconds_since_start': 'Time'}, inplace=True)\n",
    "\n",
    "# ترتيب الأعمدة: أولاً 'time' ثم 'seconds_since_start'\n",
    "df = df[['Date', 'Time','Open','High','Low','Close','Volume','EMA_10','EMA_20','RSI_10','ATR_10','Target_Price','Signal']]\n",
    "\n",
    "# حفظ الملف المعدل\n",
    "df.to_csv(r'C:\\Users\\Access\\Downloads\\nor\\train\\train1.csv', index=False)\n",
    "\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14ee49dd-3960-426f-b6d2-4e500dc106aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>ATR_10</th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.090748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.736138e-07</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857551</td>\n",
       "      <td>0.857609</td>\n",
       "      <td>0.857609</td>\n",
       "      <td>0.053222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.125017e-06</td>\n",
       "      <td>3.402</td>\n",
       "      <td>0.858017</td>\n",
       "      <td>0.858776</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.596255e-06</td>\n",
       "      <td>4.827</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.054284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.814542e-06</td>\n",
       "      <td>11.535</td>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.137951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340289</th>\n",
       "      <td>9.999904e-01</td>\n",
       "      <td>3023924.810</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.856735</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.042365</td>\n",
       "      <td>0.857822</td>\n",
       "      <td>0.857365</td>\n",
       "      <td>0.500293</td>\n",
       "      <td>0.059947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340290</th>\n",
       "      <td>9.999930e-01</td>\n",
       "      <td>3023932.656</td>\n",
       "      <td>0.855161</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>0.857463</td>\n",
       "      <td>0.857260</td>\n",
       "      <td>0.396903</td>\n",
       "      <td>0.064466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340291</th>\n",
       "      <td>9.999935e-01</td>\n",
       "      <td>3023933.950</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.855569</td>\n",
       "      <td>0.052514</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.857243</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.064783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340292</th>\n",
       "      <td>9.999949e-01</td>\n",
       "      <td>3023938.236</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.855161</td>\n",
       "      <td>0.855569</td>\n",
       "      <td>0.056880</td>\n",
       "      <td>0.857199</td>\n",
       "      <td>0.857228</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.061318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340293</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3023953.749</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.854694</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.088388</td>\n",
       "      <td>0.856878</td>\n",
       "      <td>0.857098</td>\n",
       "      <td>0.381124</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340294 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date         Time      Open      High       Low     Close  \\\n",
       "0       0.000000e+00        0.000  0.857201  0.857143  0.856793  0.856793   \n",
       "1       1.736138e-07        0.525  0.857201  0.857551  0.857609  0.857609   \n",
       "2       1.125017e-06        3.402  0.858017  0.858776  0.858425  0.859241   \n",
       "3       1.596255e-06        4.827  0.858425  0.859184  0.858833  0.859649   \n",
       "4       3.814542e-06       11.535  0.859241  0.859184  0.858833  0.858833   \n",
       "...              ...          ...       ...       ...       ...       ...   \n",
       "340289  9.999904e-01  3023924.810  0.856793  0.856735  0.855977  0.855977   \n",
       "340290  9.999930e-01  3023932.656  0.855161  0.855102  0.854753  0.854753   \n",
       "340291  9.999935e-01  3023933.950  0.854345  0.855102  0.854753  0.855569   \n",
       "340292  9.999949e-01  3023938.236  0.854753  0.855102  0.855161  0.855569   \n",
       "340293  1.000000e+00  3023953.749  0.854753  0.854694  0.854345  0.854345   \n",
       "\n",
       "          Volume    EMA_10    EMA_20    RSI_10    ATR_10  Target_Price  Signal  \n",
       "0       0.090748       NaN       NaN       NaN       NaN           NaN       0  \n",
       "1       0.053222       NaN       NaN       NaN       NaN           NaN       0  \n",
       "2       0.068917       NaN       NaN       NaN       NaN           NaN       0  \n",
       "3       0.054284       NaN       NaN       NaN       NaN           NaN       0  \n",
       "4       0.137951       NaN       NaN       NaN       NaN           NaN       0  \n",
       "...          ...       ...       ...       ...       ...           ...     ...  \n",
       "340289  0.042365  0.857822  0.857365  0.500293  0.059947           NaN       0  \n",
       "340290  0.081072  0.857463  0.857260  0.396903  0.064466           NaN       0  \n",
       "340291  0.052514  0.857318  0.857243  0.476291  0.064783           NaN       0  \n",
       "340292  0.056880  0.857199  0.857228  0.476291  0.061318           NaN       0  \n",
       "340293  0.088388  0.856878  0.857098  0.381124  0.065700           NaN       0  \n",
       "\n",
       "[340294 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d6ef094-35b1-4d32-8130-04c3b03be4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\Access\\Downloads\\nor\\train\\last_train.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "495be0f2-a642-46fd-a4d1-498dfa5fa5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>ATR_10</th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.090748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.736138e-07</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857551</td>\n",
       "      <td>0.857609</td>\n",
       "      <td>0.857609</td>\n",
       "      <td>0.053222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.125017e-06</td>\n",
       "      <td>3.402</td>\n",
       "      <td>0.858017</td>\n",
       "      <td>0.858776</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.596255e-06</td>\n",
       "      <td>4.827</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.054284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.814542e-06</td>\n",
       "      <td>11.535</td>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.137951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340289</th>\n",
       "      <td>9.999904e-01</td>\n",
       "      <td>3023924.810</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.856735</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.042365</td>\n",
       "      <td>0.857822</td>\n",
       "      <td>0.857365</td>\n",
       "      <td>0.500293</td>\n",
       "      <td>0.059947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340290</th>\n",
       "      <td>9.999930e-01</td>\n",
       "      <td>3023932.656</td>\n",
       "      <td>0.855161</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>0.857463</td>\n",
       "      <td>0.857260</td>\n",
       "      <td>0.396903</td>\n",
       "      <td>0.064466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340291</th>\n",
       "      <td>9.999935e-01</td>\n",
       "      <td>3023933.950</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.855569</td>\n",
       "      <td>0.052514</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.857243</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.064783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340292</th>\n",
       "      <td>9.999949e-01</td>\n",
       "      <td>3023938.236</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.855161</td>\n",
       "      <td>0.855569</td>\n",
       "      <td>0.056880</td>\n",
       "      <td>0.857199</td>\n",
       "      <td>0.857228</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.061318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340293</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3023953.749</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.854694</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.088388</td>\n",
       "      <td>0.856878</td>\n",
       "      <td>0.857098</td>\n",
       "      <td>0.381124</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340294 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date         Time      Open      High       Low     Close  \\\n",
       "0       0.000000e+00        0.000  0.857201  0.857143  0.856793  0.856793   \n",
       "1       1.736138e-07        0.525  0.857201  0.857551  0.857609  0.857609   \n",
       "2       1.125017e-06        3.402  0.858017  0.858776  0.858425  0.859241   \n",
       "3       1.596255e-06        4.827  0.858425  0.859184  0.858833  0.859649   \n",
       "4       3.814542e-06       11.535  0.859241  0.859184  0.858833  0.858833   \n",
       "...              ...          ...       ...       ...       ...       ...   \n",
       "340289  9.999904e-01  3023924.810  0.856793  0.856735  0.855977  0.855977   \n",
       "340290  9.999930e-01  3023932.656  0.855161  0.855102  0.854753  0.854753   \n",
       "340291  9.999935e-01  3023933.950  0.854345  0.855102  0.854753  0.855569   \n",
       "340292  9.999949e-01  3023938.236  0.854753  0.855102  0.855161  0.855569   \n",
       "340293  1.000000e+00  3023953.749  0.854753  0.854694  0.854345  0.854345   \n",
       "\n",
       "          Volume    EMA_10    EMA_20    RSI_10    ATR_10  Target_Price  Signal  \n",
       "0       0.090748       NaN       NaN       NaN       NaN           NaN       0  \n",
       "1       0.053222       NaN       NaN       NaN       NaN           NaN       0  \n",
       "2       0.068917       NaN       NaN       NaN       NaN           NaN       0  \n",
       "3       0.054284       NaN       NaN       NaN       NaN           NaN       0  \n",
       "4       0.137951       NaN       NaN       NaN       NaN           NaN       0  \n",
       "...          ...       ...       ...       ...       ...           ...     ...  \n",
       "340289  0.042365  0.857822  0.857365  0.500293  0.059947           NaN       0  \n",
       "340290  0.081072  0.857463  0.857260  0.396903  0.064466           NaN       0  \n",
       "340291  0.052514  0.857318  0.857243  0.476291  0.064783           NaN       0  \n",
       "340292  0.056880  0.857199  0.857228  0.476291  0.061318           NaN       0  \n",
       "340293  0.088388  0.856878  0.857098  0.381124  0.065700           NaN       0  \n",
       "\n",
       "[340294 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef57711-e39c-4c5d-82ef-3dcf1b2af918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c21bca2-7daa-4e6f-95b5-8dbda1ffa7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7572af17-b7fe-4c23-9d85-f21be2513f96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret activation function identifier: ReLU",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m KerasModel \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      2\u001b[0m             \u001b[38;5;66;03m# keras.layers.Input(shape=(17)),\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m             \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReLU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      4\u001b[0m             keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m      5\u001b[0m             keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReLU\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      6\u001b[0m             keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.3\u001b[39m),\n\u001b[0;32m      7\u001b[0m             keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReLU\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      8\u001b[0m             keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReLU\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      9\u001b[0m             keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     10\u001b[0m             keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m2\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReLU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m             ])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:89\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(activity_regularizer\u001b[38;5;241m=\u001b[39mactivity_regularizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias \u001b[38;5;241m=\u001b[39m use_bias\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(kernel_initializer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\activations\\__init__.py:104\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(obj):\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret activation function identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret activation function identifier: ReLU"
     ]
    }
   ],
   "source": [
    "KerasModel = keras.models.Sequential([\n",
    "            # keras.layers.Input(shape=(17)),\n",
    "            keras.layers.Dense(11,  activation = 'ReLU'),\n",
    "            keras.layers.Dropout(0.1),\n",
    "            keras.layers.Dense(128, activation = 'ReLU'),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Dense(64, activation = 'ReLU'),\n",
    "            keras.layers.Dense(32, activation = 'ReLU'),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(2, activation = 'ReLU')\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7bd54c2-58d8-4b15-b7c3-756135203ea6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api.optimizers' has no attribute 'experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m MyOptimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241m.\u001b[39mAdamW(\n\u001b[0;32m      2\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m      3\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.004\u001b[39m,\n\u001b[0;32m      4\u001b[0m     beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[0;32m      5\u001b[0m     beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m,\n\u001b[0;32m      6\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-07\u001b[39m,\n\u001b[0;32m      7\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m     clipnorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m     clipvalue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m     global_clipnorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m     use_ema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m     ema_momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m,\n\u001b[0;32m     13\u001b[0m     ema_overwrite_frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m     jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdamW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api.optimizers' has no attribute 'experimental'"
     ]
    }
   ],
   "source": [
    "MyOptimizer = tf.keras.optimizers.experimental.AdamW(\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.004,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    clipnorm=None,\n",
    "    clipvalue=None,\n",
    "    global_clipnorm=None,\n",
    "    use_ema=False,\n",
    "    ema_momentum=0.99,\n",
    "    ema_overwrite_frequency=None,\n",
    "    jit_compile=True,\n",
    "    name=\"AdamW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1aa8bb86-ceb9-4998-863f-9b8bf607d3d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KerasModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mKerasModel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39mMyOptimizer,loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m# matrix\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KerasModel' is not defined"
     ]
    }
   ],
   "source": [
    "KerasModel.compile(optimizer =MyOptimizer,loss='binary_crossentropy',metrics=['accuracy']) # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcde90df-b417-49d1-a846-081257655a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KerasModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mKerasModel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X_train,y_train,\n\u001b[0;32m      2\u001b[0m                          validation_data\u001b[38;5;241m=\u001b[39m(X_test,y_test),\n\u001b[0;32m      3\u001b[0m                          epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m      4\u001b[0m                          batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[0;32m      5\u001b[0m                          verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      6\u001b[0m                          callbacks\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[0;32m      7\u001b[0m                                             patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      8\u001b[0m                                             monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;66;03m#\"val_loss\",\u001b[39;00m\n\u001b[0;32m      9\u001b[0m                                             restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KerasModel' is not defined"
     ]
    }
   ],
   "source": [
    "history = KerasModel.fit(X_train,y_train,\n",
    "                         validation_data=(X_test,y_test),\n",
    "                         epochs=100,\n",
    "                         batch_size=10000,\n",
    "                         verbose=1,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                                            patience=10,\n",
    "                                            monitor='val_accuracy',#\"val_loss\",\n",
    "                                            restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49db152b-13fa-4e09-8393-430be93947ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>ATR_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.090748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.736138e-07</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857551</td>\n",
       "      <td>0.857609</td>\n",
       "      <td>0.857609</td>\n",
       "      <td>0.053222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.125017e-06</td>\n",
       "      <td>3.402</td>\n",
       "      <td>0.858017</td>\n",
       "      <td>0.858776</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.596255e-06</td>\n",
       "      <td>4.827</td>\n",
       "      <td>0.858425</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.054284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.814542e-06</td>\n",
       "      <td>11.535</td>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.859184</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.858833</td>\n",
       "      <td>0.137951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238200</th>\n",
       "      <td>6.660544e-01</td>\n",
       "      <td>2014117.697</td>\n",
       "      <td>0.429621</td>\n",
       "      <td>0.429796</td>\n",
       "      <td>0.430029</td>\n",
       "      <td>0.430437</td>\n",
       "      <td>0.043191</td>\n",
       "      <td>0.428419</td>\n",
       "      <td>0.428307</td>\n",
       "      <td>0.618822</td>\n",
       "      <td>0.091519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238201</th>\n",
       "      <td>6.660550e-01</td>\n",
       "      <td>2014119.392</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.428980</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.097239</td>\n",
       "      <td>0.428438</td>\n",
       "      <td>0.428320</td>\n",
       "      <td>0.504163</td>\n",
       "      <td>0.096630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238202</th>\n",
       "      <td>6.660565e-01</td>\n",
       "      <td>2014123.942</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.429388</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.430029</td>\n",
       "      <td>0.159193</td>\n",
       "      <td>0.428678</td>\n",
       "      <td>0.428449</td>\n",
       "      <td>0.570628</td>\n",
       "      <td>0.097480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238203</th>\n",
       "      <td>6.660581e-01</td>\n",
       "      <td>2014128.803</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.428980</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.428725</td>\n",
       "      <td>0.428487</td>\n",
       "      <td>0.518751</td>\n",
       "      <td>0.094496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238204</th>\n",
       "      <td>6.660583e-01</td>\n",
       "      <td>2014129.606</td>\n",
       "      <td>0.428397</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.081190</td>\n",
       "      <td>0.428763</td>\n",
       "      <td>0.428522</td>\n",
       "      <td>0.518751</td>\n",
       "      <td>0.088060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238205 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date         Time      Open      High       Low     Close  \\\n",
       "0       0.000000e+00        0.000  0.857201  0.857143  0.856793  0.856793   \n",
       "1       1.736138e-07        0.525  0.857201  0.857551  0.857609  0.857609   \n",
       "2       1.125017e-06        3.402  0.858017  0.858776  0.858425  0.859241   \n",
       "3       1.596255e-06        4.827  0.858425  0.859184  0.858833  0.859649   \n",
       "4       3.814542e-06       11.535  0.859241  0.859184  0.858833  0.858833   \n",
       "...              ...          ...       ...       ...       ...       ...   \n",
       "238200  6.660544e-01  2014117.697  0.429621  0.429796  0.430029  0.430437   \n",
       "238201  6.660550e-01  2014119.392  0.429213  0.428980  0.428805  0.428805   \n",
       "238202  6.660565e-01  2014123.942  0.428805  0.429388  0.429213  0.430029   \n",
       "238203  6.660581e-01  2014128.803  0.429213  0.428980  0.429213  0.429213   \n",
       "238204  6.660583e-01  2014129.606  0.428397  0.428571  0.428805  0.429213   \n",
       "\n",
       "          Volume    EMA_10    EMA_20    RSI_10    ATR_10  \n",
       "0       0.090748       NaN       NaN       NaN       NaN  \n",
       "1       0.053222       NaN       NaN       NaN       NaN  \n",
       "2       0.068917       NaN       NaN       NaN       NaN  \n",
       "3       0.054284       NaN       NaN       NaN       NaN  \n",
       "4       0.137951       NaN       NaN       NaN       NaN  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "238200  0.043191  0.428419  0.428307  0.618822  0.091519  \n",
       "238201  0.097239  0.428438  0.428320  0.504163  0.096630  \n",
       "238202  0.159193  0.428678  0.428449  0.570628  0.097480  \n",
       "238203  0.055700  0.428725  0.428487  0.518751  0.094496  \n",
       "238204  0.081190  0.428763  0.428522  0.518751  0.088060  \n",
       "\n",
       "[238205 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54ae7234-5237-48e8-8687-51ea97267249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238200</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238202</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238203</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238204</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238205 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target_Price  Signal\n",
       "0                NaN       0\n",
       "1                NaN       0\n",
       "2                NaN       0\n",
       "3                NaN       0\n",
       "4                NaN       0\n",
       "...              ...     ...\n",
       "238200           NaN       0\n",
       "238201           NaN       0\n",
       "238202           NaN       0\n",
       "238203           NaN       0\n",
       "238204           NaN       0\n",
       "\n",
       "[238205 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c08934d-58ae-4be8-a1fb-c3723741e662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>ATR_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238205</th>\n",
       "      <td>0.666060</td>\n",
       "      <td>2014135.583</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.428980</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.055582</td>\n",
       "      <td>0.428721</td>\n",
       "      <td>0.428514</td>\n",
       "      <td>0.491056</td>\n",
       "      <td>0.086018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238206</th>\n",
       "      <td>0.666061</td>\n",
       "      <td>2014136.768</td>\n",
       "      <td>0.427581</td>\n",
       "      <td>0.427755</td>\n",
       "      <td>0.427989</td>\n",
       "      <td>0.427989</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.428537</td>\n",
       "      <td>0.428429</td>\n",
       "      <td>0.438690</td>\n",
       "      <td>0.084180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238207</th>\n",
       "      <td>0.666062</td>\n",
       "      <td>2014141.193</td>\n",
       "      <td>0.427173</td>\n",
       "      <td>0.428163</td>\n",
       "      <td>0.427581</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.099953</td>\n",
       "      <td>0.428535</td>\n",
       "      <td>0.428430</td>\n",
       "      <td>0.497657</td>\n",
       "      <td>0.086275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238208</th>\n",
       "      <td>0.666062</td>\n",
       "      <td>2014142.032</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.428980</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.429621</td>\n",
       "      <td>0.069861</td>\n",
       "      <td>0.428682</td>\n",
       "      <td>0.428509</td>\n",
       "      <td>0.550443</td>\n",
       "      <td>0.084411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238209</th>\n",
       "      <td>0.666064</td>\n",
       "      <td>2014145.574</td>\n",
       "      <td>0.430029</td>\n",
       "      <td>0.431429</td>\n",
       "      <td>0.430437</td>\n",
       "      <td>0.432069</td>\n",
       "      <td>0.086618</td>\n",
       "      <td>0.429250</td>\n",
       "      <td>0.428815</td>\n",
       "      <td>0.668236</td>\n",
       "      <td>0.097732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340289</th>\n",
       "      <td>0.999990</td>\n",
       "      <td>3023924.810</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>0.856735</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.042365</td>\n",
       "      <td>0.857822</td>\n",
       "      <td>0.857365</td>\n",
       "      <td>0.500293</td>\n",
       "      <td>0.059947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340290</th>\n",
       "      <td>0.999993</td>\n",
       "      <td>3023932.656</td>\n",
       "      <td>0.855161</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>0.857463</td>\n",
       "      <td>0.857260</td>\n",
       "      <td>0.396903</td>\n",
       "      <td>0.064466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340291</th>\n",
       "      <td>0.999993</td>\n",
       "      <td>3023933.950</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.855569</td>\n",
       "      <td>0.052514</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.857243</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.064783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340292</th>\n",
       "      <td>0.999995</td>\n",
       "      <td>3023938.236</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.855161</td>\n",
       "      <td>0.855569</td>\n",
       "      <td>0.056880</td>\n",
       "      <td>0.857199</td>\n",
       "      <td>0.857228</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.061318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340293</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3023953.749</td>\n",
       "      <td>0.854753</td>\n",
       "      <td>0.854694</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.854345</td>\n",
       "      <td>0.088388</td>\n",
       "      <td>0.856878</td>\n",
       "      <td>0.857098</td>\n",
       "      <td>0.381124</td>\n",
       "      <td>0.065700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102089 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Time      Open      High       Low     Close  \\\n",
       "238205  0.666060  2014135.583  0.429213  0.428980  0.428805  0.428805   \n",
       "238206  0.666061  2014136.768  0.427581  0.427755  0.427989  0.427989   \n",
       "238207  0.666062  2014141.193  0.427173  0.428163  0.427581  0.428805   \n",
       "238208  0.666062  2014142.032  0.428805  0.428980  0.429213  0.429621   \n",
       "238209  0.666064  2014145.574  0.430029  0.431429  0.430437  0.432069   \n",
       "...          ...          ...       ...       ...       ...       ...   \n",
       "340289  0.999990  3023924.810  0.856793  0.856735  0.855977  0.855977   \n",
       "340290  0.999993  3023932.656  0.855161  0.855102  0.854753  0.854753   \n",
       "340291  0.999993  3023933.950  0.854345  0.855102  0.854753  0.855569   \n",
       "340292  0.999995  3023938.236  0.854753  0.855102  0.855161  0.855569   \n",
       "340293  1.000000  3023953.749  0.854753  0.854694  0.854345  0.854345   \n",
       "\n",
       "          Volume    EMA_10    EMA_20    RSI_10    ATR_10  \n",
       "238205  0.055582  0.428721  0.428514  0.491056  0.086018  \n",
       "238206  0.055700  0.428537  0.428429  0.438690  0.084180  \n",
       "238207  0.099953  0.428535  0.428430  0.497657  0.086275  \n",
       "238208  0.069861  0.428682  0.428509  0.550443  0.084411  \n",
       "238209  0.086618  0.429250  0.428815  0.668236  0.097732  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "340289  0.042365  0.857822  0.857365  0.500293  0.059947  \n",
       "340290  0.081072  0.857463  0.857260  0.396903  0.064466  \n",
       "340291  0.052514  0.857318  0.857243  0.476291  0.064783  \n",
       "340292  0.056880  0.857199  0.857228  0.476291  0.061318  \n",
       "340293  0.088388  0.856878  0.857098  0.381124  0.065700  \n",
       "\n",
       "[102089 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de03947c-08da-49fa-8613-31f0aaaf5215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238205</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238207</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238209</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340289</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340290</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340291</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340293</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102089 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target_Price  Signal\n",
       "238205           NaN       0\n",
       "238206           NaN       0\n",
       "238207           NaN       0\n",
       "238208           NaN       0\n",
       "238209           NaN       0\n",
       "...              ...     ...\n",
       "340289           NaN       0\n",
       "340290           NaN       0\n",
       "340291           NaN       0\n",
       "340292           NaN       0\n",
       "340293           NaN       0\n",
       "\n",
       "[102089 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "797f6000-1fb3-49ea-859b-85dfa009ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1563fad-170a-43c3-99cf-254afc4f3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Shift signals to start from 0\n",
    "y_train_signal = y_train['Signal'] + 1  # Now 0,1,2\n",
    "y_test_signal = y_test['Signal'] + 1\n",
    "\n",
    "# One-hot encode the signals\n",
    "y_train_signal_encoded = to_categorical(y_train_signal, num_classes=3)\n",
    "y_test_signal_encoded = to_categorical(y_test_signal, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98e328e7-b656-4df0-9b77-c35621535b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_price = y_train['Target_Price'].values\n",
    "y_test_price = y_test['Target_Price'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "539ea196-6d21-4be8-bc3f-776c2d4ad70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = layers.Input(shape=(X_train_scaled.shape[1],))\n",
    "\n",
    "# Shared hidden layers\n",
    "x = layers.Dense(128, activation='relu')(input_layer)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "# Classification output layers\n",
    "classification_output = layers.Dense(3, activation='softmax', name='classification')(x)\n",
    "\n",
    "# Regression output layers\n",
    "regression_output = layers.Dense(1, activation='linear', name='regression')(x)\n",
    "\n",
    "# Create the model\n",
    "model = models.Model(inputs=input_layer, outputs=[classification_output, regression_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c85601c9-61ca-4c74-afe8-e43cbc04f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'classification': 'categorical_crossentropy',\n",
    "        'regression': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'classification': 'accuracy',\n",
    "        'regression': 'mean_absolute_error'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'classification': 1.0,\n",
    "        'regression': 0.5  # Adjust the weight as needed\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20054ca9-e73b-4149-ab25-25a463da9ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 6ms/step - classification_accuracy: 0.9756 - classification_loss: 0.4059 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 2/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - classification_accuracy: 0.9770 - classification_loss: 0.1256 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 3/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1274 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 4/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - classification_accuracy: 0.9771 - classification_loss: 0.1249 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1228 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 5/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - classification_accuracy: 0.9768 - classification_loss: 0.1265 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 6/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - classification_accuracy: 0.9765 - classification_loss: 0.1275 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 7/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - classification_accuracy: 0.9770 - classification_loss: 0.1254 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 8/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1271 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 9/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - classification_accuracy: 0.9771 - classification_loss: 0.1248 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 10/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - classification_accuracy: 0.9767 - classification_loss: 0.1266 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 11/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1272 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 12/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9765 - classification_loss: 0.1275 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 13/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1271 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 14/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - classification_accuracy: 0.9763 - classification_loss: 0.1284 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 15/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - classification_accuracy: 0.9771 - classification_loss: 0.1248 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 16/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9763 - classification_loss: 0.1285 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 17/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9767 - classification_loss: 0.1267 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 18/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - classification_accuracy: 0.9765 - classification_loss: 0.1275 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 19/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - classification_accuracy: 0.9764 - classification_loss: 0.1283 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 20/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1273 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 21/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1270 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 22/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9770 - classification_loss: 0.1254 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 23/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - classification_accuracy: 0.9773 - classification_loss: 0.1242 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 24/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9764 - classification_loss: 0.1282 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 25/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - classification_accuracy: 0.9765 - classification_loss: 0.1279 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 26/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9767 - classification_loss: 0.1266 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 27/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - classification_accuracy: 0.9771 - classification_loss: 0.1249 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 28/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - classification_accuracy: 0.9768 - classification_loss: 0.1265 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 29/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9765 - classification_loss: 0.1276 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 30/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9767 - classification_loss: 0.1267 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 31/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9765 - classification_loss: 0.1277 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 32/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9765 - classification_loss: 0.1275 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 33/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - classification_accuracy: 0.9769 - classification_loss: 0.1257 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 34/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1274 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 35/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9770 - classification_loss: 0.1254 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 36/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9763 - classification_loss: 0.1284 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 37/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9769 - classification_loss: 0.1257 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 38/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9764 - classification_loss: 0.1283 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 39/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9768 - classification_loss: 0.1263 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 40/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1271 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 41/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9767 - classification_loss: 0.1268 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 42/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9769 - classification_loss: 0.1259 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 43/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9771 - classification_loss: 0.1251 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 44/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9772 - classification_loss: 0.1246 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 45/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9768 - classification_loss: 0.1262 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 46/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - classification_accuracy: 0.9771 - classification_loss: 0.1250 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 47/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9768 - classification_loss: 0.1263 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 48/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9770 - classification_loss: 0.1254 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 49/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9762 - classification_loss: 0.1291 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 50/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - classification_accuracy: 0.9768 - classification_loss: 0.1265 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    {\n",
    "        'classification': y_train_signal_encoded,\n",
    "        'regression': y_train_price\n",
    "    },\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(\n",
    "        X_test_scaled,\n",
    "        {\n",
    "            'classification': y_test_signal_encoded,\n",
    "            'regression': y_test_price\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b0bd882-4be9-4a91-8d86-979d18bb8797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3191/3191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 911us/step - classification_accuracy: 0.9780 - classification_loss: 0.1212 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "evaluation = model.evaluate(\n",
    "    X_test_scaled,\n",
    "    {\n",
    "        'classification': y_test_signal_encoded,\n",
    "        'regression': y_test_price\n",
    "    }\n",
    ")\n",
    "\n",
    "# The evaluation variable contains loss and metric values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c5df032-c623-4328-aea3-2dd716163081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3191/3191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step\n",
      "   Predicted_Signal  Actual_Signal  Predicted_TargetPrice  Actual_TargetPrice\n",
      "0                 0              0                    NaN                 NaN\n",
      "1                 0              0                    NaN                 NaN\n",
      "2                 0              0                    NaN                 NaN\n",
      "3                 0              0                    NaN                 NaN\n",
      "4                 0              0                    NaN                 NaN\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "classification_preds = np.argmax(predictions[0], axis=1) - 1  # Shift back to -1,0,1\n",
    "regression_preds = predictions[1].flatten()\n",
    "\n",
    "# Create a DataFrame with results\n",
    "results = pd.DataFrame({\n",
    "    'Predicted_Signal': classification_preds,\n",
    "    'Actual_Signal': y_test['Signal'].values,\n",
    "    'Predicted_TargetPrice': regression_preds,\n",
    "    'Actual_TargetPrice': y_test_price\n",
    "})\n",
    "\n",
    "print(results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6ebe995-b3ff-418a-8fd1-5ccd215cbcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (results.Predicted_Signal==-1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f327ed9b-cf9b-45b8-87b1-299460db5ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c3ea4a3-07af-4b2d-8683-b9fbe6f470d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3191/3191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 765us/step\n",
      "   Predicted_Signal  Actual_Signal  Predicted_TargetPrice  Actual_TargetPrice\n",
      "0                 0              0                    NaN                 NaN\n",
      "1                 0              0                    NaN                 NaN\n",
      "2                 0              0                    NaN                 NaN\n",
      "3                 0              0                    NaN                 NaN\n",
      "4                 0              0                    NaN                 NaN\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "classification_preds = np.argmax(predictions[0], axis=1) - 1  # Shift back to -1,0,1\n",
    "regression_preds = predictions[1].flatten()\n",
    "\n",
    "# Create a DataFrame with results\n",
    "results = pd.DataFrame({\n",
    "    'Predicted_Signal': classification_preds,\n",
    "    'Actual_Signal': y_test['Signal'].values,\n",
    "    'Predicted_TargetPrice': regression_preds,\n",
    "    'Actual_TargetPrice': y_test_price\n",
    "})\n",
    "\n",
    "print(results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36eb7069-69f7-484d-9c3b-5247a1fe7809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1162\n",
      "           0       0.98      1.00      0.99     99805\n",
      "           1       0.00      0.00      0.00      1122\n",
      "\n",
      "    accuracy                           0.98    102089\n",
      "   macro avg       0.33      0.33      0.33    102089\n",
      "weighted avg       0.96      0.98      0.97    102089\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test['Signal'], classification_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6697280-0df9-42d5-a0bf-3997fb023a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot classification loss\n",
    "plt.plot(history.history['classification_loss'], label='Classification Loss')\n",
    "plt.plot(history.history['val_classification_loss'], label='Val Classification Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot regression loss\n",
    "plt.plot(history.history['regression_loss'], label='Regression Loss')\n",
    "plt.plot(history.history['val_regression_loss'], label='Val Regression Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot classification accuracy\n",
    "plt.plot(history.history['classification_accuracy'], label='Classification Accuracy')\n",
    "plt.plot(history.history['val_classification_accuracy'], label='Val Classification Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "801e2853-809e-40a5-9b04-7c9c0f7b2250",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Combine Date and Time into a single datetime column\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Extract useful features from datetime\u001b[39;00m\n\u001b[0;32m      7\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDayOfWeek\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdayofweek     \u001b[38;5;66;03m# Monday=0, Sunday=6\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine Date and Time into a single datetime column\n",
    "data['DateTime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'])\n",
    "\n",
    "# Extract useful features from datetime\n",
    "data['DayOfWeek'] = data['DateTime'].dt.dayofweek     # Monday=0, Sunday=6\n",
    "data['Hour'] = data['DateTime'].dt.hour\n",
    "data['Minute'] = data['DateTime'].dt.minute\n",
    "\n",
    "# Drop the original Date and Time columns\n",
    "data = data.drop(columns=['Date', 'Time', 'DateTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47124f42-fb7f-43d4-9341-0a1b4db39b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fit scaler on training data and transform both training and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d83d103a-9bd3-4961-8926-ae5deb0fe81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Adjust signals from (-1, 0, 1) to (0, 1, 2) for encoding\n",
    "y_train_signals = y_train['Signal'] + 1\n",
    "y_test_signals = y_test['Signal'] + 1\n",
    "\n",
    "# One-hot encode the trading signals\n",
    "y_train_signals_encoded = to_categorical(y_train_signals, num_classes=3)\n",
    "y_test_signals_encoded = to_categorical(y_test_signals, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cce35dc1-8f9e-43e3-9874-b48e2085da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prices = y_train['Target_Price'].values\n",
    "y_test_prices = y_test['Target_Price'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fbb00910-1773-4406-ba73-6a81c3400b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = layers.Input(shape=(X_train_scaled.shape[1],))\n",
    "\n",
    "# Shared hidden layers\n",
    "x = layers.Dense(128, activation='relu')(input_layer)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Classification output layer\n",
    "classification_output = layers.Dense(3, activation='softmax', name='classification')(x)\n",
    "\n",
    "# Regression output layer\n",
    "regression_output = layers.Dense(1, activation='linear', name='regression')(x)\n",
    "\n",
    "# Define the model with two outputs\n",
    "model = models.Model(inputs=input_layer, outputs=[classification_output, regression_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9dc7985-b09e-456c-af00-5d0532239984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'classification': 'categorical_crossentropy',\n",
    "        'regression': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'classification': 'accuracy',\n",
    "        'regression': 'mean_absolute_error'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'classification': 1.0,\n",
    "        'regression': 0.5  # Adjust this weight as needed\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "401555bb-f1d7-47e4-943d-86780a99da53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - classification_accuracy: 0.9754 - classification_loss: 0.4038 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 2/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - classification_accuracy: 0.9764 - classification_loss: 0.1283 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 3/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1273 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 4/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9763 - classification_loss: 0.1286 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 5/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9770 - classification_loss: 0.1255 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 6/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9763 - classification_loss: 0.1288 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 7/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1274 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 8/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9763 - classification_loss: 0.1287 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 9/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9764 - classification_loss: 0.1283 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 10/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1274 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 11/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9762 - classification_loss: 0.1290 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 12/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9772 - classification_loss: 0.1244 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 13/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1272 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 14/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9763 - classification_loss: 0.1283 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 15/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9765 - classification_loss: 0.1277 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 16/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9771 - classification_loss: 0.1249 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 17/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9765 - classification_loss: 0.1277 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 18/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9764 - classification_loss: 0.1280 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 19/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9768 - classification_loss: 0.1261 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 20/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9764 - classification_loss: 0.1280 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 21/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9763 - classification_loss: 0.1287 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 22/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9770 - classification_loss: 0.1254 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 23/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1274 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 24/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9768 - classification_loss: 0.1263 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 25/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9769 - classification_loss: 0.1258 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 26/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1273 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 27/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1270 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 28/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9769 - classification_loss: 0.1258 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 29/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9768 - classification_loss: 0.1264 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 30/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9761 - classification_loss: 0.1294 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 31/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9769 - classification_loss: 0.1261 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 32/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - classification_accuracy: 0.9767 - classification_loss: 0.1268 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 33/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - classification_accuracy: 0.9767 - classification_loss: 0.1269 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 34/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9767 - classification_loss: 0.1269 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 35/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9768 - classification_loss: 0.1263 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1228 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 36/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9769 - classification_loss: 0.1260 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 37/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9767 - classification_loss: 0.1269 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 38/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9771 - classification_loss: 0.1249 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1228 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 39/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9764 - classification_loss: 0.1281 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 40/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9773 - classification_loss: 0.1241 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 41/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9770 - classification_loss: 0.1254 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 42/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1273 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 43/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9771 - classification_loss: 0.1248 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 44/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1273 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 45/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9764 - classification_loss: 0.1283 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 46/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9770 - classification_loss: 0.1255 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 47/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - classification_accuracy: 0.9769 - classification_loss: 0.1260 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 48/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1274 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 49/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - classification_accuracy: 0.9766 - classification_loss: 0.1271 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1226 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n",
      "Epoch 50/50\n",
      "\u001b[1m7444/7444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - classification_accuracy: 0.9770 - classification_loss: 0.1255 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan - val_classification_accuracy: 0.9776 - val_classification_loss: 0.1227 - val_loss: nan - val_regression_loss: nan - val_regression_mean_absolute_error: nan\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    {\n",
    "        'classification': y_train_signals_encoded,\n",
    "        'regression': y_train_prices\n",
    "    },\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(\n",
    "        X_test_scaled,\n",
    "        {\n",
    "            'classification': y_test_signals_encoded,\n",
    "            'regression': y_test_prices\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a8b8d5e-6329-4163-92d1-7274ea6fb610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3191/3191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 677us/step - classification_accuracy: 0.9780 - classification_loss: 0.1212 - loss: nan - regression_loss: nan - regression_mean_absolute_error: nan\n",
      "Test Loss: nan\n",
      "Classification Loss: 0.12266777455806732\n",
      "Regression Loss: nan\n",
      "Classification Accuracy: 97.76%\n",
      "Regression Mean Absolute Error: nan\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluation = model.evaluate(\n",
    "    X_test_scaled,\n",
    "    {\n",
    "        'classification': y_test_signals_encoded,\n",
    "        'regression': y_test_prices\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Test Loss: {evaluation[0]}\")\n",
    "print(f\"Classification Loss: {evaluation[1]}\")\n",
    "print(f\"Regression Loss: {evaluation[2]}\")\n",
    "print(f\"Classification Accuracy: {evaluation[3]*100:.2f}%\")\n",
    "print(f\"Regression Mean Absolute Error: {evaluation[4]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8cfa7dda-1119-47cc-b014-6380d0571de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3191/3191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 603us/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Classification predictions\n",
    "classification_preds = np.argmax(predictions[0], axis=1) - 1  # Shift back to (-1, 0, 1)\n",
    "\n",
    "# Regression predictions\n",
    "regression_preds = predictions[1].flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67e3a6ff-2fe6-4adf-871f-231d846edb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1162\n",
      "           0       0.98      1.00      0.99     99805\n",
      "           1       0.00      0.00      0.00      1122\n",
      "\n",
      "    accuracy                           0.98    102089\n",
      "   macro avg       0.33      0.33      0.33    102089\n",
      "weighted avg       0.96      0.98      0.97    102089\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test['Signal'], classification_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "44ebbbf0-cfb1-4880-983b-3d9659607a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (results.Predicted_Signal==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a81ba0a6-d25e-4e7f-8121-ad1e0ad713d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d397ea-de16-44b6-8c02-957c16bdb4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab935f3-4e92-4ad4-9724-fe13814fa861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
