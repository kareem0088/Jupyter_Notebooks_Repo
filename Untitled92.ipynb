{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f250836c-4b0f-4f0f-a61a-306c254448ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Total images: 3978 | Classes: (array([0, 1, 2]), array([ 282, 1848, 1848], dtype=int64))\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 686. MiB for an array with shape (597, 224, 224, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 62\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# === تقسيم البيانات ===\u001b[39;00m\n\u001b[0;32m     59\u001b[0m X_train, X_temp, y_train, y_temp \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     60\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mSEED, stratify\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m     61\u001b[0m )\n\u001b[1;32m---> 62\u001b[0m X_val, X_test, y_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_temp\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# === عرض عينات ===\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2683\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m-> 2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2685\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[0;32m   2686\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2687\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2685\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2684\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2685\u001b[0m         (_safe_indexing(a, train), \u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2686\u001b[0m     )\n\u001b[0;32m   2687\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:411\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:208\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    207\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 686. MiB for an array with shape (597, 224, 224, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Image folder paths - أضف مسار مجلد الرطوبة\n",
    "CRACKS_PATH = r\"C:\\Users\\Access\\Documents\\rotoba_wall\\edges\"\n",
    "NO_CRACKS_PATH = r\"C:\\Users\\Access\\Documents\\non_crack_wall\\edges\"\n",
    "MOISTURE_PATH = r\"C:\\Users\\Access\\Documents\\moisture_wall\\edges\"  # أضف مسار صور الرطوبة\n",
    "\n",
    "# Image dimensions\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = [\"Normal\", \"Cracks\", \"Moisture\"]  # 0: Normal, 1: Cracks, 2: Moisture\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# Load images function\n",
    "def load_images_from_folder(folder_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                img = img / 255.0\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and label images\n",
    "print(\"Loading images...\")\n",
    "crack_images, crack_labels = load_images_from_folder(CRACKS_PATH, 1)\n",
    "no_crack_images, no_crack_labels = load_images_from_folder(NO_CRACKS_PATH, 0)\n",
    "moisture_images, moisture_labels = load_images_from_folder(MOISTURE_PATH, 2)\n",
    "\n",
    "# Combine data\n",
    "X = np.concatenate((no_crack_images, crack_images, moisture_images), axis=0)\n",
    "y = np.concatenate((no_crack_labels, crack_labels, moisture_labels), axis=0)\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "y_categorical = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Split into train, validation, test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_categorical, test_size=0.3, random_state=SEED, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED, stratify=y_temp)\n",
    "\n",
    "print(f\"Total images: {len(X)}\")\n",
    "print(f\"Training images: {len(X_train)}\")\n",
    "print(f\"Validation images: {len(X_val)}\")\n",
    "print(f\"Test images: {len(X_test)}\")\n",
    "\n",
    "# Count distribution\n",
    "y_original = np.argmax(np.concatenate([y_train, y_val, y_test]), axis=1)\n",
    "unique, counts = np.unique(y_original, return_counts=True)\n",
    "for i, count in zip(unique, counts):\n",
    "    print(f\"{CLASS_NAMES[i]}: {count} images\")\n",
    "\n",
    "# Display sample images\n",
    "def display_sample_images(images, labels, n=6):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Show 2 samples from each class\n",
    "    for class_idx in range(NUM_CLASSES):\n",
    "        class_indices = np.where(np.argmax(labels, axis=1) == class_idx)[0]\n",
    "        if len(class_indices) >= 2:\n",
    "            for i in range(2):\n",
    "                idx = class_indices[i]\n",
    "                axes[class_idx * 2 + i].imshow(images[idx])\n",
    "                axes[class_idx * 2 + i].set_title(f\"{CLASS_NAMES[class_idx]} - Sample {i+1}\")\n",
    "                axes[class_idx * 2 + i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Sample training images:\")\n",
    "display_sample_images(X_train, y_train)\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "batch_size = 32\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Build CNN model for multi-class classification\n",
    "def build_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(NUM_CLASSES, activation='softmax')  # softmax for multi-class\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',  # categorical crossentropy for multi-class\n",
    "        metrics=['accuracy', \n",
    "                 tf.keras.metrics.Precision(name='precision'), \n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_cnn_model()\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=1e-6, verbose=1),\n",
    "    ModelCheckpoint('best_model_three_class.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "]\n",
    "\n",
    "# Train model\n",
    "epochs = 200\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "validation_steps = len(X_val) // batch_size\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save('cnn_three_class_detection_model.keras')\n",
    "\n",
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'], loc='lower right')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper right')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot precision and recall\n",
    "    if 'precision' in history.history and 'recall' in history.history:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['precision'])\n",
    "        plt.plot(history.history['val_precision'])\n",
    "        plt.title('Model Precision')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='best')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['recall'])\n",
    "        plt.plot(history.history['val_recall'])\n",
    "        plt.title('Model Recall')\n",
    "        plt.ylabel('Recall')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='best')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Evaluating model on test data...\")\n",
    "test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "metrics_names = model.metrics_names\n",
    "\n",
    "for name, value in zip(metrics_names, test_results):\n",
    "    print(f\"Test {name}: {value:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASS_NAMES, \n",
    "            yticklabels=CLASS_NAMES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Three Class Classification')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=CLASS_NAMES))\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "for i, acc in enumerate(class_accuracies):\n",
    "    print(f\"{CLASS_NAMES[i]} Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Show predictions\n",
    "def display_predictions(images, true_labels, pred_labels, n=12):\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Find correct and incorrect predictions for each class\n",
    "    correct_indices = []\n",
    "    incorrect_indices = []\n",
    "    \n",
    "    for class_idx in range(NUM_CLASSES):\n",
    "        class_mask = (true_labels == class_idx)\n",
    "        correct_mask = (true_labels == pred_labels) & class_mask\n",
    "        incorrect_mask = (true_labels != pred_labels) & class_mask\n",
    "        \n",
    "        correct_indices.extend(np.where(correct_mask)[0][:2])  # 2 correct per class\n",
    "        incorrect_indices.extend(np.where(incorrect_mask)[0][:2])  # 2 incorrect per class\n",
    "    \n",
    "    # Display correct predictions\n",
    "    for i in range(min(6, len(correct_indices))):\n",
    "        idx = correct_indices[i]\n",
    "        axes[i].imshow(images[idx])\n",
    "        axes[i].set_title(f\"✓ True: {CLASS_NAMES[true_labels[idx]]}\\nPred: {CLASS_NAMES[pred_labels[idx]]}\", \n",
    "                         color=\"green\", fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Display incorrect predictions\n",
    "    for i in range(6, min(12, 6 + len(incorrect_indices))):\n",
    "        j = i - 6\n",
    "        if j < len(incorrect_indices):\n",
    "            idx = incorrect_indices[j]\n",
    "            axes[i].imshow(images[idx])\n",
    "            axes[i].set_title(f\"✗ True: {CLASS_NAMES[true_labels[idx]]}\\nPred: {CLASS_NAMES[pred_labels[idx]]}\", \n",
    "                             color=\"red\", fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Sample predictions:\")\n",
    "display_predictions(X_test, y_test_classes, y_pred_classes)\n",
    "\n",
    "# Calculate and display prediction confidence\n",
    "def analyze_prediction_confidence(y_pred, y_test_classes, y_pred_classes):\n",
    "    confidences = np.max(y_pred, axis=1)\n",
    "    correct_predictions = (y_test_classes == y_pred_classes)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(confidences[correct_predictions], bins=20, alpha=0.7, label='Correct', color='green')\n",
    "    plt.hist(confidences[~correct_predictions], bins=20, alpha=0.7, label='Incorrect', color='red')\n",
    "    plt.xlabel('Prediction Confidence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Prediction Confidence Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    class_confidences = [confidences[y_pred_classes == i] for i in range(NUM_CLASSES)]\n",
    "    plt.boxplot(class_confidences, labels=CLASS_NAMES)\n",
    "    plt.ylabel('Prediction Confidence')\n",
    "    plt.title('Confidence by Predicted Class')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average confidence for correct predictions: {np.mean(confidences[correct_predictions]):.4f}\")\n",
    "    print(f\"Average confidence for incorrect predictions: {np.mean(confidences[~correct_predictions]):.4f}\")\n",
    "\n",
    "analyze_prediction_confidence(y_pred, y_test_classes, y_pred_classes)\n",
    "\n",
    "# Function to predict single image\n",
    "def predict_single_image(model, image_path):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not load image: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img, verbose=0)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = np.max(prediction)\n",
    "    \n",
    "    print(f\"Predicted class: {CLASS_NAMES[predicted_class]}\")\n",
    "    print(f\"Confidence: {confidence:.4f}\")\n",
    "    print(f\"All probabilities: {prediction[0]}\")\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Example usage for single prediction\n",
    "# predicted_class, confidence = predict_single_image(model, \"path_to_your_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e52292-fc84-47fc-8c29-69ef2a9106f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
