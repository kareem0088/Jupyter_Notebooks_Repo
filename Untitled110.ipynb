{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb76466d-9200-4e14-9b7d-98924e45a62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 أداة تحميل بيانات Dukascopy (شموع / تيك) متقدمة\n",
      "\n",
      "🔹 اختر نوع البيانات\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "🔢 اختر رقم:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 اختر الأداة المالية\n",
      "1. XAUUSD\n",
      "2. EURUSD\n",
      "3. GBPUSD\n",
      "4. USDJPY\n",
      "5. USDCHF\n",
      "6. AUDUSD\n",
      "7. NZDUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "🔢 اختر رقم:  1\n",
      "⏰ أدخل GMT offset (مثال 0 أو 2 أو -5) [افتراضي 0]:  \n",
      "📅 أدخل تاريخ البداية (مثال: 2020-01-01):  2020-01-01\n",
      "📅 أدخل تاريخ النهاية (مثال: 2020-01-01):  2020-02-01\n",
      "\n",
      "📁 مسار الحفظ (Enter لاستخدام الافتراضي: C:\\\\Users\\\\Access\\\\Documents\\\\DATA):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 نوع السعر\n",
      "1. Bid فقط\n",
      "2. Ask فقط\n",
      "3. كلاهما\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "🔢 اختر رقم:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.00% | متبقي: 0 ثث\n",
      "✅ اكتمل التحميل!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "DEFAULT_SAVE_PATH = r\"C:\\\\Users\\\\Access\\\\Documents\\\\DATA\"\n",
    "SYMBOLS = [\"XAUUSD\", \"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"]\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"60\", \"5m\": \"300\", \"15m\": \"900\", \"1h\": \"3600\", \"4h\": \"14400\", \"1d\": \"86400\"\n",
    "}\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"🔢 اختر رقم: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            else:\n",
    "                print(\"❌ رقم غير صحيح.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ يجب إدخال رقم.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (مثال: 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ التاريخ غير صحيح.\")\n",
    "\n",
    "def get_custom_path(default_path):\n",
    "    choice = input(f\"\\n📁 مسار الحفظ (Enter لاستخدام الافتراضي: {default_path}): \").strip()\n",
    "    return choice if choice else default_path\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"⏰ أدخل GMT offset (مثال 0 أو 2 أو -5) [افتراضي 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time):\n",
    "    percent = 100 * (progress / total)\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = progress / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percent:.2f}% | متبقي: {int(remaining)} ث\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, path, price_type, gmt_offset):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{hour}h_ticks.bi5\"\n",
    "            try:\n",
    "                r = requests.get(url, timeout=10)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    for i in range(0, len(data), 20):\n",
    "                        chunk = data[i:i+20]\n",
    "                        if len(chunk) < 20: continue\n",
    "                        t_off, ask, bid, ask_vol, bid_vol = struct.unpack(\" >IIfff\", chunk)\n",
    "                        tick_time = day + timedelta(hours=hour, milliseconds=t_off)\n",
    "                        tick_time += timedelta(hours=gmt_offset)\n",
    "                        row = [tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]]\n",
    "                        if price_type == \"Bid فقط\":\n",
    "                            row += [round(bid, 5), round(bid_vol, 2)]\n",
    "                        elif price_type == \"Ask فقط\":\n",
    "                            row += [round(ask, 5), round(ask_vol, 2)]\n",
    "                        else:\n",
    "                            row += [round(bid, 5), round(ask, 5), round(bid_vol, 2), round(ask_vol, 2)]\n",
    "                        all_ticks.append(row)\n",
    "            except: pass\n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time)\n",
    "\n",
    "    if all_ticks:\n",
    "        filename = os.path.join(path, f\"{symbol}_tick_merged.csv\")\n",
    "        with open(filename, \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if price_type == \"Bid فقط\":\n",
    "                writer.writerow([\"time\", \"bid\", \"bid_vol\"])\n",
    "            elif price_type == \"Ask فقط\":\n",
    "                writer.writerow([\"time\", \"ask\", \"ask_vol\"])\n",
    "            else:\n",
    "                writer.writerow([\"time\", \"bid\", \"ask\", \"bid_vol\", \"ask_vol\"])\n",
    "            all_ticks.sort(key=lambda x: x[0])\n",
    "            writer.writerows(all_ticks)\n",
    "        print(f\"\\n✅ تم حفظ الملف: {filename}\")\n",
    "\n",
    "# ========== تحميل بيانات Candlestick ==========\n",
    "def download_candles(symbol, tf_code, start, end, path, gmt_offset):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    url_base = \"https://datafeed.dukascopy.com/datafeed/{}/{}/{}_candles_min_{}_bi5\"\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        year, month, day_ = day.year, day.month - 1, day.day\n",
    "        url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{year}/{month:02d}/{day_:02d}/\" \\\n",
    "              f\"{tf_code}_candles.bi5\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                data = lzma.decompress(r.content)\n",
    "                for i in range(0, len(data), 20):\n",
    "                    chunk = data[i:i+20]\n",
    "                    if len(chunk) < 20: continue\n",
    "                    utc_offset, open_, high, low, close, vol = struct.unpack(\n",
    "                        \">IIffff\", chunk[:20])\n",
    "                    candle_time = day + timedelta(seconds=utc_offset) + timedelta(hours=gmt_offset)\n",
    "                    row = [candle_time.strftime(\"%Y-%m-%d %H:%M:%S\"), round(open_, 5), round(high, 5),\n",
    "                           round(low, 5), round(close, 5), round(vol, 2)]\n",
    "                    all_data.append(row)\n",
    "        except: pass\n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time)\n",
    "\n",
    "    if all_data:\n",
    "        filename = os.path.join(path, f\"{symbol}_candles_{tf_code}_merged.csv\")\n",
    "        with open(filename, \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "            all_data.sort(key=lambda x: x[0])\n",
    "            writer.writerows(all_data)\n",
    "        print(f\"\\n✅ تم حفظ الملف: {filename}\")\n",
    "\n",
    "# ========== تشغيل البرنامج ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 أداة تحميل بيانات Dukascopy (شموع / تيك) متقدمة\")\n",
    "\n",
    "    data_type = show_menu([\"Tick\", \"Candlestick\"], \"اختر نوع البيانات\")\n",
    "    symbol = show_menu(SYMBOLS, \"اختر الأداة المالية\")\n",
    "    symbol = SYMBOLS.index(symbol)\n",
    "    gmt_offset = get_gmt_offset()\n",
    "    start = get_date_input(\"📅 أدخل تاريخ البداية\")\n",
    "    end = get_date_input(\"📅 أدخل تاريخ النهاية\")\n",
    "    save_path = get_custom_path(DEFAULT_SAVE_PATH)\n",
    "\n",
    "    if start > end:\n",
    "        print(\"❌ تاريخ النهاية يجب أن يكون بعد البداية.\")\n",
    "        exit()\n",
    "\n",
    "    if data_type == \"Tick\":\n",
    "        price_type = show_menu([\"Bid فقط\", \"Ask فقط\", \"كلاهما\"], \"نوع السعر\")\n",
    "        download_tick(SYMBOLS[symbol], start, end, save_path, price_type, gmt_offset)\n",
    "\n",
    "    else:\n",
    "        tf = show_menu(TIMEFRAMES, \"اختر التايم فريم\")\n",
    "        tf_code = CANDLE_FRAME_CODES[tf]\n",
    "        download_candles(SYMBOLS[symbol], tf_code, start, end, save_path, gmt_offset)\n",
    "\n",
    "    print(\"\\n✅ اكتمل التحميل!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e93ba8-9aa0-4714-9c6c-c2d143ac293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dukascopy Downloader Tool\n",
      "\n",
      "🔹 Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2020-01-01\n",
      "End date (e.g. 2020-01-01):  2020-01-03\n",
      "\n",
      "📁 Save path (Enter to use default: C:\\\\Users\\\\Access\\\\Documents\\\\DATA):  C:\\\\Users\\\\Access\\\\Documents\\\\DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Price type\n",
      "1. Bid فقط\n",
      "2. Ask فقط\n",
      "3. كلاهما\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.00% | 0.8MB of 2.1MB | ETA: 0h 0m 0s\n",
      "✅ Download completed!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "DEFAULT_SAVE_PATH = r\"C:\\\\Users\\\\Access\\\\Documents\\\\DATA\"\n",
    "CATEGORIES = {\n",
    "    \"Metals\": [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\": [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"60\", \"5m\": \"300\", \"15m\": \"900\", \"1h\": \"3600\", \"4h\": \"14400\", \"1d\": \"86400\"\n",
    "}\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            else:\n",
    "                print(\"❌ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid date format.\")\n",
    "\n",
    "def get_custom_path(default_path):\n",
    "    choice = input(f\"\\n📁 Save path (Enter to use default: {default_path}): \").strip()\n",
    "    return choice if choice else default_path\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def format_seconds(seconds):\n",
    "    # تحويل الثواني إلى صيغة (ساعات - دقائق - ثواني)\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total)\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = progress / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percent:.2f}% | {downloaded_mb:.1f}MB of {total_est_mb:.1f}MB | ETA: {format_seconds(remaining)}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, path, price_type, gmt_offset):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024  # تقدير تقريبي بالحجم\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{hour}h_ticks.bi5\"\n",
    "            try:\n",
    "                r = requests.get(url, timeout=10)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    for i in range(0, len(data), 20):\n",
    "                        chunk = data[i:i+20]\n",
    "                        if len(chunk) < 20: continue\n",
    "                        t_off, ask, bid, ask_vol, bid_vol = struct.unpack(\" >IIfff\", chunk)\n",
    "                        tick_time = day + timedelta(hours=hour, milliseconds=t_off)\n",
    "                        tick_time += timedelta(hours=gmt_offset)\n",
    "                        row = [tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]]\n",
    "                        if price_type == \"Bid فقط\":\n",
    "                            row += [round(bid, 5), round(bid_vol, 2)]\n",
    "                        elif price_type == \"Ask فقط\":\n",
    "                            row += [round(ask, 5), round(ask_vol, 2)]\n",
    "                        else:\n",
    "                            row += [round(bid, 5), round(ask, 5), round(bid_vol, 2), round(ask_vol, 2)]\n",
    "                        all_ticks.append(row)\n",
    "            except: pass\n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    if all_ticks:\n",
    "        filename = os.path.join(path, f\"{symbol}_tick_merged.csv\")\n",
    "        with open(filename, \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if price_type == \"Bid فقط\":\n",
    "                writer.writerow([\"time\", \"bid\", \"bid_vol\"])\n",
    "            elif price_type == \"Ask فقط\":\n",
    "                writer.writerow([\"time\", \"ask\", \"ask_vol\"])\n",
    "            else:\n",
    "                writer.writerow([\"time\", \"bid\", \"ask\", \"bid_vol\", \"ask_vol\"])\n",
    "            all_ticks.sort(key=lambda x: x[0])\n",
    "            writer.writerows(all_ticks)\n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"\\n✅ File saved: {filename}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "\n",
    "# ========== تحميل بيانات Candlestick ==========\n",
    "def download_candles(symbol, tf_code, start, end, path, gmt_offset):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024  # تقدير تقريبي بالحجم\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{tf_code}_candles.bi5\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                downloaded_bytes += len(r.content)\n",
    "                data = lzma.decompress(r.content)\n",
    "                for i in range(0, len(data), 20):\n",
    "                    chunk = data[i:i+20]\n",
    "                    if len(chunk) < 20: continue\n",
    "                    utc_offset, open_, high, low, close, vol = struct.unpack(\n",
    "                        \">IIffff\", chunk[:20])\n",
    "                    candle_time = day + timedelta(seconds=utc_offset) + timedelta(hours=gmt_offset)\n",
    "                    row = [candle_time.strftime(\"%Y-%m-%d %H:%M:%S\"), round(open_, 5), round(high, 5),\n",
    "                           round(low, 5), round(close, 5), round(vol, 2)]\n",
    "                    all_data.append(row)\n",
    "        except: pass\n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    if all_data:\n",
    "        filename = os.path.join(path, f\"{symbol}_candles_{tf_code}_merged.csv\")\n",
    "        with open(filename, \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "            all_data.sort(key=lambda x: x[0])\n",
    "            writer.writerows(all_data)\n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"\\n✅ File saved: {filename}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "\n",
    "# ========== تشغيل البرنامج ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 Dukascopy Downloader Tool\")\n",
    "\n",
    "    data_type = show_menu([\"Tick\", \"Candlestick\"], \"Select data type\")\n",
    "    category = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "    symbol = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "    gmt_offset = get_gmt_offset()\n",
    "    start = get_date_input(\"Start date\")\n",
    "    end = get_date_input(\"End date\")\n",
    "    save_path = get_custom_path(DEFAULT_SAVE_PATH)\n",
    "\n",
    "    if start > end:\n",
    "        print(\"❌ End date must be after start date.\")\n",
    "        exit()\n",
    "\n",
    "    if data_type == \"Tick\":\n",
    "        price_type = show_menu([\"Bid فقط\", \"Ask فقط\", \"كلاهما\"], \"Price type\")\n",
    "        download_tick(symbol, start, end, save_path, price_type, gmt_offset)\n",
    "    else:\n",
    "        tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "        tf_code = CANDLE_FRAME_CODES[tf]\n",
    "        download_candles(symbol, tf_code, start, end, save_path, gmt_offset)\n",
    "\n",
    "    print(\"\\n✅ Download completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2fe35f4-a77e-479b-bf7f-1142911f5374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dukascopy Downloader Tool\n",
      "\n",
      "🔹 Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2020-01-02\n",
      "End date (e.g. 2020-01-01):  2020-01-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Price type\n",
      "1. Bid فقط\n",
      "2. Ask فقط\n",
      "3. كلاهما\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.00% | 0.8MB of 1.4MB | ETA: 0h 0m 0s\n",
      "✅ Download completed!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "DEFAULT_SAVE_PATH = os.getcwd()\n",
    "CATEGORIES = {\n",
    "    \"Metals\": [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\": [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"60\", \"5m\": \"300\", \"15m\": \"900\", \"1h\": \"3600\", \"4h\": \"14400\", \"1d\": \"86400\"\n",
    "}\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            else:\n",
    "                print(\"❌ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid date format.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def format_seconds(seconds):\n",
    "    # تحويل الثواني إلى صيغة (ساعات - دقائق - ثواني)\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total)\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = progress / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percent:.2f}% | {downloaded_mb:.1f}MB of {total_est_mb:.1f}MB | ETA: {format_seconds(remaining)}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, price_type, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024  # تقدير تقريبي بالحجم\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{hour}h_ticks.bi5\"\n",
    "            try:\n",
    "                r = requests.get(url, timeout=10)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    for i in range(0, len(data), 20):\n",
    "                        chunk = data[i:i+20]\n",
    "                        if len(chunk) < 20: continue\n",
    "                        t_off, ask, bid, ask_vol, bid_vol = struct.unpack(\" >IIfff\", chunk)\n",
    "                        tick_time = day + timedelta(hours=hour, milliseconds=t_off)\n",
    "                        tick_time += timedelta(hours=gmt_offset)\n",
    "                        row = [tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]]\n",
    "                        if price_type == \"Bid فقط\":\n",
    "                            row += [round(bid, 5), round(bid_vol, 2)]\n",
    "                        elif price_type == \"Ask فقط\":\n",
    "                            row += [round(ask, 5), round(ask_vol, 2)]\n",
    "                        else:\n",
    "                            row += [round(bid, 5), round(ask, 5), round(bid_vol, 2), round(ask_vol, 2)]\n",
    "                        all_ticks.append(row)\n",
    "            except: pass\n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    if all_ticks:\n",
    "        filename = os.path.join(path, f\"{symbol}_tick_merged.csv\")\n",
    "        with open(filename, \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if price_type == \"Bid فقط\":\n",
    "                writer.writerow([\"time\", \"bid\", \"bid_vol\"])\n",
    "            elif price_type == \"Ask فقط\":\n",
    "                writer.writerow([\"time\", \"ask\", \"ask_vol\"])\n",
    "            else:\n",
    "                writer.writerow([\"time\", \"bid\", \"ask\", \"bid_vol\", \"ask_vol\"])\n",
    "            all_ticks.sort(key=lambda x: x[0])\n",
    "            writer.writerows(all_ticks)\n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"\\n✅ File saved: {os.path.abspath(filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "\n",
    "# ========== تحميل بيانات Candlestick ==========\n",
    "def download_candles(symbol, tf_code, start, end, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024  # تقدير تقريبي بالحجم\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{tf_code}_candles.bi5\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                downloaded_bytes += len(r.content)\n",
    "                data = lzma.decompress(r.content)\n",
    "                for i in range(0, len(data), 20):\n",
    "                    chunk = data[i:i+20]\n",
    "                    if len(chunk) < 20: continue\n",
    "                    utc_offset, open_, high, low, close, vol = struct.unpack(\n",
    "                        \">IIffff\", chunk[:20])\n",
    "                    candle_time = day + timedelta(seconds=utc_offset) + timedelta(hours=gmt_offset)\n",
    "                    row = [candle_time.strftime(\"%Y-%m-%d %H:%M:%S\"), round(open_, 5), round(high, 5),\n",
    "                           round(low, 5), round(close, 5), round(vol, 2)]\n",
    "                    all_data.append(row)\n",
    "        except: pass\n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    if all_data:\n",
    "        filename = os.path.join(path, f\"{symbol}_candles_{tf_code}_merged.csv\")\n",
    "        with open(filename, \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "            all_data.sort(key=lambda x: x[0])\n",
    "            writer.writerows(all_data)\n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"\\n✅ File saved: {os.path.abspath(filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "\n",
    "# ========== تشغيل البرنامج ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 Dukascopy Downloader Tool\")\n",
    "\n",
    "    data_type = show_menu([\"Tick\", \"Candlestick\"], \"Select data type\")\n",
    "    category = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "    symbol = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "    gmt_offset = get_gmt_offset()\n",
    "    start = get_date_input(\"Start date\")\n",
    "    end = get_date_input(\"End date\")\n",
    "\n",
    "    if start > end:\n",
    "        print(\"❌ End date must be after start date.\")\n",
    "        exit()\n",
    "\n",
    "    if data_type == \"Tick\":\n",
    "        price_type = show_menu([\"Bid فقط\", \"Ask فقط\", \"كلاهما\"], \"Price type\")\n",
    "        download_tick(symbol, start, end, price_type, gmt_offset)\n",
    "    else:\n",
    "        tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "        tf_code = CANDLE_FRAME_CODES[tf]\n",
    "        download_candles(symbol, tf_code, start, end, gmt_offset)\n",
    "\n",
    "    print(\"\\n✅ Download completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e79c0185-8592-4e1b-824d-038729d46220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dukascopy Downloader Tool\n",
      "========================================\n",
      "\n",
      "🔹 Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2020-01-05\n",
      "End date (e.g. 2020-01-01):  2020-01-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Configuration Summary:\n",
      "   - Symbol: XAUUSD\n",
      "   - Data type: Tick\n",
      "   - Date range: 2020-01-05 to 2020-01-07\n",
      "   - GMT offset: 0\n",
      "   - Save path: C:\\Users\\Access\n",
      "\n",
      "🔹 Price type\n",
      "1. Bid فقط\n",
      "2. Ask فقط\n",
      "3. كلاهما\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Price type: كلاهما\n",
      "\n",
      "🔄 Starting tick download for XAUUSD...\n",
      "📅 Date range: 2020-01-05 to 2020-01-07\n",
      "⏰ GMT offset: 0\n",
      "[======                                            ] 13.89% | 0.0MB of 2.1MB | ETA: 0h 0m 38s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 10h\n",
      "[=======                                           ] 15.28% | 0.0MB of 2.1MB | ETA: 0h 0m 36s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 11h\n",
      "[========                                          ] 16.67% | 0.0MB of 2.1MB | ETA: 0h 0m 36s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 12h\n",
      "[=========                                         ] 18.06% | 0.0MB of 2.1MB | ETA: 0h 0m 34s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 13h\n",
      "[=========                                         ] 19.44% | 0.0MB of 2.1MB | ETA: 0h 0m 32s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 14h\n",
      "[==========                                        ] 20.83% | 0.0MB of 2.1MB | ETA: 0h 0m 30s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 15h\n",
      "[===========                                       ] 22.22% | 0.0MB of 2.1MB | ETA: 0h 0m 29s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 16h\n",
      "[===========                                       ] 23.61% | 0.0MB of 2.1MB | ETA: 0h 0m 28s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 17h\n",
      "[============                                      ] 25.00% | 0.0MB of 2.1MB | ETA: 0h 0m 27s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 18h\n",
      "[=============                                     ] 26.39% | 0.0MB of 2.1MB | ETA: 0h 0m 26s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 19h\n",
      "[=============                                     ] 27.78% | 0.0MB of 2.1MB | ETA: 0h 0m 25s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 20h\n",
      "[==============                                    ] 29.17% | 0.0MB of 2.1MB | ETA: 0h 0m 24s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 21h\n",
      "[===============                                   ] 30.56% | 0.0MB of 2.1MB | ETA: 0h 0m 23s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-05 22h\n",
      "[===============================                   ] 63.89% | 0.5MB of 2.1MB | ETA: 0h 0m 17s\n",
      "⚠️ Warning: HTTP 200 for 2020-01-06 22h\n",
      "[================================================  ] 97.22% | 1.0MB of 2.1MB | ETA: 0h 0m 1ss\n",
      "⚠️ Warning: HTTP 200 for 2020-01-07 22h\n",
      "[==================================================] 100.00% | 1.0MB of 2.1MB | ETA: 0h 0m 0s\n",
      "\n",
      "📊 Download Summary:\n",
      "   - Total hours processed: 72\n",
      "   - Successful downloads: 27\n",
      "   - Total ticks collected: 279519\n",
      "✅ File saved: C:\\Users\\Access\\XAUUSD_tick_merged.csv\n",
      "📦 Size: 12.00 MB\n",
      "\n",
      "✅ Download completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "DEFAULT_SAVE_PATH = os.getcwd()\n",
    "CATEGORIES = {\n",
    "    \"Metals\": [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\": [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"60\", \"5m\": \"300\", \"15m\": \"900\", \"1h\": \"3600\", \"4h\": \"14400\", \"1d\": \"86400\"\n",
    "}\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            else:\n",
    "                print(\"❌ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid date format.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def format_seconds(seconds):\n",
    "    # تحويل الثواني إلى صيغة (ساعات - دقائق - ثواني)\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total)\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = progress / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percent:.2f}% | {downloaded_mb:.1f}MB of {total_est_mb:.1f}MB | ETA: {format_seconds(remaining)}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, price_type, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting tick download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    \n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{hour}h_ticks.bi5\"\n",
    "            try:\n",
    "                r = requests.get(url, timeout=15)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    successful_downloads += 1\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    try:\n",
    "                        data = lzma.decompress(r.content)\n",
    "                        for i in range(0, len(data), 20):\n",
    "                            chunk = data[i:i+20]\n",
    "                            if len(chunk) < 20: \n",
    "                                continue\n",
    "                            t_off, ask, bid, ask_vol, bid_vol = struct.unpack(\">IIfff\", chunk)\n",
    "                            tick_time = day + timedelta(hours=hour, milliseconds=t_off)\n",
    "                            tick_time += timedelta(hours=gmt_offset)\n",
    "                            row = [tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]]\n",
    "                            \n",
    "                            if price_type == \"Bid فقط\":\n",
    "                                row += [round(bid, 5), round(bid_vol, 2)]\n",
    "                            elif price_type == \"Ask فقط\":\n",
    "                                row += [round(ask, 5), round(ask_vol, 2)]\n",
    "                            else:\n",
    "                                row += [round(bid, 5), round(ask, 5), round(bid_vol, 2), round(ask_vol, 2)]\n",
    "                            all_ticks.append(row)\n",
    "                    except lzma.LZMAError as e:\n",
    "                        print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                        continue\n",
    "                elif r.status_code == 404:\n",
    "                    # البيانات غير متوفرة لهذا التاريخ/الساعة (طبيعي)\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')} {hour}h\")\n",
    "                    \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                continue\n",
    "                \n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total hours processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total ticks collected: {len(all_ticks)}\")\n",
    "\n",
    "    # حفظ الملف حتى لو كانت البيانات قليلة\n",
    "    filename = os.path.join(path, f\"{symbol}_tick_merged.csv\")\n",
    "    try:\n",
    "        with open(filename, \"w\", newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if price_type == \"Bid فقط\":\n",
    "                writer.writerow([\"time\", \"bid\", \"bid_vol\"])\n",
    "            elif price_type == \"Ask فقط\":\n",
    "                writer.writerow([\"time\", \"ask\", \"ask_vol\"])\n",
    "            else:\n",
    "                writer.writerow([\"time\", \"bid\", \"ask\", \"bid_vol\", \"ask_vol\"])\n",
    "            \n",
    "            if all_ticks:\n",
    "                all_ticks.sort(key=lambda x: x[0])\n",
    "                writer.writerows(all_ticks)\n",
    "            else:\n",
    "                print(\"⚠️ No tick data was collected. Creating empty file with headers only.\")\n",
    "        \n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving file: {e}\")\n",
    "        return False\n",
    "\n",
    "# ========== تحميل بيانات Candlestick ==========\n",
    "def download_candles(symbol, tf_code, start, end, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting candle download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    print(f\"📊 Timeframe code: {tf_code}\")\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{tf_code}_candles.bi5\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=15)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                successful_downloads += 1\n",
    "                downloaded_bytes += len(r.content)\n",
    "                try:\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    for i in range(0, len(data), 24):  # Changed from 20 to 24 bytes for candles\n",
    "                        chunk = data[i:i+24]\n",
    "                        if len(chunk) < 24: \n",
    "                            continue\n",
    "                        utc_offset, open_, high, low, close, vol = struct.unpack(\">IIffff\", chunk[:24])\n",
    "                        candle_time = day + timedelta(seconds=utc_offset) + timedelta(hours=gmt_offset)\n",
    "                        row = [candle_time.strftime(\"%Y-%m-%d %H:%M:%S\"), round(open_, 5), round(high, 5),\n",
    "                               round(low, 5), round(close, 5), round(vol, 2)]\n",
    "                        all_data.append(row)\n",
    "                except lzma.LZMAError as e:\n",
    "                    print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "                    continue\n",
    "            elif r.status_code == 404:\n",
    "                # البيانات غير متوفرة لهذا التاريخ (طبيعي)\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')}\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total days processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total candles collected: {len(all_data)}\")\n",
    "\n",
    "    # حفظ الملف حتى لو كانت البيانات قليلة\n",
    "    filename = os.path.join(path, f\"{symbol}_candles_{tf_code}_merged.csv\")\n",
    "    try:\n",
    "        with open(filename, \"w\", newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "            \n",
    "            if all_data:\n",
    "                all_data.sort(key=lambda x: x[0])\n",
    "                writer.writerows(all_data)\n",
    "            else:\n",
    "                print(\"⚠️ No candle data was collected. Creating empty file with headers only.\")\n",
    "        \n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving file: {e}\")\n",
    "        return False\n",
    "\n",
    "# ========== تشغيل البرنامج ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 Dukascopy Downloader Tool\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    try:\n",
    "        data_type = show_menu([\"Tick\", \"Candlestick\"], \"Select data type\")\n",
    "        category = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "        symbol = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "        gmt_offset = get_gmt_offset()\n",
    "        start = get_date_input(\"Start date\")\n",
    "        end = get_date_input(\"End date\")\n",
    "\n",
    "        if start > end:\n",
    "            print(\"❌ End date must be after start date.\")\n",
    "            exit()\n",
    "\n",
    "        print(f\"\\n📝 Configuration Summary:\")\n",
    "        print(f\"   - Symbol: {symbol}\")\n",
    "        print(f\"   - Data type: {data_type}\")\n",
    "        print(f\"   - Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"   - GMT offset: {gmt_offset}\")\n",
    "        print(f\"   - Save path: {DEFAULT_SAVE_PATH}\")\n",
    "\n",
    "        success = False\n",
    "        if data_type == \"Tick\":\n",
    "            price_type = show_menu([\"Bid فقط\", \"Ask فقط\", \"كلاهما\"], \"Price type\")\n",
    "            print(f\"   - Price type: {price_type}\")\n",
    "            success = download_tick(symbol, start, end, price_type, gmt_offset)\n",
    "        else:\n",
    "            tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "            tf_code = CANDLE_FRAME_CODES[tf]\n",
    "            print(f\"   - Timeframe: {tf}\")\n",
    "            success = download_candles(symbol, tf_code, start, end, gmt_offset)\n",
    "\n",
    "        if success:\n",
    "            print(\"\\n✅ Download completed successfully!\")\n",
    "        else:\n",
    "            print(\"\\n❌ Download completed with errors!\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n⏹️ Download interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c579db6f-2bc4-484e-a5a2-3a2d0fa7bb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dukascopy Downloader Tool\n",
      "========================================\n",
      "\n",
      "🔹 Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2020-02-01\n",
      "End date (e.g. 2020-01-01):  2020-02-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Configuration Summary:\n",
      "   - Symbol: XAUUSD\n",
      "   - Data type: Tick\n",
      "   - Date range: 2020-02-01 to 2020-02-03\n",
      "   - GMT offset: 0\n",
      "   - Save path: C:\\Users\\Access\n",
      "\n",
      "🔹 Price type\n",
      "1. Bid فقط\n",
      "2. Ask فقط\n",
      "3. كلاهما\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Price type: كلاهما\n",
      "\n",
      "🔄 Starting tick download for XAUUSD...\n",
      "📅 Date range: 2020-02-01 to 2020-02-03\n",
      "⏰ GMT offset: 0\n",
      "[======                                            ] 13.89% | 0.0MB of 2.1MB | ETA: 0h 0m 33s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 10h\n",
      "[=======                                           ] 15.28% | 0.0MB of 2.1MB | ETA: 0h 0m 31s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 11h\n",
      "[========                                          ] 16.67% | 0.0MB of 2.1MB | ETA: 0h 0m 29s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 12h\n",
      "[=========                                         ] 18.06% | 0.0MB of 2.1MB | ETA: 0h 0m 27s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 13h\n",
      "[=========                                         ] 19.44% | 0.0MB of 2.1MB | ETA: 0h 0m 25s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 14h\n",
      "[==========                                        ] 20.83% | 0.0MB of 2.1MB | ETA: 0h 0m 24s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 15h\n",
      "[===========                                       ] 22.22% | 0.0MB of 2.1MB | ETA: 0h 0m 23s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 16h\n",
      "[===========                                       ] 23.61% | 0.0MB of 2.1MB | ETA: 0h 0m 22s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 17h\n",
      "[============                                      ] 25.00% | 0.0MB of 2.1MB | ETA: 0h 0m 21s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 18h\n",
      "[=============                                     ] 26.39% | 0.0MB of 2.1MB | ETA: 0h 0m 20s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 19h\n",
      "[=============                                     ] 27.78% | 0.0MB of 2.1MB | ETA: 0h 0m 19s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 20h\n",
      "[==============                                    ] 29.17% | 0.0MB of 2.1MB | ETA: 0h 0m 19s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 21h\n",
      "[===============                                   ] 30.56% | 0.0MB of 2.1MB | ETA: 0h 0m 18s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 22h\n",
      "[===============                                   ] 31.94% | 0.0MB of 2.1MB | ETA: 0h 0m 17s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-01 23h\n",
      "[=======================                           ] 47.22% | 0.0MB of 2.1MB | ETA: 0h 0m 13s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 10h\n",
      "[========================                          ] 48.61% | 0.0MB of 2.1MB | ETA: 0h 0m 12s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 11h\n",
      "[=========================                         ] 50.00% | 0.0MB of 2.1MB | ETA: 0h 0m 12s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 12h\n",
      "[=========================                         ] 51.39% | 0.0MB of 2.1MB | ETA: 0h 0m 11s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 13h\n",
      "[==========================                        ] 52.78% | 0.0MB of 2.1MB | ETA: 0h 0m 11s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 14h\n",
      "[===========================                       ] 54.17% | 0.0MB of 2.1MB | ETA: 0h 0m 10s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 15h\n",
      "[===========================                       ] 55.56% | 0.0MB of 2.1MB | ETA: 0h 0m 10s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 16h\n",
      "[============================                      ] 56.94% | 0.0MB of 2.1MB | ETA: 0h 0m 10s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 17h\n",
      "[=============================                     ] 58.33% | 0.0MB of 2.1MB | ETA: 0h 0m 9s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 18h\n",
      "[=============================                     ] 59.72% | 0.0MB of 2.1MB | ETA: 0h 0m 9s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 19h\n",
      "[==============================                    ] 61.11% | 0.0MB of 2.1MB | ETA: 0h 0m 9s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 20h\n",
      "[===============================                   ] 62.50% | 0.0MB of 2.1MB | ETA: 0h 0m 8s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 21h\n",
      "[===============================                   ] 63.89% | 0.0MB of 2.1MB | ETA: 0h 0m 8s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-02 22h\n",
      "[================================================  ] 97.22% | 0.4MB of 2.1MB | ETA: 0h 0m 0s\n",
      "⚠️ Warning: HTTP 200 for 2020-02-03 22h\n",
      "[==================================================] 100.00% | 0.4MB of 2.1MB | ETA: 0h 0m 0s\n",
      "\n",
      "📊 Download Summary:\n",
      "   - Total hours processed: 72\n",
      "   - Successful downloads: 14\n",
      "   - Total ticks collected: 111101\n",
      "❌ Error saving file: [Errno 13] Permission denied: 'C:\\\\Users\\\\Access\\\\XAUUSD_tick_merged.csv'\n",
      "\n",
      "❌ Download completed with errors!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "DEFAULT_SAVE_PATH = os.getcwd()\n",
    "CATEGORIES = {\n",
    "    \"Metals\": [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\": [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"60\", \"5m\": \"300\", \"15m\": \"900\", \"1h\": \"3600\", \"4h\": \"14400\", \"1d\": \"86400\"\n",
    "}\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            else:\n",
    "                print(\"❌ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid date format.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def format_seconds(seconds):\n",
    "    # تحويل الثواني إلى صيغة (ساعات - دقائق - ثواني)\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total)\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = progress / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percent:.2f}% | {downloaded_mb:.1f}MB of {total_est_mb:.1f}MB | ETA: {format_seconds(remaining)}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, price_type, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting tick download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    \n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{hour}h_ticks.bi5\"\n",
    "            try:\n",
    "                r = requests.get(url, timeout=15)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    successful_downloads += 1\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    try:\n",
    "                        data = lzma.decompress(r.content)\n",
    "                        for i in range(0, len(data), 20):\n",
    "                            chunk = data[i:i+20]\n",
    "                            if len(chunk) < 20: \n",
    "                                continue\n",
    "                            # فك ضغط البيانات: الترتيب الصحيح هو time_offset, ask, bid, ask_volume, bid_volume\n",
    "                            t_off, ask, bid, ask_vol, bid_vol = struct.unpack(\">IIfff\", chunk)\n",
    "                            \n",
    "                            # حساب الوقت الصحيح\n",
    "                            tick_time = day + timedelta(hours=hour, milliseconds=t_off)\n",
    "                            tick_time += timedelta(hours=gmt_offset)\n",
    "                            \n",
    "                            # تنسيق التاريخ والوقت معاً\n",
    "                            formatted_time = tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                            \n",
    "                            if price_type == \"Bid فقط\":\n",
    "                                row = [formatted_time, round(bid, 5), round(bid_vol, 2)]\n",
    "                            elif price_type == \"Ask فقط\":\n",
    "                                row = [formatted_time, round(ask, 5), round(ask_vol, 2)]\n",
    "                            else:  # كلاهما - دمج Bid و Ask\n",
    "                                row = [formatted_time, round(bid, 5), round(ask, 5), round(bid_vol, 2), round(ask_vol, 2)]\n",
    "                            \n",
    "                            all_ticks.append(row)\n",
    "                    except lzma.LZMAError as e:\n",
    "                        print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                        continue\n",
    "                elif r.status_code == 404:\n",
    "                    # البيانات غير متوفرة لهذا التاريخ/الساعة (طبيعي)\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')} {hour}h\")\n",
    "                    \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                continue\n",
    "                \n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total hours processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total ticks collected: {len(all_ticks)}\")\n",
    "\n",
    "    # حفظ الملف مع الترتيب الصحيح للأعمدة\n",
    "    filename = os.path.join(path, f\"{symbol}_tick_merged.csv\")\n",
    "    try:\n",
    "        with open(filename, \"w\", newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            # كتابة رؤوس الأعمدة حسب نوع البيانات المختار\n",
    "            if price_type == \"Bid فقط\":\n",
    "                writer.writerow([\"datetime\", \"bid\", \"bid_volume\"])\n",
    "            elif price_type == \"Ask فقط\":\n",
    "                writer.writerow([\"datetime\", \"ask\", \"ask_volume\"])\n",
    "            else:  # كلاهما\n",
    "                writer.writerow([\"datetime\", \"bid\", \"ask\", \"bid_volume\", \"ask_volume\"])\n",
    "            \n",
    "            if all_ticks:\n",
    "                # ترتيب البيانات حسب التاريخ والوقت\n",
    "                all_ticks.sort(key=lambda x: x[0])\n",
    "                writer.writerows(all_ticks)\n",
    "            else:\n",
    "                print(\"⚠️ No tick data was collected. Creating empty file with headers only.\")\n",
    "        \n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving file: {e}\")\n",
    "        return False\n",
    "\n",
    "# ========== تحميل بيانات Candlestick ==========\n",
    "def download_candles(symbol, tf_code, start, end, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting candle download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    print(f\"📊 Timeframe code: {tf_code}\")\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{tf_code}_candles.bi5\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=15)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                successful_downloads += 1\n",
    "                downloaded_bytes += len(r.content)\n",
    "                try:\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    for i in range(0, len(data), 24):  # Changed from 20 to 24 bytes for candles\n",
    "                        chunk = data[i:i+24]\n",
    "                        if len(chunk) < 24: \n",
    "                            continue\n",
    "                        # فك ضغط البيانات للشموع\n",
    "                        utc_offset, open_, high, low, close, vol = struct.unpack(\">IIffff\", chunk[:24])\n",
    "                        \n",
    "                        # حساب الوقت الصحيح للشمعة\n",
    "                        candle_time = day + timedelta(seconds=utc_offset) + timedelta(hours=gmt_offset)\n",
    "                        \n",
    "                        # تنسيق التاريخ والوقت معاً\n",
    "                        formatted_time = candle_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        \n",
    "                        row = [formatted_time, round(open_, 5), round(high, 5),\n",
    "                               round(low, 5), round(close, 5), round(vol, 2)]\n",
    "                        all_data.append(row)\n",
    "                except lzma.LZMAError as e:\n",
    "                    print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "                    continue\n",
    "            elif r.status_code == 404:\n",
    "                # البيانات غير متوفرة لهذا التاريخ (طبيعي)\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')}\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total days processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total candles collected: {len(all_data)}\")\n",
    "\n",
    "    # حفظ الملف حتى لو كانت البيانات قليلة\n",
    "    filename = os.path.join(path, f\"{symbol}_candles_{tf_code}_merged.csv\")\n",
    "    try:\n",
    "        with open(filename, \"w\", newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            # كتابة رؤوس الأعمدة للشموع\n",
    "            writer.writerow([\"datetime\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "            \n",
    "            if all_data:\n",
    "                # ترتيب البيانات حسب التاريخ والوقت\n",
    "                all_data.sort(key=lambda x: x[0])\n",
    "                writer.writerows(all_data)\n",
    "            else:\n",
    "                print(\"⚠️ No candle data was collected. Creating empty file with headers only.\")\n",
    "        \n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving file: {e}\")\n",
    "        return False\n",
    "\n",
    "# ========== تشغيل البرنامج ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 Dukascopy Downloader Tool\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    try:\n",
    "        data_type = show_menu([\"Tick\", \"Candlestick\"], \"Select data type\")\n",
    "        category = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "        symbol = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "        gmt_offset = get_gmt_offset()\n",
    "        start = get_date_input(\"Start date\")\n",
    "        end = get_date_input(\"End date\")\n",
    "\n",
    "        if start > end:\n",
    "            print(\"❌ End date must be after start date.\")\n",
    "            exit()\n",
    "\n",
    "        print(f\"\\n📝 Configuration Summary:\")\n",
    "        print(f\"   - Symbol: {symbol}\")\n",
    "        print(f\"   - Data type: {data_type}\")\n",
    "        print(f\"   - Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"   - GMT offset: {gmt_offset}\")\n",
    "        print(f\"   - Save path: {DEFAULT_SAVE_PATH}\")\n",
    "\n",
    "        success = False\n",
    "        if data_type == \"Tick\":\n",
    "            price_type = show_menu([\"Bid فقط\", \"Ask فقط\", \"كلاهما\"], \"Price type\")\n",
    "            print(f\"   - Price type: {price_type}\")\n",
    "            success = download_tick(symbol, start, end, price_type, gmt_offset)\n",
    "        else:\n",
    "            tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "            tf_code = CANDLE_FRAME_CODES[tf]\n",
    "            print(f\"   - Timeframe: {tf}\")\n",
    "            success = download_candles(symbol, tf_code, start, end, gmt_offset)\n",
    "\n",
    "        if success:\n",
    "            print(\"\\n✅ Download completed successfully!\")\n",
    "        else:\n",
    "            print(\"\\n❌ Download completed with errors!\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n⏹️ Download interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0293aa6-3d3f-4cec-92d1-f224551ee331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dukascopy Downloader Tool\n",
      "========================================\n",
      "\n",
      "🔹 Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Invalid date format.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Start date (e.g. 2020-01-01):  2025-01-01\n",
      "End date (e.g. 2020-01-01):  2025-01-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Configuration Summary:\n",
      "   - Symbol: XAUUSD\n",
      "   - Data type: Candlestick\n",
      "   - Date range: 2025-01-01 to 2025-01-01\n",
      "   - GMT offset: 0\n",
      "   - Save path: C:\\Users\\Access\\Downloads\n",
      "\n",
      "🔹 Select timeframe\n",
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Timeframe: 1h\n",
      "\n",
      "🔄 Starting candle download for XAUUSD...\n",
      "📅 Date range: 2025-01-01 to 2025-01-01\n",
      "⏰ GMT offset: 0\n",
      "📊 Timeframe code: 3600\n",
      "[==================================================] 100.00% | 0.0MB of 0.0MB | ETA: 0h 0m 0s\n",
      "\n",
      "📊 Download Summary:\n",
      "   - Total days processed: 1\n",
      "   - Successful downloads: 0\n",
      "   - Total candles collected: 0\n",
      "✅ File saved: C:\\Users\\Access\\Downloads\\XAUUSD_candles_3600_merged_1.csv\n",
      "📦 Size: 0.00 MB\n",
      "⚠️ No candle data was collected. File contains headers only.\n",
      "\n",
      "✅ Download completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "def get_save_path():\n",
    "    \"\"\"تحديد مسار الحفظ الآمن\"\"\"\n",
    "    possible_paths = [\n",
    "        os.path.join(os.path.expanduser(\"~\"), \"Downloads\"),  # مجلد التحميلات\n",
    "        os.path.join(os.path.expanduser(\"~\"), \"Documents\"),  # مجلد المستندات\n",
    "        os.path.expanduser(\"~\"),  # المجلد الرئيسي للمستخدم\n",
    "        os.getcwd()  # المجلد الحالي\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        try:\n",
    "            # اختبار إمكانية الكتابة\n",
    "            test_file = os.path.join(path, \"test_write.tmp\")\n",
    "            with open(test_file, \"w\") as f:\n",
    "                f.write(\"test\")\n",
    "            os.remove(test_file)\n",
    "            return path\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return os.getcwd()  # العودة للمجلد الحالي كخيار أخير\n",
    "\n",
    "DEFAULT_SAVE_PATH = get_save_path()\n",
    "CATEGORIES = {\n",
    "    \"Metals\": [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\": [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"60\", \"5m\": \"300\", \"15m\": \"900\", \"1h\": \"3600\", \"4h\": \"14400\", \"1d\": \"86400\"\n",
    "}\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            else:\n",
    "                print(\"❌ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid date format.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_safe_filename(base_path, filename):\n",
    "    \"\"\"إنشاء اسم ملف آمن مع تجنب تضارب الأسماء\"\"\"\n",
    "    full_path = os.path.join(base_path, filename)\n",
    "    if not os.path.exists(full_path):\n",
    "        return full_path\n",
    "    \n",
    "    # في حالة وجود الملف، إضافة رقم متسلسل\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    counter = 1\n",
    "    while os.path.exists(os.path.join(base_path, f\"{name}_{counter}{ext}\")):\n",
    "        counter += 1\n",
    "    return os.path.join(base_path, f\"{name}_{counter}{ext}\")\n",
    "\n",
    "def safe_file_write(filename, headers, data, encoding='utf-8'):\n",
    "    \"\"\"كتابة آمنة للملف مع معالجة أخطاء الصلاحيات\"\"\"\n",
    "    try:\n",
    "        # محاولة الكتابة في المسار المحدد\n",
    "        with open(filename, \"w\", newline='', encoding=encoding) as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(headers)\n",
    "            if data:\n",
    "                writer.writerows(data)\n",
    "        return filename, True, None\n",
    "        \n",
    "    except PermissionError:\n",
    "        # محاولة الحفظ في مجلد التحميلات\n",
    "        downloads_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "        try:\n",
    "            os.makedirs(downloads_path, exist_ok=True)\n",
    "            alt_filename = os.path.join(downloads_path, os.path.basename(filename))\n",
    "            alt_filename = get_safe_filename(downloads_path, os.path.basename(filename))\n",
    "            \n",
    "            with open(alt_filename, \"w\", newline='', encoding=encoding) as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(headers)\n",
    "                if data:\n",
    "                    writer.writerows(data)\n",
    "            return alt_filename, True, \"Saved to Downloads folder due to permission issue\"\n",
    "            \n",
    "        except Exception as e2:\n",
    "            # محاولة الحفظ في سطح المكتب\n",
    "            try:\n",
    "                desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "                os.makedirs(desktop_path, exist_ok=True)\n",
    "                desktop_filename = os.path.join(desktop_path, os.path.basename(filename))\n",
    "                desktop_filename = get_safe_filename(desktop_path, os.path.basename(filename))\n",
    "                \n",
    "                with open(desktop_filename, \"w\", newline='', encoding=encoding) as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(headers)\n",
    "                    if data:\n",
    "                        writer.writerows(data)\n",
    "                return desktop_filename, True, \"Saved to Desktop due to permission issue\"\n",
    "                \n",
    "            except Exception as e3:\n",
    "                return filename, False, f\"Failed to save file: {str(e3)}\"\n",
    "                \n",
    "def format_seconds(seconds):\n",
    "    # تحويل الثواني إلى صيغة (ساعات - دقائق - ثواني)\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total)\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = progress / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percent:.2f}% | {downloaded_mb:.1f}MB of {total_est_mb:.1f}MB | ETA: {format_seconds(remaining)}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, price_type, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting tick download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    \n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{hour}h_ticks.bi5\"\n",
    "            try:\n",
    "                r = requests.get(url, timeout=15)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    successful_downloads += 1\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    try:\n",
    "                        data = lzma.decompress(r.content)\n",
    "                        for i in range(0, len(data), 20):\n",
    "                            chunk = data[i:i+20]\n",
    "                            if len(chunk) < 20: \n",
    "                                continue\n",
    "                            # فك ضغط البيانات: الترتيب الصحيح هو time_offset, ask, bid, ask_volume, bid_volume\n",
    "                            t_off, ask, bid, ask_vol, bid_vol = struct.unpack(\">IIfff\", chunk)\n",
    "                            \n",
    "                            # حساب الوقت الصحيح\n",
    "                            tick_time = day + timedelta(hours=hour, milliseconds=t_off)\n",
    "                            tick_time += timedelta(hours=gmt_offset)\n",
    "                            \n",
    "                            # تنسيق التاريخ والوقت معاً\n",
    "                            formatted_time = tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                            \n",
    "                            if price_type == \"Bid فقط\":\n",
    "                                row = [formatted_time, round(bid, 5), round(bid_vol, 2)]\n",
    "                            elif price_type == \"Ask فقط\":\n",
    "                                row = [formatted_time, round(ask, 5), round(ask_vol, 2)]\n",
    "                            else:  # كلاهما - دمج Bid و Ask\n",
    "                                row = [formatted_time, round(bid, 5), round(ask, 5), round(bid_vol, 2), round(ask_vol, 2)]\n",
    "                            \n",
    "                            all_ticks.append(row)\n",
    "                    except lzma.LZMAError as e:\n",
    "                        print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                        continue\n",
    "                elif r.status_code == 404:\n",
    "                    # البيانات غير متوفرة لهذا التاريخ/الساعة (طبيعي)\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')} {hour}h\")\n",
    "                    \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                continue\n",
    "                \n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total hours processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total ticks collected: {len(all_ticks)}\")\n",
    "\n",
    "    # حفظ الملف مع الترتيب الصحيح للأعمدة\n",
    "    base_filename = f\"{symbol}_tick_merged.csv\"\n",
    "    filename = get_safe_filename(path, base_filename)\n",
    "    \n",
    "    # تحديد رؤوس الأعمدة حسب نوع البيانات\n",
    "    if price_type == \"Bid فقط\":\n",
    "        headers = [\"datetime\", \"bid\", \"bid_volume\"]\n",
    "    elif price_type == \"Ask فقط\":\n",
    "        headers = [\"datetime\", \"ask\", \"ask_volume\"]\n",
    "    else:  # كلاهما\n",
    "        headers = [\"datetime\", \"bid\", \"ask\", \"bid_volume\", \"ask_volume\"]\n",
    "    \n",
    "    # محاولة حفظ الملف بطريقة آمنة\n",
    "    final_filename, success, message = safe_file_write(filename, headers, all_ticks if all_ticks else None)\n",
    "    \n",
    "    if success:\n",
    "        file_size = os.path.getsize(final_filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(final_filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        if message:\n",
    "            print(f\"ℹ️ Note: {message}\")\n",
    "        if not all_ticks:\n",
    "            print(\"⚠️ No tick data was collected. File contains headers only.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "        return False\n",
    "\n",
    "# ========== تحميل بيانات Candlestick ==========\n",
    "def download_candles(symbol, tf_code, start, end, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting candle download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    print(f\"📊 Timeframe code: {tf_code}\")\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{tf_code}_candles.bi5\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=15)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                successful_downloads += 1\n",
    "                downloaded_bytes += len(r.content)\n",
    "                try:\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    for i in range(0, len(data), 24):  # Changed from 20 to 24 bytes for candles\n",
    "                        chunk = data[i:i+24]\n",
    "                        if len(chunk) < 24: \n",
    "                            continue\n",
    "                        # فك ضغط البيانات للشموع\n",
    "                        utc_offset, open_, high, low, close, vol = struct.unpack(\">IIffff\", chunk[:24])\n",
    "                        \n",
    "                        # حساب الوقت الصحيح للشمعة\n",
    "                        candle_time = day + timedelta(seconds=utc_offset) + timedelta(hours=gmt_offset)\n",
    "                        \n",
    "                        # تنسيق التاريخ والوقت معاً\n",
    "                        formatted_time = candle_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        \n",
    "                        row = [formatted_time, round(open_, 5), round(high, 5),\n",
    "                               round(low, 5), round(close, 5), round(vol, 2)]\n",
    "                        all_data.append(row)\n",
    "                except lzma.LZMAError as e:\n",
    "                    print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "                    continue\n",
    "            elif r.status_code == 404:\n",
    "                # البيانات غير متوفرة لهذا التاريخ (طبيعي)\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')}\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total days processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total candles collected: {len(all_data)}\")\n",
    "\n",
    "    # حفظ الملف للشموع\n",
    "    base_filename = f\"{symbol}_candles_{tf_code}_merged.csv\"\n",
    "    filename = get_safe_filename(path, base_filename)\n",
    "    headers = [\"datetime\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    \n",
    "    # محاولة حفظ الملف بطريقة آمنة\n",
    "    final_filename, success, message = safe_file_write(filename, headers, all_data if all_data else None)\n",
    "    \n",
    "    if success:\n",
    "        file_size = os.path.getsize(final_filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(final_filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        if message:\n",
    "            print(f\"ℹ️ Note: {message}\")\n",
    "        if not all_data:\n",
    "            print(\"⚠️ No candle data was collected. File contains headers only.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "        return False\n",
    "\n",
    "# ========== تشغيل البرنامج ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 Dukascopy Downloader Tool\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    try:\n",
    "        data_type = show_menu([\"Tick\", \"Candlestick\"], \"Select data type\")\n",
    "        category = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "        symbol = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "        gmt_offset = get_gmt_offset()\n",
    "        start = get_date_input(\"Start date\")\n",
    "        end = get_date_input(\"End date\")\n",
    "\n",
    "        if start > end:\n",
    "            print(\"❌ End date must be after start date.\")\n",
    "            exit()\n",
    "\n",
    "        print(f\"\\n📝 Configuration Summary:\")\n",
    "        print(f\"   - Symbol: {symbol}\")\n",
    "        print(f\"   - Data type: {data_type}\")\n",
    "        print(f\"   - Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"   - GMT offset: {gmt_offset}\")\n",
    "        print(f\"   - Save path: {DEFAULT_SAVE_PATH}\")\n",
    "\n",
    "        success = False\n",
    "        if data_type == \"Tick\":\n",
    "            price_type = show_menu([\"Bid فقط\", \"Ask فقط\", \"كلاهما\"], \"Price type\")\n",
    "            print(f\"   - Price type: {price_type}\")\n",
    "            success = download_tick(symbol, start, end, price_type, gmt_offset)\n",
    "        else:\n",
    "            tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "            tf_code = CANDLE_FRAME_CODES[tf]\n",
    "            print(f\"   - Timeframe: {tf}\")\n",
    "            success = download_candles(symbol, tf_code, start, end, gmt_offset)\n",
    "\n",
    "        if success:\n",
    "            print(\"\\n✅ Download completed successfully!\")\n",
    "        else:\n",
    "            print(\"\\n❌ Download completed with errors!\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n⏹️ Download interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd2fb1a6-796e-47d5-b9b8-1229047846bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dukascopy Downloader Tool\n",
      "========================================\n",
      "\n",
      "🔹 Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2020-01-01\n",
      "End date (e.g. 2020-01-01):  2020-01-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Configuration Summary:\n",
      "   - Symbol: XAUUSD\n",
      "   - Data type: Candlestick\n",
      "   - Date range: 2020-01-01 to 2020-01-02\n",
      "   - GMT offset: 0\n",
      "   - Save path: C:\\Users\\Access\\Downloads\n",
      "\n",
      "🔹 Select timeframe\n",
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Timeframe: 15m\n",
      "\n",
      "🔄 Starting candle download for XAUUSD...\n",
      "📅 Date range: 2020-01-01 to 2020-01-02\n",
      "⏰ GMT offset: 0\n",
      "📊 Timeframe code: M15\n",
      "[==================================================] 100.00% | 0.0MB of 0.0MB | ETA: 0h 0m 0s\n",
      "\n",
      "📊 Download Summary:\n",
      "   - Total days processed: 2\n",
      "   - Successful downloads: 0\n",
      "   - Total candles collected: 0\n",
      "✅ File saved: C:\\Users\\Access\\Downloads\\XAUUSD_candles_M15.csv\n",
      "📦 Size: 0.00 MB\n",
      "⚠️ No candle data was collected. File contains headers only.\n",
      "\n",
      "✅ Download completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "def get_save_path():\n",
    "    \"\"\"تحديد مسار الحفظ الآمن\"\"\"\n",
    "    possible_paths = [\n",
    "        os.path.join(os.path.expanduser(\"~\"), \"Downloads\"),  # مجلد التحميلات\n",
    "        os.path.join(os.path.expanduser(\"~\"), \"Documents\"),  # مجلد المستندات\n",
    "        os.path.expanduser(\"~\"),  # المجلد الرئيسي للمستخدم\n",
    "        os.getcwd()  # المجلد الحالي\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        try:\n",
    "            # اختبار إمكانية الكتابة\n",
    "            test_file = os.path.join(path, \"test_write.tmp\")\n",
    "            with open(test_file, \"w\") as f:\n",
    "                f.write(\"test\")\n",
    "            os.remove(test_file)\n",
    "            return path\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return os.getcwd()  # العودة للمجلد الحالي كخيار أخير\n",
    "\n",
    "DEFAULT_SAVE_PATH = get_save_path()\n",
    "CATEGORIES = {\n",
    "    \"Metals\": [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\": [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"M1\", \"5m\": \"M5\", \"15m\": \"M15\", \"1h\": \"H1\", \"4h\": \"H4\", \"1d\": \"D1\"\n",
    "}\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            else:\n",
    "                print(\"❌ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid date format.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_safe_filename(base_path, filename):\n",
    "    \"\"\"إنشاء اسم ملف آمن مع تجنب تضارب الأسماء\"\"\"\n",
    "    full_path = os.path.join(base_path, filename)\n",
    "    if not os.path.exists(full_path):\n",
    "        return full_path\n",
    "    \n",
    "    # في حالة وجود الملف، إضافة رقم متسلسل\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    counter = 1\n",
    "    while os.path.exists(os.path.join(base_path, f\"{name}_{counter}{ext}\")):\n",
    "        counter += 1\n",
    "    return os.path.join(base_path, f\"{name}_{counter}{ext}\")\n",
    "\n",
    "def safe_file_write(filename, headers, data, encoding='utf-8'):\n",
    "    \"\"\"كتابة آمنة للملف مع معالجة أخطاء الصلاحيات\"\"\"\n",
    "    try:\n",
    "        # محاولة الكتابة في المسار المحدد\n",
    "        with open(filename, \"w\", newline='', encoding=encoding) as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(headers)\n",
    "            if data:\n",
    "                writer.writerows(data)\n",
    "        return filename, True, None\n",
    "        \n",
    "    except PermissionError:\n",
    "        # محاولة الحفظ في مجلد التحميلات\n",
    "        downloads_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "        try:\n",
    "            os.makedirs(downloads_path, exist_ok=True)\n",
    "            alt_filename = os.path.join(downloads_path, os.path.basename(filename))\n",
    "            alt_filename = get_safe_filename(downloads_path, os.path.basename(filename))\n",
    "            \n",
    "            with open(alt_filename, \"w\", newline='', encoding=encoding) as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(headers)\n",
    "                if data:\n",
    "                    writer.writerows(data)\n",
    "            return alt_filename, True, \"Saved to Downloads folder due to permission issue\"\n",
    "            \n",
    "        except Exception as e2:\n",
    "            # محاولة الحفظ في سطح المكتب\n",
    "            try:\n",
    "                desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "                os.makedirs(desktop_path, exist_ok=True)\n",
    "                desktop_filename = os.path.join(desktop_path, os.path.basename(filename))\n",
    "                desktop_filename = get_safe_filename(desktop_path, os.path.basename(filename))\n",
    "                \n",
    "                with open(desktop_filename, \"w\", newline='', encoding=encoding) as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(headers)\n",
    "                    if data:\n",
    "                        writer.writerows(data)\n",
    "                return desktop_filename, True, \"Saved to Desktop due to permission issue\"\n",
    "                \n",
    "            except Exception as e3:\n",
    "                return filename, False, f\"Failed to save file: {str(e3)}\"\n",
    "                \n",
    "def format_seconds(seconds):\n",
    "    # تحويل الثواني إلى صيغة (ساعات - دقائق - ثواني)\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total)\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = progress / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percent:.2f}% | {downloaded_mb:.1f}MB of {total_est_mb:.1f}MB | ETA: {format_seconds(remaining)}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, price_type, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting tick download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    \n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{hour:02d}h_ticks.bi5\"\n",
    "            try:\n",
    "                r = requests.get(url, timeout=15)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    successful_downloads += 1\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    try:\n",
    "                        data = lzma.decompress(r.content)\n",
    "                        # كل tick يحتوي على 20 بايت: 4 بايت للوقت + 4*4 بايت للأسعار والحجم\n",
    "                        for i in range(0, len(data), 20):\n",
    "                            chunk = data[i:i+20]\n",
    "                            if len(chunk) < 20: \n",
    "                                continue\n",
    "                            \n",
    "                            # فك البيانات: time_delta(ms), ask, bid, ask_volume, bid_volume\n",
    "                            try:\n",
    "                                time_delta, ask, bid, ask_vol, bid_vol = struct.unpack(\">Iffff\", chunk)\n",
    "                                \n",
    "                                # تحويل القيم من الوحدات الصغيرة إلى الأسعار الحقيقية\n",
    "                                # Dukascopy يخزن الأسعار مقسومة على 100000\n",
    "                                if symbol in [\"USDJPY\", \"EURJPY\", \"GBPJPY\", \"AUDJPY\", \"NZDJPY\", \"CADJPY\", \"CHFJPY\"]:\n",
    "                                    # أزواج الين لها 3 خانات عشرية\n",
    "                                    ask = ask / 1000\n",
    "                                    bid = bid / 1000\n",
    "                                else:\n",
    "                                    # باقي الأزواج لها 5 خانات عشرية\n",
    "                                    ask = ask / 100000\n",
    "                                    bid = bid / 100000\n",
    "                                \n",
    "                                # حساب الوقت الصحيح\n",
    "                                tick_time = day.replace(hour=hour) + timedelta(milliseconds=time_delta)\n",
    "                                tick_time += timedelta(hours=gmt_offset)\n",
    "                                \n",
    "                                # تنسيق التاريخ والوقت معاً\n",
    "                                formatted_time = tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                                \n",
    "                                if price_type == \"Bid فقط\":\n",
    "                                    row = [formatted_time, round(bid, 5), round(bid_vol, 2)]\n",
    "                                elif price_type == \"Ask فقط\":\n",
    "                                    row = [formatted_time, round(ask, 5), round(ask_vol, 2)]\n",
    "                                else:  # كلاهما - دمج Bid و Ask\n",
    "                                    row = [formatted_time, round(bid, 5), round(ask, 5), round(bid_vol, 2), round(ask_vol, 2)]\n",
    "                                \n",
    "                                all_ticks.append(row)\n",
    "                            except struct.error as se:\n",
    "                                print(f\"\\n⚠️ Struct error: {se} for chunk length {len(chunk)}\")\n",
    "                                continue\n",
    "                                \n",
    "                    except lzma.LZMAError as e:\n",
    "                        print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')} {hour:02d}h: {e}\")\n",
    "                        continue\n",
    "                elif r.status_code == 404:\n",
    "                    # البيانات غير متوفرة لهذا التاريخ/الساعة (طبيعي)\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')} {hour:02d}h\")\n",
    "                    \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')} {hour:02d}h: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')} {hour:02d}h: {e}\")\n",
    "                continue\n",
    "                \n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total hours processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total ticks collected: {len(all_ticks)}\")\n",
    "\n",
    "    # حفظ الملف مع الترتيب الصحيح للأعمدة\n",
    "    base_filename = f\"{symbol}_tick_{price_type.replace(' ', '_').replace('فقط', 'only').replace('كلاهما', 'both')}.csv\"\n",
    "    filename = get_safe_filename(path, base_filename)\n",
    "    \n",
    "    # تحديد رؤوس الأعمدة حسب نوع البيانات\n",
    "    if price_type == \"Bid فقط\":\n",
    "        headers = [\"datetime\", \"bid\", \"bid_volume\"]\n",
    "    elif price_type == \"Ask فقط\":\n",
    "        headers = [\"datetime\", \"ask\", \"ask_volume\"]\n",
    "    else:  # كلاهما\n",
    "        headers = [\"datetime\", \"bid\", \"ask\", \"bid_volume\", \"ask_volume\"]\n",
    "    \n",
    "    # محاولة حفظ الملف بطريقة آمنة\n",
    "    final_filename, success, message = safe_file_write(filename, headers, all_ticks if all_ticks else None)\n",
    "    \n",
    "    if success:\n",
    "        file_size = os.path.getsize(final_filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(final_filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        if message:\n",
    "            print(f\"ℹ️ Note: {message}\")\n",
    "        if not all_ticks:\n",
    "            print(\"⚠️ No tick data was collected. File contains headers only.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "        return False\n",
    "\n",
    "# ========== تحميل بيانات Candlestick ==========\n",
    "def download_candles(symbol, tf_code, start, end, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting candle download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    print(f\"📊 Timeframe code: {tf_code}\")\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{tf_code}_candles.bi5\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=15)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                successful_downloads += 1\n",
    "                downloaded_bytes += len(r.content)\n",
    "                try:\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    # كل شمعة تحتوي على 24 بايت: 4 للوقت + 5*4 للأسعار والحجم\n",
    "                    for i in range(0, len(data), 24):\n",
    "                        chunk = data[i:i+24]\n",
    "                        if len(chunk) < 24: \n",
    "                            continue\n",
    "                        \n",
    "                        try:\n",
    "                            # فك ضغط البيانات للشموع: time, open, high, low, close, volume\n",
    "                            time_offset, open_price, high_price, low_price, close_price, volume = struct.unpack(\">Ifffff\", chunk)\n",
    "                            \n",
    "                            # تحويل القيم من الوحدات الصغيرة إلى الأسعار الحقيقية\n",
    "                            if symbol in [\"USDJPY\", \"EURJPY\", \"GBPJPY\", \"AUDJPY\", \"NZDJPY\", \"CADJPY\", \"CHFJPY\"]:\n",
    "                                # أزواج الين لها 3 خانات عشرية\n",
    "                                open_price = open_price / 1000\n",
    "                                high_price = high_price / 1000\n",
    "                                low_price = low_price / 1000\n",
    "                                close_price = close_price / 1000\n",
    "                            else:\n",
    "                                # باقي الأزواج لها 5 خانات عشرية\n",
    "                                open_price = open_price / 100000\n",
    "                                high_price = high_price / 100000\n",
    "                                low_price = low_price / 100000\n",
    "                                close_price = close_price / 100000\n",
    "                            \n",
    "                            # حساب الوقت الصحيح للشمعة\n",
    "                            candle_time = day + timedelta(seconds=time_offset) + timedelta(hours=gmt_offset)\n",
    "                            \n",
    "                            # تنسيق التاريخ والوقت معاً\n",
    "                            formatted_time = candle_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                            \n",
    "                            row = [formatted_time, round(open_price, 5), round(high_price, 5),\n",
    "                                   round(low_price, 5), round(close_price, 5), round(volume, 2)]\n",
    "                            all_data.append(row)\n",
    "                        except struct.error as se:\n",
    "                            print(f\"\\n⚠️ Struct error: {se} for chunk length {len(chunk)}\")\n",
    "                            continue\n",
    "                            \n",
    "                except lzma.LZMAError as e:\n",
    "                    print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "                    continue\n",
    "            elif r.status_code == 404:\n",
    "                # البيانات غير متوفرة لهذا التاريخ (طبيعي)\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')}\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total days processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total candles collected: {len(all_data)}\")\n",
    "\n",
    "    # حفظ الملف للشموع\n",
    "    base_filename = f\"{symbol}_candles_{tf_code}.csv\"\n",
    "    filename = get_safe_filename(path, base_filename)\n",
    "    headers = [\"datetime\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    \n",
    "    # محاولة حفظ الملف بطريقة آمنة\n",
    "    final_filename, success, message = safe_file_write(filename, headers, all_data if all_data else None)\n",
    "    \n",
    "    if success:\n",
    "        file_size = os.path.getsize(final_filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(final_filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        if message:\n",
    "            print(f\"ℹ️ Note: {message}\")\n",
    "        if not all_data:\n",
    "            print(\"⚠️ No candle data was collected. File contains headers only.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "        return False\n",
    "\n",
    "# ========== تشغيل البرنامج ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 Dukascopy Downloader Tool\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    try:\n",
    "        data_type = show_menu([\"Tick\", \"Candlestick\"], \"Select data type\")\n",
    "        category = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "        symbol = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "        gmt_offset = get_gmt_offset()\n",
    "        start = get_date_input(\"Start date\")\n",
    "        end = get_date_input(\"End date\")\n",
    "\n",
    "        if start > end:\n",
    "            print(\"❌ End date must be after start date.\")\n",
    "            exit()\n",
    "\n",
    "        print(f\"\\n📝 Configuration Summary:\")\n",
    "        print(f\"   - Symbol: {symbol}\")\n",
    "        print(f\"   - Data type: {data_type}\")\n",
    "        print(f\"   - Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"   - GMT offset: {gmt_offset}\")\n",
    "        print(f\"   - Save path: {DEFAULT_SAVE_PATH}\")\n",
    "\n",
    "        success = False\n",
    "        if data_type == \"Tick\":\n",
    "            price_type = show_menu([\"Bid فقط\", \"Ask فقط\", \"كلاهما\"], \"Price type\")\n",
    "            print(f\"   - Price type: {price_type}\")\n",
    "            success = download_tick(symbol, start, end, price_type, gmt_offset)\n",
    "        else:\n",
    "            tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "            tf_code = CANDLE_FRAME_CODES[tf]\n",
    "            print(f\"   - Timeframe: {tf}\")\n",
    "            success = download_candles(symbol, tf_code, start, end, gmt_offset)\n",
    "\n",
    "        if success:\n",
    "            print(\"\\n✅ Download completed successfully!\")\n",
    "        else:\n",
    "            print(\"\\n❌ Download completed with errors!\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n⏹️ Download interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f47087d-1669-40fb-b9cd-02428ccc5a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dukascopy Downloader Tool\n",
      "\n",
      "🔹 Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2020-01-01\n",
      "End date (e.g. 2020-01-01):  2020-01-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select timeframe\n",
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.00% | 0.0MB of 0.0MB | ETA: 0h 0m 0s\n",
      "✅ Download completed!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "# يتم الحفظ داخل مجلد Jupyter الحالي\n",
    "DEFAULT_SAVE_PATH = os.getcwd()\n",
    "\n",
    "CATEGORIES = {\n",
    "    \"Metals\": [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\": [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"60\", \"5m\": \"300\", \"15m\": \"900\", \"1h\": \"3600\", \"4h\": \"14400\", \"1d\": \"86400\"\n",
    "}\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            else:\n",
    "                print(\"❌ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid date format.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def format_seconds(seconds):\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total)\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = progress / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percent:.2f}% | {downloaded_mb:.1f}MB of {total_est_mb:.1f}MB | ETA: {format_seconds(remaining)}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, price_type, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{hour}h_ticks.bi5\"\n",
    "            try:\n",
    "                r = requests.get(url, timeout=10)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    for i in range(0, len(data), 20):\n",
    "                        chunk = data[i:i+20]\n",
    "                        if len(chunk) < 20: continue\n",
    "                        t_off, ask, bid, ask_vol, bid_vol = struct.unpack(\" >IIfff\", chunk)\n",
    "                        tick_time = day + timedelta(hours=hour, milliseconds=t_off)\n",
    "                        tick_time += timedelta(hours=gmt_offset)\n",
    "                        row = [tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]]\n",
    "                        if price_type == \"Bid فقط\":\n",
    "                            row += [round(bid, 5), round(bid_vol, 2)]\n",
    "                        elif price_type == \"Ask فقط\":\n",
    "                            row += [round(ask, 5), round(ask_vol, 2)]\n",
    "                        else:\n",
    "                            row += [round(bid, 5), round(ask, 5), round(bid_vol, 2), round(ask_vol, 2)]\n",
    "                        all_ticks.append(row)\n",
    "            except:\n",
    "                pass\n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    if all_ticks:\n",
    "        filename = os.path.join(path, f\"{symbol}_tick_merged.csv\")\n",
    "        with open(filename, \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if price_type == \"Bid فقط\":\n",
    "                writer.writerow([\"time\", \"bid\", \"bid_vol\"])\n",
    "            elif price_type == \"Ask فقط\":\n",
    "                writer.writerow([\"time\", \"ask\", \"ask_vol\"])\n",
    "            else:\n",
    "                writer.writerow([\"time\", \"bid\", \"ask\", \"bid_vol\", \"ask_vol\"])\n",
    "            all_ticks.sort(key=lambda x: x[0])\n",
    "            writer.writerows(all_ticks)\n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"\\n✅ File saved: {os.path.abspath(filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "\n",
    "# ========== تحميل بيانات الشموع ==========\n",
    "def download_candles(symbol, tf_code, start, end, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{tf_code}_candles.bi5\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                downloaded_bytes += len(r.content)\n",
    "                data = lzma.decompress(r.content)\n",
    "                for i in range(0, len(data), 20):\n",
    "                    chunk = data[i:i+20]\n",
    "                    if len(chunk) < 20: continue\n",
    "                    utc_offset, open_, high, low, close, vol = struct.unpack(\">IIffff\", chunk[:20])\n",
    "                    candle_time = day + timedelta(seconds=utc_offset) + timedelta(hours=gmt_offset)\n",
    "                    row = [candle_time.strftime(\"%Y-%m-%d %H:%M:%S\"), round(open_, 5), round(high, 5),\n",
    "                           round(low, 5), round(close, 5), round(vol, 2)]\n",
    "                    all_data.append(row)\n",
    "        except:\n",
    "            pass\n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    if all_data:\n",
    "        filename = os.path.join(path, f\"{symbol}_candles_{tf_code}_merged.csv\")\n",
    "        with open(filename, \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "            all_data.sort(key=lambda x: x[0])\n",
    "            writer.writerows(all_data)\n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"\\n✅ File saved: {os.path.abspath(filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "\n",
    "# ========== تشغيل البرنامج ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 Dukascopy Downloader Tool\")\n",
    "\n",
    "    data_type = show_menu([\"Tick\", \"Candlestick\"], \"Select data type\")\n",
    "    category = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "    symbol = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "    gmt_offset = get_gmt_offset()\n",
    "    start = get_date_input(\"Start date\")\n",
    "    end = get_date_input(\"End date\")\n",
    "\n",
    "    if start > end:\n",
    "        print(\"❌ End date must be after start date.\")\n",
    "        exit()\n",
    "\n",
    "    if data_type == \"Tick\":\n",
    "        price_type = show_menu([\"Bid فقط\", \"Ask فقط\", \"كلاهما\"], \"Price type\")\n",
    "        download_tick(symbol, start, end, price_type, gmt_offset)\n",
    "    else:\n",
    "        tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "        tf_code = CANDLE_FRAME_CODES[tf]\n",
    "        download_candles(symbol, tf_code, start, end, gmt_offset)\n",
    "\n",
    "    print(\"\\n✅ Download completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45e85a96-db5b-4135-926d-6fb9a7e067d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dukascopy Downloader Tool - Enhanced Version\n",
      "==================================================\n",
      "\n",
      "🔹 Select action\n",
      "1. Download New Data\n",
      "2. View Previous Downloads\n",
      "3. Merge Files\n",
      "4. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2020-01-01\n",
      "End date (e.g. 2020-01-01):  2020-01-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Configuration Summary:\n",
      "   - Symbol: XAUUSD\n",
      "   - Data type: Candlestick\n",
      "   - Date range: 2020-01-01 to 2020-01-02\n",
      "   - GMT offset: 0\n",
      "   - Save path: C:\\Users\\Access\\Downloads\n",
      "\n",
      "🔹 Select timeframe\n",
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Timeframe: 15m\n",
      "   - Columns: datetime, open_price, high_price, low_price, close_price, volume\n",
      "\n",
      "🔄 Starting candle download for XAUUSD...\n",
      "📅 Date range: 2020-01-01 to 2020-01-02\n",
      "⏰ GMT offset: 0\n",
      "📊 Timeframe code: M15\n",
      "📊 Column structure: datetime, open_price, high_price, low_price, close_price, volume\n",
      "[==================================================] 100.00% | 0.0MB of 0.0MB | ETA: 0h 0m 0s\n",
      "\n",
      "📊 Download Summary:\n",
      "   - Total days processed: 2\n",
      "   - Successful downloads: 0\n",
      "   - Total candles collected: 0\n",
      "✅ File saved: C:\\Users\\Access\\Downloads\\XAUUSD_candles_15m_20200101_20200102.csv\n",
      "📦 Size: 0.00 MB\n",
      "⚠️ No candle data was collected. File contains headers only.\n",
      "📋 Metadata saved to: C:\\Users\\Access\\Downloads\\downloads_metadata.json\n",
      "\n",
      "✅ Download completed successfully!\n",
      "\n",
      "💡 Tip: You can now use 'Merge Files' option to combine multiple downloads.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "def get_save_path():\n",
    "    \"\"\"تحديد مسار الحفظ الآمن\"\"\"\n",
    "    possible_paths = [\n",
    "        os.path.join(os.path.expanduser(\"~\"), \"Downloads\"),  # مجلد التحميلات\n",
    "        os.path.join(os.path.expanduser(\"~\"), \"Documents\"),  # مجلد المستندات\n",
    "        os.path.expanduser(\"~\"),  # المجلد الرئيسي للمستخدم\n",
    "        os.getcwd()  # المجلد الحالي\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        try:\n",
    "            # اختبار إمكانية الكتابة\n",
    "            test_file = os.path.join(path, \"test_write.tmp\")\n",
    "            with open(test_file, \"w\") as f:\n",
    "                f.write(\"test\")\n",
    "            os.remove(test_file)\n",
    "            return path\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return os.getcwd()  # العودة للمجلد الحالي كخيار أخير\n",
    "\n",
    "DEFAULT_SAVE_PATH = get_save_path()\n",
    "CATEGORIES = {\n",
    "    \"Metals\": [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\": [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"M1\", \"5m\": \"M5\", \"15m\": \"M15\", \"1h\": \"H1\", \"4h\": \"H4\", \"1d\": \"D1\"\n",
    "}\n",
    "\n",
    "# ========== تعريف ثابت لأسماء الأعمدة ==========\n",
    "COLUMN_SCHEMAS = {\n",
    "    \"tick_bid\": [\"datetime\", \"bid_price\", \"bid_volume\"],\n",
    "    \"tick_ask\": [\"datetime\", \"ask_price\", \"ask_volume\"], \n",
    "    \"tick_both\": [\"datetime\", \"bid_price\", \"ask_price\", \"bid_volume\", \"ask_volume\"],\n",
    "    \"candles\": [\"datetime\", \"open_price\", \"high_price\", \"low_price\", \"close_price\", \"volume\"]\n",
    "}\n",
    "\n",
    "# ========== إدارة الملفات المحملة ==========\n",
    "def save_download_metadata(symbol, data_type, start_date, end_date, filename, columns, price_type=None, timeframe=None):\n",
    "    \"\"\"حفظ معلومات التحميل في ملف منفصل لتتبع الأعمدة\"\"\"\n",
    "    metadata_file = os.path.join(DEFAULT_SAVE_PATH, \"downloads_metadata.json\")\n",
    "    \n",
    "    metadata = {\n",
    "        \"symbol\": symbol,\n",
    "        \"data_type\": data_type,\n",
    "        \"start_date\": start_date.isoformat(),\n",
    "        \"end_date\": end_date.isoformat(),\n",
    "        \"filename\": os.path.basename(filename),\n",
    "        \"full_path\": os.path.abspath(filename),\n",
    "        \"columns\": columns,\n",
    "        \"download_timestamp\": datetime.now().isoformat(),\n",
    "        \"price_type\": price_type,\n",
    "        \"timeframe\": timeframe\n",
    "    }\n",
    "    \n",
    "    # قراءة البيانات الموجودة\n",
    "    existing_data = []\n",
    "    if os.path.exists(metadata_file):\n",
    "        try:\n",
    "            with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "                existing_data = json.load(f)\n",
    "        except:\n",
    "            existing_data = []\n",
    "    \n",
    "    # إضافة البيانات الجديدة\n",
    "    existing_data.append(metadata)\n",
    "    \n",
    "    # حفظ البيانات المحدثة\n",
    "    try:\n",
    "        with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(existing_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"📋 Metadata saved to: {metadata_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning: Could not save metadata: {e}\")\n",
    "\n",
    "def load_download_metadata():\n",
    "    \"\"\"قراءة معلومات التحميلات السابقة\"\"\"\n",
    "    metadata_file = os.path.join(DEFAULT_SAVE_PATH, \"downloads_metadata.json\")\n",
    "    if os.path.exists(metadata_file):\n",
    "        try:\n",
    "            with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def show_previous_downloads():\n",
    "    \"\"\"عرض التحميلات السابقة\"\"\"\n",
    "    metadata = load_download_metadata()\n",
    "    if not metadata:\n",
    "        print(\"📂 No previous downloads found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n📂 Previous Downloads:\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, item in enumerate(metadata, 1):\n",
    "        print(f\"{i}. {item['symbol']} - {item['data_type']}\")\n",
    "        print(f\"   📅 Date: {item['start_date']} to {item['end_date']}\")\n",
    "        print(f\"   📄 File: {item['filename']}\")\n",
    "        print(f\"   📊 Columns: {', '.join(item['columns'])}\")\n",
    "        if item.get('price_type'):\n",
    "            print(f\"   💰 Price Type: {item['price_type']}\")\n",
    "        if item.get('timeframe'):\n",
    "            print(f\"   ⏱️ Timeframe: {item['timeframe']}\")\n",
    "        print(f\"   📁 Path: {item['full_path']}\")\n",
    "        print()\n",
    "\n",
    "def get_standardized_columns(data_type, price_type=None):\n",
    "    \"\"\"الحصول على أسماء الأعمدة المعيارية\"\"\"\n",
    "    if data_type == \"Tick\":\n",
    "        if price_type == \"Bid فقط\":\n",
    "            return COLUMN_SCHEMAS[\"tick_bid\"]\n",
    "        elif price_type == \"Ask فقط\":\n",
    "            return COLUMN_SCHEMAS[\"tick_ask\"]\n",
    "        else:  # كلاهما\n",
    "            return COLUMN_SCHEMAS[\"tick_both\"]\n",
    "    else:  # Candlestick\n",
    "        return COLUMN_SCHEMAS[\"candles\"]\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            else:\n",
    "                print(\"❌ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid date format.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_safe_filename(base_path, filename):\n",
    "    \"\"\"إنشاء اسم ملف آمن مع تجنب تضارب الأسماء\"\"\"\n",
    "    full_path = os.path.join(base_path, filename)\n",
    "    if not os.path.exists(full_path):\n",
    "        return full_path\n",
    "    \n",
    "    # في حالة وجود الملف، إضافة رقم متسلسل\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    counter = 1\n",
    "    while os.path.exists(os.path.join(base_path, f\"{name}_{counter}{ext}\")):\n",
    "        counter += 1\n",
    "    return os.path.join(base_path, f\"{name}_{counter}{ext}\")\n",
    "\n",
    "def safe_file_write(filename, headers, data, encoding='utf-8'):\n",
    "    \"\"\"كتابة آمنة للملف مع معالجة أخطاء الصلاحيات\"\"\"\n",
    "    try:\n",
    "        # محاولة الكتابة في المسار المحدد\n",
    "        with open(filename, \"w\", newline='', encoding=encoding) as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(headers)\n",
    "            if data:\n",
    "                writer.writerows(data)\n",
    "        return filename, True, None\n",
    "        \n",
    "    except PermissionError:\n",
    "        # محاولة الحفظ في مجلد التحميلات\n",
    "        downloads_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "        try:\n",
    "            os.makedirs(downloads_path, exist_ok=True)\n",
    "            alt_filename = os.path.join(downloads_path, os.path.basename(filename))\n",
    "            alt_filename = get_safe_filename(downloads_path, os.path.basename(filename))\n",
    "            \n",
    "            with open(alt_filename, \"w\", newline='', encoding=encoding) as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(headers)\n",
    "                if data:\n",
    "                    writer.writerows(data)\n",
    "            return alt_filename, True, \"Saved to Downloads folder due to permission issue\"\n",
    "            \n",
    "        except Exception as e2:\n",
    "            # محاولة الحفظ في سطح المكتب\n",
    "            try:\n",
    "                desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "                os.makedirs(desktop_path, exist_ok=True)\n",
    "                desktop_filename = os.path.join(desktop_path, os.path.basename(filename))\n",
    "                desktop_filename = get_safe_filename(desktop_path, os.path.basename(filename))\n",
    "                \n",
    "                with open(desktop_filename, \"w\", newline='', encoding=encoding) as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(headers)\n",
    "                    if data:\n",
    "                        writer.writerows(data)\n",
    "                return desktop_filename, True, \"Saved to Desktop due to permission issue\"\n",
    "                \n",
    "            except Exception as e3:\n",
    "                return filename, False, f\"Failed to save file: {str(e3)}\"\n",
    "                \n",
    "def format_seconds(seconds):\n",
    "    # تحويل الثواني إلى صيغة (ساعات - دقائق - ثواني)\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total)\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = progress / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percent:.2f}% | {downloaded_mb:.1f}MB of {total_est_mb:.1f}MB | ETA: {format_seconds(remaining)}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, price_type, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting tick download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    \n",
    "    # الحصول على أسماء الأعمدة المعيارية\n",
    "    headers = get_standardized_columns(\"Tick\", price_type)\n",
    "    print(f\"📊 Column structure: {', '.join(headers)}\")\n",
    "    \n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{hour:02d}h_ticks.bi5\"\n",
    "            try:\n",
    "                r = requests.get(url, timeout=15)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    successful_downloads += 1\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    try:\n",
    "                        data = lzma.decompress(r.content)\n",
    "                        # كل tick يحتوي على 20 بايت: 4 بايت للوقت + 4*4 بايت للأسعار والحجم\n",
    "                        for i in range(0, len(data), 20):\n",
    "                            chunk = data[i:i+20]\n",
    "                            if len(chunk) < 20: \n",
    "                                continue\n",
    "                            \n",
    "                            # فك البيانات: time_delta(ms), ask, bid, ask_volume, bid_volume\n",
    "                            try:\n",
    "                                time_delta, ask, bid, ask_vol, bid_vol = struct.unpack(\">Iffff\", chunk)\n",
    "                                \n",
    "                                # تحويل القيم من الوحدات الصغيرة إلى الأسعار الحقيقية\n",
    "                                # Dukascopy يخزن الأسعار مقسومة على 100000\n",
    "                                if symbol in [\"USDJPY\", \"EURJPY\", \"GBPJPY\", \"AUDJPY\", \"NZDJPY\", \"CADJPY\", \"CHFJPY\"]:\n",
    "                                    # أزواج الين لها 3 خانات عشرية\n",
    "                                    ask = ask / 1000\n",
    "                                    bid = bid / 1000\n",
    "                                else:\n",
    "                                    # باقي الأزواج لها 5 خانات عشرية\n",
    "                                    ask = ask / 100000\n",
    "                                    bid = bid / 100000\n",
    "                                \n",
    "                                # حساب الوقت الصحيح\n",
    "                                tick_time = day.replace(hour=hour) + timedelta(milliseconds=time_delta)\n",
    "                                tick_time += timedelta(hours=gmt_offset)\n",
    "                                \n",
    "                                # تنسيق التاريخ والوقت معاً\n",
    "                                formatted_time = tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                                \n",
    "                                # ترتيب البيانات حسب الأعمدة المعيارية\n",
    "                                if price_type == \"Bid فقط\":\n",
    "                                    row = [formatted_time, round(bid, 5), round(bid_vol, 2)]\n",
    "                                elif price_type == \"Ask فقط\":\n",
    "                                    row = [formatted_time, round(ask, 5), round(ask_vol, 2)]\n",
    "                                else:  # كلاهما - دمج Bid و Ask\n",
    "                                    row = [formatted_time, round(bid, 5), round(ask, 5), round(bid_vol, 2), round(ask_vol, 2)]\n",
    "                                \n",
    "                                all_ticks.append(row)\n",
    "                            except struct.error as se:\n",
    "                                print(f\"\\n⚠️ Struct error: {se} for chunk length {len(chunk)}\")\n",
    "                                continue\n",
    "                                \n",
    "                    except lzma.LZMAError as e:\n",
    "                        print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')} {hour:02d}h: {e}\")\n",
    "                        continue\n",
    "                elif r.status_code == 404:\n",
    "                    # البيانات غير متوفرة لهذا التاريخ/الساعة (طبيعي)\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')} {hour:02d}h\")\n",
    "                    \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')} {hour:02d}h: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')} {hour:02d}h: {e}\")\n",
    "                continue\n",
    "                \n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total hours processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total ticks collected: {len(all_ticks)}\")\n",
    "\n",
    "    # حفظ الملف مع اسم موحد\n",
    "    price_type_code = {\n",
    "        \"Bid فقط\": \"bid\",\n",
    "        \"Ask فقط\": \"ask\", \n",
    "        \"كلاهما\": \"both\"\n",
    "    }[price_type]\n",
    "    \n",
    "    base_filename = f\"{symbol}_tick_{price_type_code}_{start.strftime('%Y%m%d')}_{end.strftime('%Y%m%d')}.csv\"\n",
    "    filename = get_safe_filename(path, base_filename)\n",
    "    \n",
    "    # محاولة حفظ الملف بطريقة آمنة\n",
    "    final_filename, success, message = safe_file_write(filename, headers, all_ticks if all_ticks else None)\n",
    "    \n",
    "    if success:\n",
    "        file_size = os.path.getsize(final_filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(final_filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        if message:\n",
    "            print(f\"ℹ️ Note: {message}\")\n",
    "        if not all_ticks:\n",
    "            print(\"⚠️ No tick data was collected. File contains headers only.\")\n",
    "        \n",
    "        # حفظ معلومات التحميل\n",
    "        save_download_metadata(symbol, \"Tick\", start, end, final_filename, headers, price_type)\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "        return False\n",
    "\n",
    "# ========== تحميل بيانات Candlestick ==========\n",
    "def download_candles(symbol, tf_code, timeframe, start, end, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting candle download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    print(f\"📊 Timeframe code: {tf_code}\")\n",
    "\n",
    "    # الحصول على أسماء الأعمدة المعيارية\n",
    "    headers = get_standardized_columns(\"Candlestick\")\n",
    "    print(f\"📊 Column structure: {', '.join(headers)}\")\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{tf_code}_candles.bi5\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=15)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                successful_downloads += 1\n",
    "                downloaded_bytes += len(r.content)\n",
    "                try:\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    # كل شمعة تحتوي على 24 بايت: 4 للوقت + 5*4 للأسعار والحجم\n",
    "                    for i in range(0, len(data), 24):\n",
    "                        chunk = data[i:i+24]\n",
    "                        if len(chunk) < 24: \n",
    "                            continue\n",
    "                        \n",
    "                        try:\n",
    "                            # فك ضغط البيانات للشموع: time, open, high, low, close, volume\n",
    "                            time_offset, open_price, high_price, low_price, close_price, volume = struct.unpack(\">Ifffff\", chunk)\n",
    "                            \n",
    "                            # تحويل القيم من الوحدات الصغيرة إلى الأسعار الحقيقية\n",
    "                            if symbol in [\"USDJPY\", \"EURJPY\", \"GBPJPY\", \"AUDJPY\", \"NZDJPY\", \"CADJPY\", \"CHFJPY\"]:\n",
    "                                # أزواج الين لها 3 خانات عشرية\n",
    "                                open_price = open_price / 1000\n",
    "                                high_price = high_price / 1000\n",
    "                                low_price = low_price / 1000\n",
    "                                close_price = close_price / 1000\n",
    "                            else:\n",
    "                                # باقي الأزواج لها 5 خانات عشرية\n",
    "                                open_price = open_price / 100000\n",
    "                                high_price = high_price / 100000\n",
    "                                low_price = low_price / 100000\n",
    "                                close_price = close_price / 100000\n",
    "                            \n",
    "                            # حساب الوقت الصحيح للشمعة\n",
    "                            candle_time = day + timedelta(seconds=time_offset) + timedelta(hours=gmt_offset)\n",
    "                            \n",
    "                            # تنسيق التاريخ والوقت معاً\n",
    "                            formatted_time = candle_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                            \n",
    "                            # ترتيب البيانات حسب الأعمدة المعيارية\n",
    "                            row = [formatted_time, round(open_price, 5), round(high_price, 5),\n",
    "                                   round(low_price, 5), round(close_price, 5), round(volume, 2)]\n",
    "                            all_data.append(row)\n",
    "                        except struct.error as se:\n",
    "                            print(f\"\\n⚠️ Struct error: {se} for chunk length {len(chunk)}\")\n",
    "                            continue\n",
    "                            \n",
    "                except lzma.LZMAError as e:\n",
    "                    print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "                    continue\n",
    "            elif r.status_code == 404:\n",
    "                # البيانات غير متوفرة لهذا التاريخ (طبيعي)\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')}\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total days processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total candles collected: {len(all_data)}\")\n",
    "\n",
    "    # حفظ الملف للشموع مع اسم موحد\n",
    "    base_filename = f\"{symbol}_candles_{timeframe}_{start.strftime('%Y%m%d')}_{end.strftime('%Y%m%d')}.csv\"\n",
    "    filename = get_safe_filename(path, base_filename)\n",
    "    \n",
    "    # محاولة حفظ الملف بطريقة آمنة\n",
    "    final_filename, success, message = safe_file_write(filename, headers, all_data if all_data else None)\n",
    "    \n",
    "    if success:\n",
    "        file_size = os.path.getsize(final_filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(final_filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        if message:\n",
    "            print(f\"ℹ️ Note: {message}\")\n",
    "        if not all_data:\n",
    "            print(\"⚠️ No candle data was collected. File contains headers only.\")\n",
    "        \n",
    "        # حفظ معلومات التحميل\n",
    "        save_download_metadata(symbol, \"Candlestick\", start, end, final_filename, headers, timeframe=timeframe)\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "        return False\n",
    "\n",
    "# ========== دمج الملفات ==========\n",
    "def merge_files():\n",
    "    \"\"\"دمج ملفات CSV متعددة مع نفس التركيب\"\"\"\n",
    "    metadata = load_download_metadata()\n",
    "    if len(metadata) < 2:\n",
    "        print(\"❌ Need at least 2 files to merge.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n📁 Available files for merging:\")\n",
    "    for i, item in enumerate(metadata, 1):\n",
    "        print(f\"{i}. {item['filename']} - {item['symbol']} ({item['data_type']})\")\n",
    "        print(f\"   📊 Columns: {', '.join(item['columns'])}\")\n",
    "    \n",
    "    # اختيار الملفات للدمج\n",
    "    selected_files = []\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(\"\\nEnter file numbers to merge (comma-separated, e.g. 1,2,3) or 'done': \").strip()\n",
    "            if choice.lower() == 'done':\n",
    "                break\n",
    "            \n",
    "            file_indices = [int(x.strip()) - 1 for x in choice.split(',')]\n",
    "            for idx in file_indices:\n",
    "                if 0 <= idx < len(metadata):\n",
    "                    selected_files.append(metadata[idx])\n",
    "                else:\n",
    "                    print(f\"❌ Invalid file number: {idx + 1}\")\n",
    "                    \n",
    "            if len(selected_files) >= 2:\n",
    "                break\n",
    "            else:\n",
    "                print(\"❌ Select at least 2 files to merge.\")\n",
    "                selected_files = []\n",
    "                \n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid input format.\")\n",
    "    \n",
    "    if len(selected_files) < 2:\n",
    "        print(\"❌ Merge cancelled.\")\n",
    "        return\n",
    "    \n",
    "    # التحقق من توافق الأعمدة\n",
    "    first_columns = selected_files[0]['columns']\n",
    "    incompatible_files = []\n",
    "    \n",
    "    for file_info in selected_files[1:]:\n",
    "        if file_info['columns'] != first_columns:\n",
    "            incompatible_files.append(file_info['filename'])\n",
    "    \n",
    "    if incompatible_files:\n",
    "        print(f\"❌ Column mismatch detected in files: {', '.join(incompatible_files)}\")\n",
    "        print(f\"Expected columns: {', '.join(first_columns)}\")\n",
    "        for file_info in selected_files:\n",
    "            if file_info['filename'] in incompatible_files:\n",
    "                print(f\"   {file_info['filename']}: {', '.join(file_info['columns'])}\")\n",
    "        return\n",
    "    \n",
    "    # دمج الملفات\n",
    "    print(f\"\\n🔄 Merging {len(selected_files)} files...\")\n",
    "    merged_data = []\n",
    "    \n",
    "    for file_info in selected_files:\n",
    "        file_path = file_info['full_path']\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"⚠️ Warning: File not found: {file_path}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                reader = csv.reader(f)\n",
    "                header = next(reader)  # تخطي الرأس\n",
    "                data = list(reader)\n",
    "                merged_data.extend(data)\n",
    "                print(f\"   ✅ Added {len(data)} rows from {file_info['filename']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error reading {file_info['filename']}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not merged_data:\n",
    "        print(\"❌ No data to merge.\")\n",
    "        return\n",
    "    \n",
    "    # ترتيب البيانات حسب التاريخ والوقت\n",
    "    try:\n",
    "        merged_data.sort(key=lambda x: datetime.strptime(x[0], \"%Y-%m-%d %H:%M:%S.%f\" if '.' in x[0] else \"%Y-%m-%d %H:%M:%S\"))\n",
    "        print(f\"   ✅ Sorted {len(merged_data)} rows by datetime\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning: Could not sort data by datetime: {e}\")\n",
    "    \n",
    "    # حفظ الملف المدمج\n",
    "    symbols = list(set([f['symbol'] for f in selected_files]))\n",
    "    data_types = list(set([f['data_type'] for f in selected_files]))\n",
    "    \n",
    "    merged_filename = f\"merged_{'_'.join(symbols)}_{'_'.join(data_types)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    merged_path = get_safe_filename(DEFAULT_SAVE_PATH, merged_filename)\n",
    "    \n",
    "    # حفظ الملف المدمج\n",
    "    final_path, success, message = safe_file_write(merged_path, first_columns, merged_data)\n",
    "    \n",
    "    if success:\n",
    "        file_size = os.path.getsize(final_path) / (1024 * 1024)\n",
    "        print(f\"\\n✅ Merged file saved: {os.path.abspath(final_path)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        print(f\"📊 Total rows: {len(merged_data)}\")\n",
    "        if message:\n",
    "            print(f\"ℹ️ Note: {message}\")\n",
    "        \n",
    "        # حفظ معلومات الملف المدمج\n",
    "        start_dates = [datetime.fromisoformat(f['start_date']) for f in selected_files]\n",
    "        end_dates = [datetime.fromisoformat(f['end_date']) for f in selected_files]\n",
    "        \n",
    "        save_download_metadata(\n",
    "            symbol='_'.join(symbols),\n",
    "            data_type='Merged_' + '_'.join(data_types),\n",
    "            start_date=min(start_dates),\n",
    "            end_date=max(end_dates),\n",
    "            filename=final_path,\n",
    "            columns=first_columns\n",
    "        )\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "        return False\n",
    "\n",
    "# ========== تشغيل البرنامج ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 Dukascopy Downloader Tool - Enhanced Version\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        main_options = [\"Download New Data\", \"View Previous Downloads\", \"Merge Files\", \"Exit\"]\n",
    "        main_choice = show_menu(main_options, \"Select action\")\n",
    "        \n",
    "        if main_choice == \"View Previous Downloads\":\n",
    "            show_previous_downloads()\n",
    "            \n",
    "        elif main_choice == \"Merge Files\":\n",
    "            merge_files()\n",
    "            \n",
    "        elif main_choice == \"Exit\":\n",
    "            print(\"👋 Goodbye!\")\n",
    "            exit()\n",
    "            \n",
    "        elif main_choice == \"Download New Data\":\n",
    "            data_type = show_menu([\"Tick\", \"Candlestick\"], \"Select data type\")\n",
    "            category = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "            symbol = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "            gmt_offset = get_gmt_offset()\n",
    "            start = get_date_input(\"Start date\")\n",
    "            end = get_date_input(\"End date\")\n",
    "\n",
    "            if start > end:\n",
    "                print(\"❌ End date must be after start date.\")\n",
    "                exit()\n",
    "\n",
    "            print(f\"\\n📝 Configuration Summary:\")\n",
    "            print(f\"   - Symbol: {symbol}\")\n",
    "            print(f\"   - Data type: {data_type}\")\n",
    "            print(f\"   - Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"   - GMT offset: {gmt_offset}\")\n",
    "            print(f\"   - Save path: {DEFAULT_SAVE_PATH}\")\n",
    "\n",
    "            success = False\n",
    "            if data_type == \"Tick\":\n",
    "                price_type = show_menu([\"Bid فقط\", \"Ask فقط\", \"كلاهما\"], \"Price type\")\n",
    "                print(f\"   - Price type: {price_type}\")\n",
    "                columns = get_standardized_columns(\"Tick\", price_type)\n",
    "                print(f\"   - Columns: {', '.join(columns)}\")\n",
    "                success = download_tick(symbol, start, end, price_type, gmt_offset)\n",
    "            else:\n",
    "                tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "                tf_code = CANDLE_FRAME_CODES[tf]\n",
    "                print(f\"   - Timeframe: {tf}\")\n",
    "                columns = get_standardized_columns(\"Candlestick\")\n",
    "                print(f\"   - Columns: {', '.join(columns)}\")\n",
    "                success = download_candles(symbol, tf_code, tf, start, end, gmt_offset)\n",
    "\n",
    "            if success:\n",
    "                print(\"\\n✅ Download completed successfully!\")\n",
    "                print(\"\\n💡 Tip: You can now use 'Merge Files' option to combine multiple downloads.\")\n",
    "            else:\n",
    "                print(\"\\n❌ Download completed with errors!\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n⏹️ Operation interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed6dfdbf-22b6-4f9b-89a9-1993f94fefef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dukascopy Downloader Tool\n",
      "========================================\n",
      "\n",
      "🔹 Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2020-01-01\n",
      "End date (e.g. 2020-01-01):  2020-01-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Configuration Summary:\n",
      "   - Symbol: XAUUSD\n",
      "   - Data type: Candlestick\n",
      "   - Date range: 2020-01-01 to 2020-01-01\n",
      "   - GMT offset: 0\n",
      "   - Save path: C:\\Users\\Access\n",
      "\n",
      "🔹 Select timeframe\n",
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Timeframe: 1h\n",
      "\n",
      "🔄 Starting candle download for XAUUSD...\n",
      "📅 Date range: 2020-01-01 to 2020-01-01\n",
      "⏰ GMT offset: 0\n",
      "📊 Timeframe code: 3600\n",
      "[==================================================] 100.00% | 0.0MB of 0.0MB | ETA: 0h 0m 0s\n",
      "\n",
      "📊 Download Summary:\n",
      "   - Total days processed: 1\n",
      "   - Successful downloads: 0\n",
      "   - Total candles collected: 0\n",
      "⚠️ No candle data was collected. Creating empty file with headers only.\n",
      "✅ File saved: C:\\Users\\Access\\XAUUSD_candles_3600_merged.csv\n",
      "📦 Size: 0.00 MB\n",
      "\n",
      "✅ Download completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "DEFAULT_SAVE_PATH = os.getcwd()\n",
    "CATEGORIES = {\n",
    "    \"Metals\": [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\": [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"60\", \"5m\": \"300\", \"15m\": \"900\", \"1h\": \"3600\", \"4h\": \"14400\", \"1d\": \"86400\"\n",
    "}\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            else:\n",
    "                print(\"❌ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid date format.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def format_seconds(seconds):\n",
    "    # تحويل الثواني إلى صيغة (ساعات - دقائق - ثواني)\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total)\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = progress / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percent:.2f}% | {downloaded_mb:.1f}MB of {total_est_mb:.1f}MB | ETA: {format_seconds(remaining)}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, price_type, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting tick download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    \n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{hour}h_ticks.bi5\"\n",
    "            try:\n",
    "                r = requests.get(url, timeout=15)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    successful_downloads += 1\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    try:\n",
    "                        data = lzma.decompress(r.content)\n",
    "                        for i in range(0, len(data), 20):\n",
    "                            chunk = data[i:i+20]\n",
    "                            if len(chunk) < 20: \n",
    "                                continue\n",
    "                            t_off, ask, bid, ask_vol, bid_vol = struct.unpack(\">IIfff\", chunk)\n",
    "                            tick_time = day + timedelta(hours=hour, milliseconds=t_off)\n",
    "                            tick_time += timedelta(hours=gmt_offset)\n",
    "                            row = [tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]]\n",
    "                            \n",
    "                            if price_type == \"Bid فقط\":\n",
    "                                row += [round(bid, 5), round(bid_vol, 2)]\n",
    "                            elif price_type == \"Ask فقط\":\n",
    "                                row += [round(ask, 5), round(ask_vol, 2)]\n",
    "                            else:\n",
    "                                row += [round(bid, 5), round(ask, 5), round(bid_vol, 2), round(ask_vol, 2)]\n",
    "                            all_ticks.append(row)\n",
    "                    except lzma.LZMAError as e:\n",
    "                        print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                        continue\n",
    "                elif r.status_code == 404:\n",
    "                    # البيانات غير متوفرة لهذا التاريخ/الساعة (طبيعي)\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')} {hour}h\")\n",
    "                    \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')} {hour}h: {e}\")\n",
    "                continue\n",
    "                \n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total hours processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total ticks collected: {len(all_ticks)}\")\n",
    "\n",
    "    # حفظ الملف حتى لو كانت البيانات قليلة\n",
    "    filename = os.path.join(path, f\"{symbol}_tick_merged.csv\")\n",
    "    try:\n",
    "        with open(filename, \"w\", newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if price_type == \"Bid فقط\":\n",
    "                writer.writerow([\"time\", \"bid\", \"bid_vol\"])\n",
    "            elif price_type == \"Ask فقط\":\n",
    "                writer.writerow([\"time\", \"ask\", \"ask_vol\"])\n",
    "            else:\n",
    "                writer.writerow([\"time\", \"bid\", \"ask\", \"bid_vol\", \"ask_vol\"])\n",
    "            \n",
    "            if all_ticks:\n",
    "                all_ticks.sort(key=lambda x: x[0])\n",
    "                writer.writerows(all_ticks)\n",
    "            else:\n",
    "                print(\"⚠️ No tick data was collected. Creating empty file with headers only.\")\n",
    "        \n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving file: {e}\")\n",
    "        return False\n",
    "\n",
    "# ========== تحميل بيانات Candlestick ==========\n",
    "def download_candles(symbol, tf_code, start, end, gmt_offset):\n",
    "    path = DEFAULT_SAVE_PATH\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024\n",
    "    successful_downloads = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting candle download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "    print(f\"📊 Timeframe code: {tf_code}\")\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{day.year}/{day.month - 1:02d}/{day.day:02d}/{tf_code}_candles.bi5\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=15)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                successful_downloads += 1\n",
    "                downloaded_bytes += len(r.content)\n",
    "                try:\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    for i in range(0, len(data), 24):  # Changed from 20 to 24 bytes for candles\n",
    "                        chunk = data[i:i+24]\n",
    "                        if len(chunk) < 24: \n",
    "                            continue\n",
    "                        utc_offset, open_, high, low, close, vol = struct.unpack(\">IIffff\", chunk[:24])\n",
    "                        candle_time = day + timedelta(seconds=utc_offset) + timedelta(hours=gmt_offset)\n",
    "                        row = [candle_time.strftime(\"%Y-%m-%d %H:%M:%S\"), round(open_, 5), round(high, 5),\n",
    "                               round(low, 5), round(close, 5), round(vol, 2)]\n",
    "                        all_data.append(row)\n",
    "                except lzma.LZMAError as e:\n",
    "                    print(f\"\\n⚠️ Warning: Failed to decompress data for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "                    continue\n",
    "            elif r.status_code == 404:\n",
    "                # البيانات غير متوفرة لهذا التاريخ (طبيعي)\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"\\n⚠️ Warning: HTTP {r.status_code} for {day.strftime('%Y-%m-%d')}\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"\\n⚠️ Warning: Network error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ Warning: Unexpected error for {day.strftime('%Y-%m-%d')}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Download Summary:\")\n",
    "    print(f\"   - Total days processed: {count}\")\n",
    "    print(f\"   - Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   - Total candles collected: {len(all_data)}\")\n",
    "\n",
    "    # حفظ الملف حتى لو كانت البيانات قليلة\n",
    "    filename = os.path.join(path, f\"{symbol}_candles_{tf_code}_merged.csv\")\n",
    "    try:\n",
    "        with open(filename, \"w\", newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "            \n",
    "            if all_data:\n",
    "                all_data.sort(key=lambda x: x[0])\n",
    "                writer.writerows(all_data)\n",
    "            else:\n",
    "                print(\"⚠️ No candle data was collected. Creating empty file with headers only.\")\n",
    "        \n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"✅ File saved: {os.path.abspath(filename)}\")\n",
    "        print(f\"📦 Size: {file_size:.2f} MB\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving file: {e}\")\n",
    "        return False\n",
    "\n",
    "# ========== تشغيل البرنامج ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 Dukascopy Downloader Tool\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    try:\n",
    "        data_type = show_menu([\"Tick\", \"Candlestick\"], \"Select data type\")\n",
    "        category = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "        symbol = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "        gmt_offset = get_gmt_offset()\n",
    "        start = get_date_input(\"Start date\")\n",
    "        end = get_date_input(\"End date\")\n",
    "\n",
    "        if start > end:\n",
    "            print(\"❌ End date must be after start date.\")\n",
    "            exit()\n",
    "\n",
    "        print(f\"\\n📝 Configuration Summary:\")\n",
    "        print(f\"   - Symbol: {symbol}\")\n",
    "        print(f\"   - Data type: {data_type}\")\n",
    "        print(f\"   - Date range: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"   - GMT offset: {gmt_offset}\")\n",
    "        print(f\"   - Save path: {DEFAULT_SAVE_PATH}\")\n",
    "\n",
    "        success = False\n",
    "        if data_type == \"Tick\":\n",
    "            price_type = show_menu([\"Bid فقط\", \"Ask فقط\", \"كلاهما\"], \"Price type\")\n",
    "            print(f\"   - Price type: {price_type}\")\n",
    "            success = download_tick(symbol, start, end, price_type, gmt_offset)\n",
    "        else:\n",
    "            tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "            tf_code = CANDLE_FRAME_CODES[tf]\n",
    "            print(f\"   - Timeframe: {tf}\")\n",
    "            success = download_candles(symbol, tf_code, start, end, gmt_offset)\n",
    "\n",
    "        if success:\n",
    "            print(\"\\n✅ Download completed successfully!\")\n",
    "        else:\n",
    "            print(\"\\n❌ Download completed with errors!\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n⏹️ Download interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73c366ad-fa45-4a0f-b072-33f73e516f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟡 اختر الأداة التي تريد تحميل بياناتها:\n",
      "1. XAUUSD\n",
      "2. EURUSD\n",
      "3. GBPUSD\n",
      "4. USDJPY\n",
      "5. USDCHF\n",
      "6. AUDUSD\n",
      "7. NZDUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "🔢 أدخل رقم الأداة:  2\n",
      "📅 أدخل تاريخ البداية (مثال: 2020-01-01):  2020-01-01\n",
      "📅 أدخل تاريخ النهاية (مثال: 2020-01-01):  2020-01-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ جاري تحميل بيانات EURUSD من 2020-01-01 إلى 2020-01-01...\n",
      "\n",
      "✅ تم حفظ بيانات يوم 2020-01-01 في EURUSD_2020-01-01.csv\n",
      "\n",
      "🧩 جاري دمج الملفات...\n",
      "✅ تم حفظ الملف المدمج في: output\\EURUSD_merged_20200101_to_20200101.csv\n",
      "\n",
      "✅ تم الانتهاء من التحميل والدمج.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd  # مكتبة لدمج وفرز البيانات\n",
    "\n",
    "symbols = [\n",
    "    \"XAUUSD\", \"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"\n",
    "]\n",
    "\n",
    "def show_symbol_menu():\n",
    "    print(\"🟡 اختر الأداة التي تريد تحميل بياناتها:\")\n",
    "    for i, sym in enumerate(symbols):\n",
    "        print(f\"{i + 1}. {sym}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"🔢 أدخل رقم الأداة: \")) - 1\n",
    "            if 0 <= choice < len(symbols):\n",
    "                return symbols[choice]\n",
    "            else:\n",
    "                print(\"❌ رقم غير صحيح. جرب مرة أخرى.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ يرجى إدخال رقم.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (مثال: 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ التاريخ غير صحيح. يرجى المحاولة مرة أخرى.\")\n",
    "\n",
    "def download_tick_data(symbol, start_date, end_date, save_path=\"output\"):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    current = start_date\n",
    "\n",
    "    while current <= end_date:\n",
    "        daily_ticks = []\n",
    "\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{current.year}/{current.month - 1:02d}/{current.day:02d}/{hour}h_ticks.bi5\"\n",
    "            try:\n",
    "                response = requests.get(url, timeout=10)\n",
    "                if response.status_code == 200 and response.content:\n",
    "                    decompressed = lzma.decompress(response.content)\n",
    "                    for i in range(0, len(decompressed), 20):\n",
    "                        chunk = decompressed[i:i+20]\n",
    "                        if len(chunk) < 20:\n",
    "                            continue\n",
    "                        timestamp_offset, ask, bid, ask_vol, bid_vol = struct.unpack(\">IIfff\", chunk)\n",
    "                        tick_time = current + timedelta(hours=hour, milliseconds=timestamp_offset)\n",
    "                        daily_ticks.append([\n",
    "                            tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3],\n",
    "                            round(bid, 5),\n",
    "                            round(ask, 5),\n",
    "                            round(bid_vol, 2),\n",
    "                            round(ask_vol, 2)\n",
    "                        ])\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ خطأ في تحميل الساعة {hour}: {e}\")\n",
    "\n",
    "        if daily_ticks:\n",
    "            filename = f\"{symbol}_{current.strftime('%Y-%m-%d')}.csv\"\n",
    "            with open(os.path.join(save_path, filename), \"w\", newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"gmt_time\", \"bid\", \"ask\", \"bid_vol\", \"ask_vol\"])\n",
    "                writer.writerows(daily_ticks)\n",
    "            print(f\"✅ تم حفظ بيانات يوم {current.date()} في {filename}\")\n",
    "        else:\n",
    "            print(f\"ℹ️ لا توجد بيانات لـ {current.date()}\")\n",
    "\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "def merge_csv_files(symbol, start_date, end_date, save_path=\"output\"):\n",
    "    print(\"\\n🧩 جاري دمج الملفات...\")\n",
    "    all_files = [\n",
    "        os.path.join(save_path, f) for f in os.listdir(save_path)\n",
    "        if f.startswith(symbol) and f.endswith(\".csv\")\n",
    "    ]\n",
    "\n",
    "    if not all_files:\n",
    "        print(\"❌ لم يتم العثور على أي ملفات CSV للدمج.\")\n",
    "        return\n",
    "\n",
    "    df_list = []\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ خطأ في قراءة الملف {file}: {e}\")\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"❌ لم يتمكن من قراءة أي ملفات.\")\n",
    "        return\n",
    "\n",
    "    merged_df = pd.concat(df_list)\n",
    "    merged_df.sort_values(by=\"gmt_time\", inplace=True)\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    merged_filename = f\"{symbol}_merged_{start_date.strftime('%Y%m%d')}_to_{end_date.strftime('%Y%m%d')}.csv\"\n",
    "    merged_path = os.path.join(save_path, merged_filename)\n",
    "    merged_df.to_csv(merged_path, index=False)\n",
    "    print(f\"✅ تم حفظ الملف المدمج في: {merged_path}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 🚀 التشغيل\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = show_symbol_menu()\n",
    "    start = get_date_input(\"📅 أدخل تاريخ البداية\")\n",
    "    end = get_date_input(\"📅 أدخل تاريخ النهاية\")\n",
    "\n",
    "    if end < start:\n",
    "        print(\"❌ تاريخ النهاية يجب أن يكون بعد البداية.\")\n",
    "    else:\n",
    "        print(f\"\\n⬇️ جاري تحميل بيانات {symbol} من {start.date()} إلى {end.date()}...\\n\")\n",
    "        download_tick_data(symbol, start, end)\n",
    "        merge_csv_files(symbol, start, end)\n",
    "        print(\"\\n✅ تم الانتهاء من التحميل والدمج.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "654d476a-3f39-4ea1-8965-04c78d57eb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟡 اختر الأداة التي تريد تحميل بياناتها:\n",
      "1. XAUUSD\n",
      "2. EURUSD\n",
      "3. GBPUSD\n",
      "4. USDJPY\n",
      "5. USDCHF\n",
      "6. AUDUSD\n",
      "7. NZDUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "🔢 أدخل رقم الأداة:  2\n",
      "📅 أدخل تاريخ البداية (مثال: 2020-01-01):  2020-01-01\n",
      "📅 أدخل تاريخ النهاية (مثال: 2020-01-01):  2020-01-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⬇️ جاري تحميل بيانات EURUSD من 2020-01-01 إلى 2020-01-03...\n",
      "\n",
      "✅ تم حفظ بيانات يوم 2020-01-01 في EURUSD_2020-01-01.csv\n",
      "✅ تم حفظ بيانات يوم 2020-01-02 في EURUSD_2020-01-02.csv\n",
      "✅ تم حفظ بيانات يوم 2020-01-03 في EURUSD_2020-01-03.csv\n",
      "\n",
      "🧩 جاري دمج الملفات...\n",
      "✅ تم حفظ الملف المدمج في: output\\EURUSD_merged_20200101_to_20200103.csv\n",
      "\n",
      "✅ تم الانتهاء من التحميل والدمج.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "import struct\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd  # مكتبة لدمج وفرز البيانات\n",
    "\n",
    "symbols = [\n",
    "    \"XAUUSD\", \"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"\n",
    "]\n",
    "\n",
    "def show_symbol_menu():\n",
    "    print(\"🟡 اختر الأداة التي تريد تحميل بياناتها:\")\n",
    "    for i, sym in enumerate(symbols):\n",
    "        print(f\"{i + 1}. {sym}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"🔢 أدخل رقم الأداة: \")) - 1\n",
    "            if 0 <= choice < len(symbols):\n",
    "                return symbols[choice]\n",
    "            else:\n",
    "                print(\"❌ رقم غير صحيح. جرب مرة أخرى.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ يرجى إدخال رقم.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (مثال: 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ التاريخ غير صحيح. يرجى المحاولة مرة أخرى.\")\n",
    "\n",
    "def download_tick_data(symbol, start_date, end_date, save_path=\"output\"):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    current = start_date\n",
    "\n",
    "    while current <= end_date:\n",
    "        daily_ticks = []\n",
    "\n",
    "        for hour in range(24):\n",
    "            url = f\"https://datafeed.dukascopy.com/datafeed/{symbol}/{current.year}/{current.month - 1:02d}/{current.day:02d}/{hour}h_ticks.bi5\"\n",
    "            try:\n",
    "                response = requests.get(url, timeout=10)\n",
    "                if response.status_code == 200 and response.content:\n",
    "                    decompressed = lzma.decompress(response.content)\n",
    "                    for i in range(0, len(decompressed), 20):\n",
    "                        chunk = decompressed[i:i+20]\n",
    "                        if len(chunk) < 20:\n",
    "                            continue\n",
    "                        timestamp_offset, ask, bid, ask_vol, bid_vol = struct.unpack(\">IIfff\", chunk)\n",
    "                        tick_time = current + timedelta(hours=hour, milliseconds=timestamp_offset)\n",
    "                        daily_ticks.append([\n",
    "                            tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3],\n",
    "                            round(ask, 5),\n",
    "                            round(bid, 5),\n",
    "                            round(ask_vol, 2),\n",
    "                            round(bid_vol, 2)\n",
    "                        ])\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ خطأ في تحميل الساعة {hour}: {e}\")\n",
    "\n",
    "        if daily_ticks:\n",
    "            filename = f\"{symbol}_{current.strftime('%Y-%m-%d')}.csv\"\n",
    "            with open(os.path.join(save_path, filename), \"w\", newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"Gmt time\", \"Ask\", \"Bid\", \"AskVolume\", \"BidVolume\"])\n",
    "                writer.writerows(daily_ticks)\n",
    "            print(f\"✅ تم حفظ بيانات يوم {current.date()} في {filename}\")\n",
    "        else:\n",
    "            print(f\"ℹ️ لا توجد بيانات لـ {current.date()}\")\n",
    "\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "def merge_csv_files(symbol, start_date, end_date, save_path=\"output\"):\n",
    "    print(\"\\n🧩 جاري دمج الملفات...\")\n",
    "    all_files = [\n",
    "        os.path.join(save_path, f) for f in os.listdir(save_path)\n",
    "        if f.startswith(symbol) and f.endswith(\".csv\")\n",
    "    ]\n",
    "\n",
    "    if not all_files:\n",
    "        print(\"❌ لم يتم العثور على أي ملفات CSV للدمج.\")\n",
    "        return\n",
    "\n",
    "    df_list = []\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ خطأ في قراءة الملف {file}: {e}\")\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"❌ لم يتمكن من قراءة أي ملفات.\")\n",
    "        return\n",
    "\n",
    "    merged_df = pd.concat(df_list)\n",
    "    merged_df.sort_values(by=\"Gmt time\", inplace=True)\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    merged_filename = f\"{symbol}_merged_{start_date.strftime('%Y%m%d')}_to_{end_date.strftime('%Y%m%d')}.csv\"\n",
    "    merged_path = os.path.join(save_path, merged_filename)\n",
    "    merged_df.to_csv(merged_path, index=False)\n",
    "    print(f\"✅ تم حفظ الملف المدمج في: {merged_path}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 🚀 التشغيل\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = show_symbol_menu()\n",
    "    start = get_date_input(\"📅 أدخل تاريخ البداية\")\n",
    "    end = get_date_input(\"📅 أدخل تاريخ النهاية\")\n",
    "\n",
    "    if end < start:\n",
    "        print(\"❌ تاريخ النهاية يجب أن يكون بعد البداية.\")\n",
    "    else:\n",
    "        print(f\"\\n⬇️ جاري تحميل بيانات {symbol} من {start.date()} إلى {end.date()}...\\n\")\n",
    "        download_tick_data(symbol, start, end)\n",
    "        merge_csv_files(symbol, start, end)\n",
    "        print(\"\\n✅ تم الانتهاء من التحميل والدمج.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab3aadeb-57b9-4727-bd8e-de0297769048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select main category:\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter category number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected category: Metals\n",
      "\n",
      "Select instrument:\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter instrument number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected instrument: XAUUSD\n",
      "\n",
      "1. Candlestick\n",
      "2. Tick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose data type (number):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select timeframe:  3\n",
      "Enter start date (YYYY-MM-DD):  2020-01-01\n",
      "Enter end date (YYYY-MM-DD):  2020-01-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://www.dukascopy.com/datafeed/XAUUSD/15m/2020/01/01/15m.bi5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XAUUSD_20200101.csv: 4.52kiB [00:00, 9.39kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://www.dukascopy.com/datafeed/XAUUSD/15m/2020/01/02/15m.bi5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XAUUSD_20200102.csv: 4.52kiB [00:00, 813kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://www.dukascopy.com/datafeed/XAUUSD/15m/2020/01/03/15m.bi5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XAUUSD_20200103.csv: 4.52kiB [00:00, ?iB/s]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 135\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles saved to directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 128\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Merge files\u001b[39;00m\n\u001b[0;32m    127\u001b[0m merged_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_merged.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 128\u001b[0m \u001b[43mmerge_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownloaded_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles saved to directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 76\u001b[0m, in \u001b[0;36mmerge_csv\u001b[1;34m(files, output_path)\u001b[0m\n\u001b[0;32m     74\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m---> 76\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     78\u001b[0m all_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants\n",
    "BASE_URL = 'https://www.dukascopy.com/datafeed'\n",
    "\n",
    "# Mapping of categories to URL paths (example)\n",
    "CATEGORIES = {\n",
    "    'Metals': ['XAUUSD', 'XAGUSD'],\n",
    "    'Forex': ['EURUSD', 'GBPUSD', 'USDJPY'],\n",
    "    'Indices': ['DAX', 'SP500'],\n",
    "    # Add more...\n",
    "}\n",
    "HISTORICAL_PATH = 'widgets/quotes/historical_data_feed'\n",
    "\n",
    "\n",
    "def select_option(options, prompt_text):\n",
    "    \"\"\"\n",
    "    Display a numbered list of options and return the selected item.\n",
    "    \"\"\"\n",
    "    for idx, opt in enumerate(options, 1):\n",
    "        print(f\"{idx}. {opt}\")\n",
    "    while True:\n",
    "        choice = input(prompt_text)\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return options[int(choice) - 1]\n",
    "        print(\"Invalid selection, please try again.\")\n",
    "\n",
    "\n",
    "def build_url(symbol, data_type, start_dt, end_dt, timeframe=None):\n",
    "    \"\"\"\n",
    "    Construct the download URL for dukascopy data.\n",
    "    \"\"\"\n",
    "    start_str = start_dt.strftime('%Y/%m/%d')\n",
    "    end_str = end_dt.strftime('%Y/%m/%d')\n",
    "    if data_type == 'Tick':\n",
    "        path = f\"{symbol}/{start_dt.year}/{start_dt.strftime('%m')}/{start_dt.strftime('%d')}/ticks.bi5\"\n",
    "    else:\n",
    "        path = f\"{symbol}/{timeframe}/{start_dt.year}/{start_dt.strftime('%m')}/{start_dt.strftime('%d')}/{timeframe}.bi5\"\n",
    "    return f\"{BASE_URL}/{path}\"  # Adjust as per actual API\n",
    "\n",
    "\n",
    "def download_file(url, dest_path):\n",
    "    \"\"\"\n",
    "    Download a file with progress bar showing time remaining, speed, and size.\n",
    "    \"\"\"\n",
    "    r = requests.get(url, stream=True)\n",
    "    total_size = int(r.headers.get('content-length', 0))\n",
    "    block_size = 1024\n",
    "    wrote = 0\n",
    "    start = time.time()\n",
    "    with open(dest_path, 'wb') as f, tqdm(\n",
    "        total=total_size, unit='iB', unit_scale=True,\n",
    "        desc=os.path.basename(dest_path)\n",
    "    ) as bar:\n",
    "        for data in r.iter_content(block_size):\n",
    "            f.write(data)\n",
    "            wrote += len(data)\n",
    "            bar.update(len(data))\n",
    "    if total_size != 0 and wrote != total_size:\n",
    "        print(\"ERROR, something went wrong\")\n",
    "\n",
    "\n",
    "def merge_csv(files, output_path):\n",
    "    \"\"\"\n",
    "    Read multiple CSVs, concatenate and sort by Gmt time then save.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "    all_df['Gmt time'] = pd.to_datetime(all_df['Gmt time'])\n",
    "    all_df = all_df.sort_values('Gmt time')\n",
    "    all_df.to_csv(output_path, index=False)\n",
    "    print(f\"Merged file saved to: {output_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Select main category:\")\n",
    "    category = select_option(list(CATEGORIES.keys()), \"Enter category number: \")\n",
    "    symbols = CATEGORIES[category]\n",
    "    print(f\"Selected category: {category}\\n\")\n",
    "\n",
    "    print(\"Select instrument:\")\n",
    "    symbol = select_option(symbols, \"Enter instrument number: \")\n",
    "    print(f\"Selected instrument: {symbol}\\n\")\n",
    "\n",
    "    # Choose data type\n",
    "    data_type = select_option(['Candlestick', 'Tick'], \"Choose data type (number): \")\n",
    "    timeframe = None\n",
    "    if data_type == 'Candlestick':\n",
    "        # Available timeframes\n",
    "        tfs = ['1m', '5m', '15m', '1h', '4h', '1d']\n",
    "        timeframe = select_option(tfs, \"Select timeframe: \")\n",
    "    else:\n",
    "        ticks = input(\"Enter number of ticks per file: \")\n",
    "\n",
    "    # Date selection\n",
    "    start_date = input(\"Enter start date (YYYY-MM-DD): \")\n",
    "    end_date = input(\"Enter end date (YYYY-MM-DD): \")\n",
    "    start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "    # Create output dir\n",
    "    out_dir = os.path.join(os.getcwd(), 'downloads', symbol)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    downloaded_files = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        url = build_url(symbol, data_type, current, end_dt, timeframe)\n",
    "        date_str = current.strftime('%Y%m%d')\n",
    "        out_file = os.path.join(out_dir, f\"{symbol}_{date_str}.csv\")\n",
    "        print(f\"Downloading: {url}\")\n",
    "        download_file(url, out_file)\n",
    "        downloaded_files.append(out_file)\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "    # Merge files\n",
    "    merged_path = os.path.join(out_dir, f\"{symbol}_{start_date}_{end_date}_merged.csv\")\n",
    "    merge_csv(downloaded_files, merged_path)\n",
    "\n",
    "    print(\"Download complete.\")\n",
    "    print(f\"Files saved to directory: {out_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5708e9c3-b734-4dd6-abdc-3ef1c04313f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select main category:\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter category number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected category: Metals\n",
      "\n",
      "Select instrument:\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter instrument number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected instrument: XAUUSD\n",
      "\n",
      "1. Candlestick\n",
      "2. Tick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose data type (number):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select timeframe:  3\n",
      "Enter start date (YYYY-MM-DD):  2020-01-01\n",
      "Enter end date (YYYY-MM-DD):  2020-01-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 2020-01-01...\n",
      "⚠️ فشل تنزيل XAUUSD_20200101.bi5: تعذر معرفة حجم الملف من الخادم.\n",
      "\n",
      "Downloading 2020-01-02...\n",
      "⚠️ فشل تنزيل XAUUSD_20200102.bi5: تعذر معرفة حجم الملف من الخادم.\n",
      "\n",
      "Downloading 2020-01-03...\n",
      "⚠️ فشل تنزيل XAUUSD_20200103.bi5: تعذر معرفة حجم الملف من الخادم.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 167\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll files stored in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 162\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    160\u001b[0m merged_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_merged.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m merged_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_dir, merged_name)\n\u001b[1;32m--> 162\u001b[0m \u001b[43mmerge_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll files stored in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 98\u001b[0m, in \u001b[0;36mmerge_csv\u001b[1;34m(csv_files, out_path)\u001b[0m\n\u001b[0;32m     96\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(f, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGmt time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     97\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m---> 98\u001b[0m all_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m all_df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGmt time\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    100\u001b[0m all_df\u001b[38;5;241m.\u001b[39mto_csv(out_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ——————————————\n",
    "# إعدادات أساسية\n",
    "# ——————————————\n",
    "BASE_URL = 'https://www.dukascopy.com/datafeed'\n",
    "# مثال لتصنيفات الأدوات؛ أضف ما تريد:\n",
    "CATEGORIES = {\n",
    "    'Metals': ['XAUUSD', 'XAGUSD'],\n",
    "    'Forex' : ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDUSD'],\n",
    "    'Indices': ['DAX', 'SP500'],\n",
    "}\n",
    "# الأطر الزمنية المدعومة للشموع اليابانية\n",
    "TIMEFRAMES = ['1m', '5m', '15m', '1h', '4h', '1d']\n",
    "\n",
    "# ——————————————\n",
    "# دوال مساعدة\n",
    "# ——————————————\n",
    "def select_option(options, prompt_text):\n",
    "    \"\"\"عرض قائمة من الخيارات وإرجاع الاختيار.\"\"\"\n",
    "    for idx, opt in enumerate(options, 1):\n",
    "        print(f\"{idx}. {opt}\")\n",
    "    while True:\n",
    "        choice = input(prompt_text).strip()\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return options[int(choice) - 1]\n",
    "        print(\"اختيار غير صالح، حاول مرة أخرى.\")\n",
    "\n",
    "def build_bi5_url(symbol, data_type, date_dt, timeframe=None):\n",
    "    \"\"\"\n",
    "    بناء رابط التنزيل لملف .bi5:\n",
    "    - Tick: symbol/YYYY/MM/DD/ticks.bi5\n",
    "    - Candlestick: symbol/{tf}/YYYY/MM/DD/{tf}.bi5\n",
    "    \"\"\"\n",
    "    y, m, d = date_dt.year, f\"{date_dt.month:02}\", f\"{date_dt.day:02}\"\n",
    "    if data_type == 'Tick':\n",
    "        path = f\"{symbol}/{y}/{m}/{d}/ticks.bi5\"\n",
    "    else:\n",
    "        path = f\"{symbol}/{timeframe}/{y}/{m}/{d}/{timeframe}.bi5\"\n",
    "    return f\"{BASE_URL}/{path}\"\n",
    "\n",
    "def download_bi5(url, dest_path):\n",
    "    \"\"\"تنزيل ملف bi5 مع شريط تقدم يوضح الحجم والسرعة والوقت المتبقي.\"\"\"\n",
    "    resp = requests.get(url, stream=True)\n",
    "    total = int(resp.headers.get('content-length', 0))\n",
    "    if total == 0:\n",
    "        raise RuntimeError(\"تعذر معرفة حجم الملف من الخادم.\")\n",
    "    with open(dest_path, 'wb') as f, tqdm(\n",
    "        total=total, unit='iB', unit_scale=True,\n",
    "        desc=os.path.basename(dest_path),\n",
    "        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\"\n",
    "    ) as bar:\n",
    "        for chunk in resp.iter_content(1024):\n",
    "            if not chunk:\n",
    "                break\n",
    "            f.write(chunk)\n",
    "            bar.update(len(chunk))\n",
    "\n",
    "def bi5_to_csv(bi5_path, csv_path, timeframe):\n",
    "    \"\"\"\n",
    "    فك ضغط .bi5 وتحويله إلى CSV بعناوين:\n",
    "    ['Gmt time','Open','High','Low','Close','Volume']\n",
    "    \"\"\"\n",
    "    # حوّل الإطار الزمني إلى ميليثانية\n",
    "    tf_ms = {\n",
    "        '1m': 60_000, '5m': 5*60_000, '15m': 15*60_000,\n",
    "        '1h': 3600_000, '4h': 4*3600_000, '1d': 86400_000\n",
    "    }[timeframe]\n",
    "    \n",
    "    with lzma.open(bi5_path) as fin, open(csv_path, 'w', newline='') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        writer.writerow(['Gmt time','Open','High','Low','Close','Volume'])\n",
    "        record_size = 8 + 5*4  # 8 bytes للوقت + 5×4 bytes للبيانات\n",
    "        while True:\n",
    "            chunk = fin.read(record_size)\n",
    "            if len(chunk) < record_size:\n",
    "                break\n",
    "            t_ms, o, h, l, c, v = struct.unpack('>Qffffi', chunk)\n",
    "            t_str = datetime.utcfromtimestamp(t_ms/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            writer.writerow([t_str, o, h, l, c, v])\n",
    "\n",
    "def merge_csv(csv_files, out_path):\n",
    "    \"\"\"دمج عدة CSV فرعية فرزًا حسب 'Gmt time' ثم حفظ النتيجة.\"\"\"\n",
    "    dfs = []\n",
    "    for f in csv_files:\n",
    "        df = pd.read_csv(f, parse_dates=['Gmt time'])\n",
    "        dfs.append(df)\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "    all_df.sort_values('Gmt time', inplace=True)\n",
    "    all_df.to_csv(out_path, index=False)\n",
    "    print(f\"\\n✔︎ تم الدمج وحفظ الملف النهائي: {out_path}\")\n",
    "\n",
    "# ——————————————\n",
    "# الدالة الرئيسية\n",
    "# ——————————————\n",
    "def main():\n",
    "    # 1) اختيار التصنيف ثم الأداة\n",
    "    print(\"Select main category:\")\n",
    "    category = select_option(list(CATEGORIES.keys()), \"Enter category number: \")\n",
    "    print(f\"Selected category: {category}\\n\")\n",
    "\n",
    "    print(\"Select instrument:\")\n",
    "    symbol = select_option(CATEGORIES[category], \"Enter instrument number: \")\n",
    "    print(f\"Selected instrument: {symbol}\\n\")\n",
    "\n",
    "    # 2) نوع البيانات: Candlestick أو Tick\n",
    "    data_type = select_option(['Candlestick', 'Tick'], \"Choose data type (number): \")\n",
    "    timeframe = None\n",
    "    if data_type == 'Candlestick':\n",
    "        timeframe = select_option(TIMEFRAMES, \"Select timeframe: \")\n",
    "    else:\n",
    "        # نستخدم إطار زمني وهمي لتحويل bi5 إلى CSV بـفواصل زمنية متناهية\n",
    "        timeframe = 'tick'  \n",
    "\n",
    "    # 3) تحديد النطاق الزمني\n",
    "    start_date = input(\"Enter start date (YYYY-MM-DD): \").strip()\n",
    "    end_date   = input(\"Enter end date (YYYY-MM-DD): \").strip()\n",
    "    start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_dt   = datetime.strptime(end_date,   '%Y-%m-%d')\n",
    "\n",
    "    # 4) إنشاء مجلد النتائج\n",
    "    out_dir = os.path.join(os.getcwd(), 'downloads', symbol)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    csv_files = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        # رابط التنزيل واسم الملف المحلي\n",
    "        url = build_bi5_url(symbol, data_type, current, timeframe)\n",
    "        bi5_name = f\"{symbol}_{current.strftime('%Y%m%d')}.bi5\"\n",
    "        bi5_path = os.path.join(out_dir, bi5_name)\n",
    "\n",
    "        print(f\"\\nDownloading {current.strftime('%Y-%m-%d')}...\")\n",
    "        try:\n",
    "            download_bi5(url, bi5_path)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ فشل تنزيل {bi5_name}: {e}\")\n",
    "            current += timedelta(days=1)\n",
    "            continue\n",
    "\n",
    "        # تحويل BI5 إلى CSV\n",
    "        csv_name = bi5_name.replace('.bi5', '.csv')\n",
    "        csv_path = os.path.join(out_dir, csv_name)\n",
    "        bi5_to_csv(bi5_path, csv_path, timeframe)\n",
    "        csv_files.append(csv_path)\n",
    "\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "    # 5) دمج كل CSV في ملف واحد\n",
    "    merged_name = f\"{symbol}_{start_date}_{end_date}_merged.csv\"\n",
    "    merged_path = os.path.join(out_dir, merged_name)\n",
    "    merge_csv(csv_files, merged_path)\n",
    "\n",
    "    print(f\"\\nAll files stored in: {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88e58b05-0e42-4b82-b772-aecc43e1cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select main category:\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter category number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected category: Metals\n",
      "\n",
      "Select instrument:\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter instrument number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected instrument: XAUUSD\n",
      "\n",
      "1. Candlestick\n",
      "2. Tick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose data type (number):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select timeframe:  4\n",
      "Enter start date (YYYY-MM-DD):  2020-01-01\n",
      "Enter end date   (YYYY-MM-DD):  2020-01-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 2020-01-01...\n",
      "⚠️ تخطى 2020-01-01: HTTP 403\n",
      "\n",
      "Downloading 2020-01-02...\n",
      "⚠️ تخطى 2020-01-02: HTTP 403\n",
      "\n",
      "Downloading 2020-01-03...\n",
      "⚠️ تخطى 2020-01-03: HTTP 403\n",
      "\n",
      "Downloading 2020-01-04...\n",
      "⚠️ تخطى 2020-01-04: HTTP 403\n",
      "⚠️ لا توجد ملفات CSV لدمجها.\n",
      "\n",
      "All files stored in: C:\\Users\\Access\\downloads\\XAUUSD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ——————————————\n",
    "# إعدادات أساسية\n",
    "# ——————————————\n",
    "BASE_URL = 'https://www.dukascopy.com/datafeed'\n",
    "CATEGORIES = {\n",
    "    'Metals': ['XAUUSD', 'XAGUSD'],\n",
    "    'Forex' : ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDUSD'],\n",
    "    'Indices': ['DAX', 'SP500'],\n",
    "}\n",
    "TIMEFRAMES = ['1m', '5m', '15m', '1h', '4h', '1d']\n",
    "\n",
    "# ——————————————\n",
    "# دوال مساعدة\n",
    "# ——————————————\n",
    "def select_option(options, prompt_text):\n",
    "    for idx, opt in enumerate(options, 1):\n",
    "        print(f\"{idx}. {opt}\")\n",
    "    while True:\n",
    "        choice = input(prompt_text).strip()\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return options[int(choice) - 1]\n",
    "        print(\"اختيار غير صالح، حاول مرة أخرى.\")\n",
    "\n",
    "def build_bi5_url(symbol, data_type, date_dt, timeframe=None):\n",
    "    y, m, d = date_dt.year, f\"{date_dt.month:02}\", f\"{date_dt.day:02}\"\n",
    "    if data_type == 'Tick':\n",
    "        return f\"{BASE_URL}/{symbol}/{y}/{m}/{d}/ticks.bi5\"\n",
    "    else:\n",
    "        return f\"{BASE_URL}/{symbol}/{timeframe}/{y}/{m}/{d}/{timeframe}.bi5\"\n",
    "\n",
    "def download_bi5(url, dest_path):\n",
    "    \"\"\"\n",
    "    ينزل ملف bi5. إذا لم يكن موجوداً (404) أو حجمه صفر، يرفع استثناء.\n",
    "    \"\"\"\n",
    "    resp = requests.get(url, stream=True)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f\"HTTP {resp.status_code}\")\n",
    "    # حاول قراءة header الحجم:\n",
    "    total = resp.headers.get('content-length')\n",
    "    total = int(total) if total and total.isdigit() else None\n",
    "\n",
    "    with open(dest_path, 'wb') as f, tqdm(\n",
    "        total=total, unit='iB', unit_scale=True,\n",
    "        desc=os.path.basename(dest_path),\n",
    "        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\"\n",
    "    ) as bar:\n",
    "        for chunk in resp.iter_content(1024):\n",
    "            if not chunk:\n",
    "                break\n",
    "            f.write(chunk)\n",
    "            bar.update(len(chunk))\n",
    "\n",
    "    # تأكد أن الملف ليس فارغاً\n",
    "    if os.path.getsize(dest_path) == 0:\n",
    "        os.remove(dest_path)\n",
    "        raise RuntimeError(\"الملف فارغ\")\n",
    "\n",
    "def bi5_to_csv(bi5_path, csv_path, timeframe):\n",
    "    tf_ms = {\n",
    "        '1m': 60_000, '5m': 5*60_000, '15m': 15*60_000,\n",
    "        '1h': 3600_000, '4h': 4*3600_000, '1d': 86400_000\n",
    "    }[timeframe]\n",
    "    with lzma.open(bi5_path) as fin, open(csv_path, 'w', newline='') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        writer.writerow(['Gmt time','Open','High','Low','Close','Volume'])\n",
    "        record_size = 8 + 5*4\n",
    "        while True:\n",
    "            chunk = fin.read(record_size)\n",
    "            if len(chunk) < record_size:\n",
    "                break\n",
    "            t_ms, o, h, l, c, v = struct.unpack('>Qffffi', chunk)\n",
    "            t_str = datetime.utcfromtimestamp(t_ms/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            writer.writerow([t_str, o, h, l, c, v])\n",
    "\n",
    "def merge_csv(csv_files, out_path):\n",
    "    if not csv_files:\n",
    "        print(\"⚠️ لا توجد ملفات CSV لدمجها.\")\n",
    "        return\n",
    "    dfs = []\n",
    "    for f in csv_files:\n",
    "        dfs.append(pd.read_csv(f, parse_dates=['Gmt time']))\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "    all_df.sort_values('Gmt time', inplace=True)\n",
    "    all_df.to_csv(out_path, index=False)\n",
    "    print(f\"\\n✔︎ تم الدمج وحفظ الملف النهائي: {out_path}\")\n",
    "\n",
    "# ——————————————\n",
    "# الدالة الرئيسية\n",
    "# ——————————————\n",
    "def main():\n",
    "    print(\"Select main category:\")\n",
    "    category = select_option(list(CATEGORIES.keys()), \"Enter category number: \")\n",
    "    print(f\"Selected category: {category}\\n\")\n",
    "\n",
    "    print(\"Select instrument:\")\n",
    "    symbol = select_option(CATEGORIES[category], \"Enter instrument number: \")\n",
    "    print(f\"Selected instrument: {symbol}\\n\")\n",
    "\n",
    "    data_type = select_option(['Candlestick', 'Tick'], \"Choose data type (number): \")\n",
    "    if data_type == 'Candlestick':\n",
    "        timeframe = select_option(TIMEFRAMES, \"Select timeframe: \")\n",
    "    else:\n",
    "        timeframe = '1m'  # إطار وهمي لتحويل التيك إلى CSV\n",
    "\n",
    "    start_dt = datetime.strptime(input(\"Enter start date (YYYY-MM-DD): \").strip(), '%Y-%m-%d')\n",
    "    end_dt   = datetime.strptime(input(\"Enter end date   (YYYY-MM-DD): \").strip(), '%Y-%m-%d')\n",
    "\n",
    "    out_dir = os.path.join(os.getcwd(), 'downloads', symbol)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    csv_files = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        print(f\"\\nDownloading {current.strftime('%Y-%m-%d')}...\")\n",
    "        url      = build_bi5_url(symbol, data_type, current, timeframe)\n",
    "        bi5_file = os.path.join(out_dir, f\"{symbol}_{current.strftime('%Y%m%d')}.bi5\")\n",
    "\n",
    "        try:\n",
    "            download_bi5(url, bi5_file)\n",
    "            # تحويل وفك الضغط\n",
    "            csv_file = bi5_file.replace('.bi5', '.csv')\n",
    "            bi5_to_csv(bi5_file, csv_file, timeframe)\n",
    "            csv_files.append(csv_file)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ تخطى {current.strftime('%Y-%m-%d')}: {e}\")\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "    # دمج وإنهاء\n",
    "    merged_name = f\"{symbol}_{start_dt.date()}_{end_dt.date()}_merged.csv\"\n",
    "    merge_csv(csv_files, os.path.join(out_dir, merged_name))\n",
    "    print(f\"\\nAll files stored in: {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e05c2c6b-916b-469a-b8b3-a50b9dafb8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select main category:\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter category number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected category: Metals\n",
      "\n",
      "Select instrument:\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter instrument number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected instrument: XAUUSD\n",
      "\n",
      "1. Candlestick\n",
      "2. Tick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose data type (number):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select timeframe:  3\n",
      "Enter start date (YYYY-MM-DD):  2020-01-01\n",
      "Enter end date   (YYYY-MM-DD):  2020-01-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 2020-01-01...\n",
      "⚠️ تخطى 2020-01-01: HTTP 404\n",
      "\n",
      "Downloading 2020-01-02...\n",
      "⚠️ تخطى 2020-01-02: HTTP 404\n",
      "⚠️ لا توجد ملفات CSV لدمجها.\n",
      "\n",
      "All files stored in: C:\\Users\\Access\\downloads\\XAUUSD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ——————————————\n",
    "# إعدادات أساسية\n",
    "# ——————————————\n",
    "BASE_URL = 'https://datafeed.dukascopy.com/datafeed'\n",
    "CATEGORIES = {\n",
    "    'Metals': ['XAUUSD', 'XAGUSD'],\n",
    "    'Forex' : ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDUSD'],\n",
    "    'Indices': ['DAX', 'SP500'],\n",
    "}\n",
    "TIMEFRAMES = ['1m', '5m', '15m', '1h', '4h', '1d']\n",
    "\n",
    "# ——————————————\n",
    "# تهيئة الجلسة مع الرؤوس المطلوبة\n",
    "# ——————————————\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/115.0.0.0 Safari/537.36',\n",
    "    'Referer': 'https://www.dukascopy.com/trading-tools/widgets/quotes/historical_data_feed'\n",
    "})\n",
    "\n",
    "# ——————————————\n",
    "# دوال مساعدة\n",
    "# ——————————————\n",
    "def select_option(options, prompt_text):\n",
    "    for idx, opt in enumerate(options, 1):\n",
    "        print(f\"{idx}. {opt}\")\n",
    "    while True:\n",
    "        choice = input(prompt_text).strip()\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return options[int(choice) - 1]\n",
    "        print(\"اختيار غير صالح، حاول مرة أخرى.\")\n",
    "\n",
    "def build_bi5_url(symbol, data_type, date_dt, timeframe=None):\n",
    "    y, m, d = date_dt.year, f\"{date_dt.month:02}\", f\"{date_dt.day:02}\"\n",
    "    if data_type == 'Tick':\n",
    "        return f\"{BASE_URL}/{symbol}/{y}/{m}/{d}/ticks.bi5\"\n",
    "    else:\n",
    "        return f\"{BASE_URL}/{symbol}/{timeframe}/{y}/{m}/{d}/{timeframe}.bi5\"\n",
    "\n",
    "def download_bi5(url, dest_path):\n",
    "    \"\"\"\n",
    "    ينزل ملف bi5. إذا كان غير موجود (404) أو فارغًا، يرفع استثناء.\n",
    "    \"\"\"\n",
    "    resp = session.get(url, stream=True)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f\"HTTP {resp.status_code}\")\n",
    "    total = resp.headers.get('content-length')\n",
    "    total = int(total) if total and total.isdigit() else None\n",
    "\n",
    "    with open(dest_path, 'wb') as f, tqdm(\n",
    "        total=total, unit='iB', unit_scale=True,\n",
    "        desc=os.path.basename(dest_path),\n",
    "        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\"\n",
    "    ) as bar:\n",
    "        for chunk in resp.iter_content(1024):\n",
    "            if not chunk:\n",
    "                break\n",
    "            f.write(chunk)\n",
    "            bar.update(len(chunk))\n",
    "\n",
    "    if os.path.getsize(dest_path) == 0:\n",
    "        os.remove(dest_path)\n",
    "        raise RuntimeError(\"الملف فارغ\")\n",
    "\n",
    "def bi5_to_csv(bi5_path, csv_path, timeframe):\n",
    "    tf_ms = {\n",
    "        '1m': 60_000, '5m': 5*60_000, '15m': 15*60_000,\n",
    "        '1h': 3600_000, '4h': 4*3600_000, '1d': 86400_000\n",
    "    }[timeframe]\n",
    "    with lzma.open(bi5_path) as fin, open(csv_path, 'w', newline='') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        writer.writerow(['Gmt time','Open','High','Low','Close','Volume'])\n",
    "        record_size = 8 + 5*4\n",
    "        while True:\n",
    "            chunk = fin.read(record_size)\n",
    "            if len(chunk) < record_size:\n",
    "                break\n",
    "            t_ms, o, h, l, c, v = struct.unpack('>Qffffi', chunk)\n",
    "            t_str = datetime.utcfromtimestamp(t_ms/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            writer.writerow([t_str, o, h, l, c, v])\n",
    "\n",
    "def merge_csv(csv_files, out_path):\n",
    "    if not csv_files:\n",
    "        print(\"⚠️ لا توجد ملفات CSV لدمجها.\")\n",
    "        return\n",
    "    dfs = [pd.read_csv(f, parse_dates=['Gmt time']) for f in csv_files]\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "    all_df.sort_values('Gmt time', inplace=True)\n",
    "    all_df.to_csv(out_path, index=False)\n",
    "    print(f\"\\n✔︎ تم الدمج وحفظ الملف النهائي: {out_path}\")\n",
    "\n",
    "# ——————————————\n",
    "# الدالة الرئيسية\n",
    "# ——————————————\n",
    "def main():\n",
    "    print(\"Select main category:\")\n",
    "    category = select_option(list(CATEGORIES.keys()), \"Enter category number: \")\n",
    "    print(f\"Selected category: {category}\\n\")\n",
    "\n",
    "    print(\"Select instrument:\")\n",
    "    symbol = select_option(CATEGORIES[category], \"Enter instrument number: \")\n",
    "    print(f\"Selected instrument: {symbol}\\n\")\n",
    "\n",
    "    data_type = select_option(['Candlestick', 'Tick'], \"Choose data type (number): \")\n",
    "    timeframe = (select_option(TIMEFRAMES, \"Select timeframe: \")\n",
    "                 if data_type=='Candlestick' else '1m')\n",
    "\n",
    "    start_dt = datetime.strptime(input(\"Enter start date (YYYY-MM-DD): \").strip(), '%Y-%m-%d')\n",
    "    end_dt   = datetime.strptime(input(\"Enter end date   (YYYY-MM-DD): \").strip(), '%Y-%m-%d')\n",
    "\n",
    "    out_dir = os.path.join(os.getcwd(), 'downloads', symbol)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    csv_files = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        print(f\"\\nDownloading {current.strftime('%Y-%m-%d')}...\")\n",
    "        url      = build_bi5_url(symbol, data_type, current, timeframe)\n",
    "        bi5_file = os.path.join(out_dir, f\"{symbol}_{current.strftime('%Y%m%d')}.bi5\")\n",
    "\n",
    "        try:\n",
    "            download_bi5(url, bi5_file)\n",
    "            csv_file = bi5_file.replace('.bi5', '.csv')\n",
    "            bi5_to_csv(bi5_file, csv_file, timeframe)\n",
    "            csv_files.append(csv_file)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ تخطى {current.strftime('%Y-%m-%d')}: {e}\")\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "    merged_name = f\"{symbol}_{start_dt.date()}_{end_dt.date()}_merged.csv\"\n",
    "    merge_csv(csv_files, os.path.join(out_dir, merged_name))\n",
    "    print(f\"\\nAll files stored in: {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6cfe6-0118-4300-9469-a6c91d5f9461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
