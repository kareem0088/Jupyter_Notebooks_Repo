{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c99b59-d3dd-424c-90e9-b801733e8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# تثبيت والتحقق من مكتبات مشروع تصنيف الصور باستخدام CNN\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "def install_package(package_name):\n",
    "    \"\"\"تثبيت حزمة إذا لم تكن موجودة بالفعل\"\"\"\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"✓ الحزمة {package_name} مثبتة بالفعل\")\n",
    "    except ImportError:\n",
    "        print(f\"⏳ جاري تثبيت الحزمة {package_name}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "        print(f\"✓ تم تثبيت الحزمة {package_name} بنجاح\")\n",
    "\n",
    "# قائمة المكتبات المطلوبة للمشروع\n",
    "packages = [\n",
    "    \"os\",\n",
    "    \"numpy\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"scikit-learn\",\n",
    "    \"tensorflow\",\n",
    "    \"opencv-python\",\n",
    "    \"pillow\"\n",
    "]\n",
    "\n",
    "print(\"جاري التحقق من المكتبات المطلوبة وتثبيتها...\\n\")\n",
    "\n",
    "# تثبيت كل حزمة إذا لم تكن موجودة\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "# التحقق من الإصدارات\n",
    "print(\"\\nإصدارات المكتبات المثبتة:\")\n",
    "for package in packages:\n",
    "    try:\n",
    "        if package == \"os\":\n",
    "            import os\n",
    "            print(f\"os: مدمجة في بايثون\")\n",
    "        elif package == \"opencv-python\":\n",
    "            import cv2\n",
    "            print(f\"OpenCV: {cv2.__version__}\")\n",
    "        elif package == \"pillow\":\n",
    "            import PIL\n",
    "            print(f\"Pillow: {PIL.__version__}\")\n",
    "        else:\n",
    "            module = importlib.import_module(package)\n",
    "            print(f\"{package}: {module.__version__}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{package}: خطأ في معرفة الإصدار ({e})\")\n",
    "\n",
    "# التحقق من دعم GPU لتينسرفلو\n",
    "import tensorflow as tf\n",
    "print(\"\\nمعلومات TensorFlow:\")\n",
    "print(f\"TensorFlow الإصدار: {tf.__version__}\")\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(f\"الأجهزة المتاحة: {devices}\")\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"✓ يتم استخدام GPU للتدريب (موصى به)\")\n",
    "else:\n",
    "    print(\"⚠️ لا يوجد دعم GPU. سيتم استخدام CPU للتدريب (قد يكون أبطأ)\")\n",
    "\n",
    "print(\"\\n✓ تم التحقق من جميع المكتبات بنجاح! يمكنك الآن تشغيل نموذج CNN.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7159d-3174-4a10-a5cf-329534c15c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28acc55d-9464-4c28-9847-55b5bc2d121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Image folder paths - use relative paths or configurable paths\n",
    "CRACKS_PATH = r\"C:\\Users\\Access\\Documents\\crack_wall\"\n",
    "NO_CRACKS_PATH = r\"C:\\Users\\Access\\Documents\\non_crack_wall\"\n",
    "\n",
    "# Image dimensions\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# Load images function\n",
    "def load_images_from_folder(folder_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                img = img / 255.0\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and label images\n",
    "print(\"Loading images...\")\n",
    "crack_images, crack_labels = load_images_from_folder(CRACKS_PATH, 1)\n",
    "no_crack_images, no_crack_labels = load_images_from_folder(NO_CRACKS_PATH, 0)\n",
    "\n",
    "# Combine data\n",
    "X = np.concatenate((crack_images, no_crack_images), axis=0)\n",
    "y = np.concatenate((crack_labels, no_crack_labels), axis=0)\n",
    "\n",
    "# Split into train, validation, test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED, stratify=y_temp)\n",
    "\n",
    "print(f\"Total images: {len(X)}\")\n",
    "print(f\"Training images: {len(X_train)}\")\n",
    "print(f\"Validation images: {len(X_val)}\")\n",
    "print(f\"Test images: {len(X_test)}\")\n",
    "print(f\"Distribution - Cracks: {np.sum(y == 1)}, No Cracks: {np.sum(y == 0)}\")\n",
    "\n",
    "# Display sample images\n",
    "def display_sample_images(images, labels, n=5):\n",
    "    classes = [\"No Crack\", \"Crack\"]  # Fixed class names\n",
    "    fig, axes = plt.subplots(1, n, figsize=(15, 5))\n",
    "    for i in range(n):\n",
    "        idx = np.random.randint(0, len(images))\n",
    "        axes[i].imshow(images[idx])\n",
    "        axes[i].set_title(classes[labels[idx]])\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Sample training images:\")\n",
    "display_sample_images(X_train, y_train)\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "batch_size = 32\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Build CNN model\n",
    "def build_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dropout(0.1),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        #Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', \n",
    "                 tf.keras.metrics.Precision(name='precision'), \n",
    "                 tf.keras.metrics.Recall(name='recall'),\n",
    "                 tf.keras.metrics.AUC(name='auc')]  # Added AUC metric\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_cnn_model()\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1),\n",
    "    ModelCheckpoint('best_model_cracks.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "]\n",
    "\n",
    "# Train model\n",
    "epochs = 5  # Using early stopping for actual number of epochs\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "validation_steps = len(X_val) // batch_size\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save('cnn_crack_detection_model.keras')\n",
    "\n",
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'], loc='lower right')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper right')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot precision, recall and AUC\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    metrics_to_plot = ['precision', 'recall', 'auc']\n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        if metric in history.history:\n",
    "            plt.subplot(2, 2, i+1)\n",
    "            plt.plot(history.history[metric])\n",
    "            plt.plot(history.history[f'val_{metric}'])\n",
    "            plt.title(f'Model {metric.capitalize()}')\n",
    "            plt.ylabel(metric.capitalize())\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='best')\n",
    "            plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Evaluating model on test data...\")\n",
    "test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "metrics_names = model.metrics_names\n",
    "\n",
    "for name, value in zip(metrics_names, test_results):\n",
    "    print(f\"Test {name}: {value:.4f}\")\n",
    "\n",
    "# Find optimal threshold using validation data\n",
    "y_val_pred = model.predict(X_val).flatten()\n",
    "thresholds = np.arange(0.3, 0.8, 0.05)\n",
    "best_threshold = 0.75\n",
    "best_f1 = 0\n",
    "\n",
    "# Find optimal threshold based on F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "for threshold in thresholds:\n",
    "    y_val_classes = (y_val_pred > threshold).astype(int)\n",
    "    f1 = f1_score(y_val, y_val_classes)\n",
    "    print(f\"Threshold: {threshold:.2f}, F1: {f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.2f} with F1 score: {best_f1:.4f}\")\n",
    "\n",
    "# Predict with optimal threshold\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "y_pred_classes = (y_pred > best_threshold).astype(int)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Crack', 'Crack'], \n",
    "            yticklabels=['No Crack', 'Crack'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=['No Crack', 'Crack']))\n",
    "\n",
    "# Show predictions\n",
    "def display_predictions(images, true_labels, pred_labels, n=10):\n",
    "    classes = [\"No Crack\", \"Crack\"]  # Fixed class names\n",
    "    fig, axes = plt.subplots(2, n//2, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Find correct and incorrect predictions\n",
    "    correct = np.where(true_labels == pred_labels)[0]\n",
    "    incorrect = np.where(true_labels != pred_labels)[0]\n",
    "    \n",
    "    # Display correct predictions\n",
    "    for i in range(n//2):\n",
    "        if i < len(correct):\n",
    "            idx = correct[i]\n",
    "            axes[i].imshow(images[idx])\n",
    "            axes[i].set_title(f\"True: {classes[true_labels[idx]]}\\nPred: {classes[pred_labels[idx]]}\", color=\"green\")\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # Display incorrect predictions\n",
    "    for i in range(n//2, n):\n",
    "        j = i - n//2\n",
    "        if j < len(incorrect):\n",
    "            idx = incorrect[j]\n",
    "            axes[i].imshow(images[idx])\n",
    "            axes[i].set_title(f\"True: {classes[true_labels[idx]]}\\nPred: {classes[pred_labels[idx]]}\", color=\"red\")\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].axis('off')  # Hide empty plot\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Sample predictions:\")\n",
    "display_predictions(X_test, y_test, y_pred_classes)\n",
    "\n",
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
