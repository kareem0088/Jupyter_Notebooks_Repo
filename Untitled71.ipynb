{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b470e-e610-4577-8a0d-9791039e60db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207cd302-b8bd-473a-b18d-793095035a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053830e2-26d4-4aad-af3e-95863b15b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# تعيين بذرة عشوائية لضمان إمكانية تكرار النتائج\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# معلمات النموذج\n",
    "IMG_SIZE = 224  # حجم الصورة (MobileNetV2 يتوقع 224×224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "NUM_CLASSES = 2  # فئتان: رطوبة / لا رطوبة\n",
    "\n",
    "def create_dataset_structure(base_dir=\"wall_moisture_dataset\"):\n",
    "    \"\"\"إنشاء هيكل المجلدات اللازم للمشروع\"\"\"\n",
    "    \n",
    "    # إنشاء المجلدات الرئيسية\n",
    "    directories = [\n",
    "        os.path.join(base_dir, \"train\", \"moisture\"),\n",
    "        os.path.join(base_dir, \"train\", \"no_moisture\"),\n",
    "        os.path.join(base_dir, \"validation\", \"moisture\"),\n",
    "        os.path.join(base_dir, \"validation\", \"no_moisture\"),\n",
    "    ]\n",
    "    \n",
    "    # إنشاء المجلدات إذا لم تكن موجودة\n",
    "    for directory in directories:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        print(f\"تم إنشاء المجلد: {directory}\")\n",
    "    \n",
    "    return base_dir\n",
    "\n",
    "def organize_images(moisture_dir, no_moisture_dir, base_dir=\"wall_moisture_dataset\", split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    تنظيم الصور من مجلدي المصدر إلى مجلدات التدريب والتحقق\n",
    "    \n",
    "    المعلمات:\n",
    "    - moisture_dir: مجلد يحتوي على صور الحوائط بها رطوبة\n",
    "    - no_moisture_dir: مجلد يحتوي على صور الحوائط ليس بها رطوبة\n",
    "    - base_dir: المجلد الأساسي لمجموعة البيانات المنظمة\n",
    "    - split_ratio: نسبة الانقسام بين بيانات التدريب والتحقق (افتراضيا 80% للتدريب)\n",
    "    \"\"\"\n",
    "    # التحقق من وجود المجلدات المصدرية\n",
    "    if not os.path.exists(moisture_dir):\n",
    "        print(f\"خطأ: مجلد الصور التي بها رطوبة {moisture_dir} غير موجود!\")\n",
    "        return False\n",
    "        \n",
    "    if not os.path.exists(no_moisture_dir):\n",
    "        print(f\"خطأ: مجلد الصور التي ليس بها رطوبة {no_moisture_dir} غير موجود!\")\n",
    "        return False\n",
    "    \n",
    "    # إنشاء بنية المجلدات\n",
    "    create_dataset_structure(base_dir)\n",
    "    \n",
    "    # معالجة مجلد الصور التي بها رطوبة\n",
    "    print(\"جاري تنظيم الصور التي بها رطوبة...\")\n",
    "    image_files = [f for f in os.listdir(moisture_dir) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
    "    \n",
    "    # خلط الصور بشكل عشوائي\n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    # تقسيم الصور بين التدريب والتحقق\n",
    "    split_idx = int(len(image_files) * split_ratio)\n",
    "    train_files = image_files[:split_idx]\n",
    "    val_files = image_files[split_idx:]\n",
    "    \n",
    "    # نسخ ملفات التدريب\n",
    "    print(f\"جاري نسخ {len(train_files)} صورة رطوبة إلى مجلد التدريب...\")\n",
    "    for img_file in tqdm(train_files):\n",
    "        src_path = os.path.join(moisture_dir, img_file)\n",
    "        dst_path = os.path.join(base_dir, \"train\", \"moisture\", img_file)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    # نسخ ملفات التحقق\n",
    "    print(f\"جاري نسخ {len(val_files)} صورة رطوبة إلى مجلد التحقق...\")\n",
    "    for img_file in tqdm(val_files):\n",
    "        src_path = os.path.join(moisture_dir, img_file)\n",
    "        dst_path = os.path.join(base_dir, \"validation\", \"moisture\", img_file)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    # معالجة مجلد الصور التي ليس بها رطوبة\n",
    "    print(\"\\nجاري تنظيم الصور التي ليس بها رطوبة...\")\n",
    "    image_files = [f for f in os.listdir(no_moisture_dir) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
    "    \n",
    "    # خلط الصور بشكل عشوائي\n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    # تقسيم الصور بين التدريب والتحقق\n",
    "    split_idx = int(len(image_files) * split_ratio)\n",
    "    train_files = image_files[:split_idx]\n",
    "    val_files = image_files[split_idx:]\n",
    "    \n",
    "    # نسخ ملفات التدريب\n",
    "    print(f\"جاري نسخ {len(train_files)} صورة بدون رطوبة إلى مجلد التدريب...\")\n",
    "    for img_file in tqdm(train_files):\n",
    "        src_path = os.path.join(no_moisture_dir, img_file)\n",
    "        dst_path = os.path.join(base_dir, \"train\", \"no_moisture\", img_file)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    # نسخ ملفات التحقق\n",
    "    print(f\"جاري نسخ {len(val_files)} صورة بدون رطوبة إلى مجلد التحقق...\")\n",
    "    for img_file in tqdm(val_files):\n",
    "        src_path = os.path.join(no_moisture_dir, img_file)\n",
    "        dst_path = os.path.join(base_dir, \"validation\", \"no_moisture\", img_file)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    # طباعة ملخص\n",
    "    print(\"\\nتم الانتهاء من تنظيم مجموعة البيانات!\")\n",
    "    for split in [\"train\", \"validation\"]:\n",
    "        for category in [\"moisture\", \"no_moisture\"]:\n",
    "            dir_path = os.path.join(base_dir, split, category)\n",
    "            count = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])\n",
    "            print(f\"{split}/{category}: {count} صورة\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def create_data_generators(base_dir=\"wall_moisture_dataset\"):\n",
    "    \"\"\"إنشاء مولدات البيانات للتدريب والتحقق\"\"\"\n",
    "    \n",
    "    # مسارات المجلدات\n",
    "    train_dir = os.path.join(base_dir, \"train\")\n",
    "    validation_dir = os.path.join(base_dir, \"validation\")\n",
    "    \n",
    "    # تعزيز البيانات للتدريب\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,  # تطبيع البيانات\n",
    "        rotation_range=20,  # دوران عشوائي\n",
    "        width_shift_range=0.2,  # إزاحة أفقية\n",
    "        height_shift_range=0.2,  # إزاحة رأسية\n",
    "        shear_range=0.2,  # قص\n",
    "        zoom_range=0.2,  # تكبير/تصغير\n",
    "        horizontal_flip=True,  # انعكاس أفقي\n",
    "        fill_mode='nearest'  # طريقة ملء البكسلات المفقودة\n",
    "    )\n",
    "    \n",
    "    # للتحقق، نقوم فقط بتطبيع البيانات دون تعزيز\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # قراءة بيانات التدريب\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # قراءة بيانات التحقق\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"بناء النموذج باستخدام التعلم التحويلي (Transfer Learning) مع MobileNetV2\"\"\"\n",
    "    \n",
    "    # استدعاء النموذج الأساسي MobileNetV2 (مدرب مسبقاً على ImageNet)\n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # تجميد طبقات النموذج الأساسي\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # بناء النموذج الكامل\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),  # للمساعدة في منع فرط التعلم (Overfitting)\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # تجميع النموذج\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, train_generator, validation_generator):\n",
    "    \"\"\"تدريب النموذج\"\"\"\n",
    "    \n",
    "    # تحضير مسار حفظ أفضل نموذج\n",
    "    checkpoint_path = \"best_moisture_model.h5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # التوقف المبكر لمنع فرط التعلم\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # تقليل معدل التعلم عند توقف التحسن\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # تدريب النموذج\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[checkpoint, early_stop, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def evaluate_and_plot(model, history, validation_generator):\n",
    "    \"\"\"تقييم النموذج ورسم نتائج التدريب\"\"\"\n",
    "    \n",
    "    # تقييم النموذج على بيانات التحقق\n",
    "    evaluation = model.evaluate(validation_generator)\n",
    "    print(f\"Loss: {evaluation[0]:.4f}, Accuracy: {evaluation[1]:.4f}\")\n",
    "    \n",
    "    # رسم دقة التدريب والتحقق\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('دقة النموذج')\n",
    "    plt.ylabel('الدقة')\n",
    "    plt.xlabel('الحقبة')\n",
    "    plt.legend(['التدريب', 'التحقق'], loc='upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('خسارة النموذج')\n",
    "    plt.ylabel('الخسارة')\n",
    "    plt.xlabel('الحقبة')\n",
    "    plt.legend(['التدريب', 'التحقق'], loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_results.png')\n",
    "    plt.show()\n",
    "\n",
    "def predict_single_image(model, image_path):\n",
    "    \"\"\"التنبؤ بتصنيف صورة واحدة وعرض النتيجة\"\"\"\n",
    "    \n",
    "    # تحميل ومعالجة الصورة\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    \n",
    "    # التنبؤ باستخدام النموذج\n",
    "    prediction = model.predict(img_array)\n",
    "    class_idx = np.argmax(prediction[0])\n",
    "    \n",
    "    # الحصول على الفئة والثقة\n",
    "    confidence = prediction[0][class_idx] * 100\n",
    "    class_labels = [\"moisture\", \"no_moisture\"]  # ترتيب الفئات حسب مولد البيانات\n",
    "    class_name = class_labels[class_idx]\n",
    "    arabic_class = \"يوجد رطوبة\" if class_name == \"moisture\" else \"لا يوجد رطوبة\"\n",
    "    \n",
    "    # عرض الصورة مع التنبؤ\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"التصنيف: {arabic_class} (الثقة: {confidence:.2f}%)\", fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"التصنيف: {arabic_class}\")\n",
    "    print(f\"الثقة: {confidence:.2f}%\")\n",
    "    print(f\"احتمالية وجود رطوبة: {prediction[0][0]*100:.2f}%\")\n",
    "    print(f\"احتمالية عدم وجود رطوبة: {prediction[0][1]*100:.2f}%\")\n",
    "\n",
    "def batch_predict(model, images_dir):\n",
    "    \"\"\"التنبؤ بتصنيف مجموعة من الصور\"\"\"\n",
    "    \n",
    "    if not os.path.exists(images_dir):\n",
    "        print(f\"المجلد {images_dir} غير موجود!\")\n",
    "        return\n",
    "    \n",
    "    # الحصول على قائمة بجميع ملفات الصور\n",
    "    image_files = [f for f in os.listdir(images_dir) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"لا توجد صور في المجلد المحدد!\")\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"جاري التنبؤ بتصنيف {len(image_files)} صورة...\")\n",
    "    for img_file in tqdm(image_files):\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        \n",
    "        try:\n",
    "            # تحميل ومعالجة الصورة\n",
    "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "            \n",
    "            # التنبؤ باستخدام النموذج\n",
    "            prediction = model.predict(img_array, verbose=0)\n",
    "            class_idx = np.argmax(prediction[0])\n",
    "            \n",
    "            # الحصول على الفئة والثقة\n",
    "            confidence = prediction[0][class_idx] * 100\n",
    "            class_labels = [\"moisture\", \"no_moisture\"]  # ترتيب الفئات حسب مولد البيانات\n",
    "            class_name = class_labels[class_idx]\n",
    "            arabic_class = \"يوجد رطوبة\" if class_name == \"moisture\" else \"لا يوجد رطوبة\"\n",
    "            \n",
    "            # تخزين النتائج\n",
    "            results.append({\n",
    "                \"file\": img_file,\n",
    "                \"prediction\": class_name,\n",
    "                \"arabic_prediction\": arabic_class,\n",
    "                \"confidence\": confidence\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"خطأ في معالجة الصورة {img_path}: {e}\")\n",
    "    \n",
    "    # عرض النتائج\n",
    "    moisture_count = sum(1 for r in results if r[\"prediction\"] == \"moisture\")\n",
    "    no_moisture_count = sum(1 for r in results if r[\"prediction\"] == \"no_moisture\")\n",
    "    \n",
    "    print(\"\\n=== نتائج التنبؤ ===\")\n",
    "    print(f\"إجمالي الصور: {len(results)}\")\n",
    "    print(f\"عدد الصور التي تحتوي على رطوبة: {moisture_count} ({moisture_count/len(results)*100:.1f}%)\")\n",
    "    print(f\"عدد الصور التي لا تحتوي على رطوبة: {no_moisture_count} ({no_moisture_count/len(results)*100:.1f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def fine_tune_model(model, train_generator, validation_generator):\n",
    "    \"\"\"تحسين النموذج بعد التدريب الأولي عن طريق إلغاء تجميد بعض طبقات النموذج الأساسي\"\"\"\n",
    "    \n",
    "    # تجميد النصف الأسفل من طبقات النموذج الأساسي وإلغاء تجميد النصف الأعلى\n",
    "    base_model = model.layers[0]\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # تجميد الطبقات السفلية وترك الطبقات العليا قابلة للتدريب\n",
    "    for layer in base_model.layers[:100]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[100:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # إعادة تجميع النموذج بمعدل تعلم أقل\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.0001),  # معدل تعلم أقل للضبط الدقيق\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # تحضير مسار حفظ أفضل نموذج\n",
    "    checkpoint_path = \"best_fine_tuned_model.h5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # التوقف المبكر\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # تقليل معدل التعلم\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # تدريب النموذج (الضبط الدقيق)\n",
    "    print(\"\\nجاري الضبط الدقيق للنموذج...\")\n",
    "    history_fine = model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,  # عدد أقل من الحقب للضبط الدقيق\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[checkpoint, early_stop, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    return model, history_fine\n",
    "\n",
    "def main():\n",
    "    \"\"\"الوظيفة الرئيسية\"\"\"\n",
    "    \n",
    "    print(\"=== برنامج تصنيف صور الرطوبة في الحوائط ===\\n\")\n",
    "    \n",
    "    # التحقق من وجود بطاقة رسومات GPU وإعدادها\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if physical_devices:\n",
    "        print(f\"تم العثور على {len(physical_devices)} وحدة GPU. جاري تكوينها...\")\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "        print(\"تم تكوين وحدة GPU بنجاح.\\n\")\n",
    "    else:\n",
    "        print(\"لم يتم العثور على GPU. سيتم التدريب على وحدة المعالجة المركزية CPU.\\n\")\n",
    "    \n",
    "    # طلب المعلومات من المستخدم\n",
    "    moisture_dir = input(\"أدخل مسار المجلد الذي يحتوي على صور الحوائط بها رطوبة: \")\n",
    "    no_moisture_dir = input(\"أدخل مسار المجلد الذي يحتوي على صور الحوائط بدون رطوبة: \")\n",
    "    \n",
    "    base_dir = input(\"أدخل مسار المجلد الذي تريد إنشاء مجموعة البيانات المنظمة فيه (افتراضيًا: wall_moisture_dataset): \")\n",
    "    if not base_dir.strip():\n",
    "        base_dir = \"wall_moisture_dataset\"\n",
    "    \n",
    "    # تنظيم الصور\n",
    "    print(\"\\nجاري تنظيم مجموعة البيانات...\")\n",
    "    success = organize_images(moisture_dir, no_moisture_dir, base_dir)\n",
    "    \n",
    "    if not success:\n",
    "        print(\"فشل تنظيم مجموعة البيانات. يرجى التحقق من المسارات والمحاولة مرة أخرى.\")\n",
    "        return\n",
    "    \n",
    "    # إنشاء مولدات البيانات\n",
    "    print(\"\\nجاري إنشاء مولدات البيانات...\")\n",
    "    train_generator, validation_generator = create_data_generators(base_dir)\n",
    "    \n",
    "    # بناء النموذج\n",
    "    print(\"\\nجاري بناء النموذج...\")\n",
    "    model = build_model()\n",
    "    print(\"تم بناء النموذج:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # تدريب النموذج\n",
    "    print(\"\\nبدء تدريب النموذج...\")\n",
    "    model, history = train_model(model, train_generator, validation_generator)\n",
    "    \n",
    "    # تقييم النموذج ورسم النتائج\n",
    "    print(\"\\nتقييم النموذج...\")\n",
    "    evaluate_and_plot(model, history, validation_generator)\n",
    "    \n",
    "    # سؤال المستخدم إذا كان يريد تحسين النموذج\n",
    "    fine_tune_option = input(\"\\nهل ترغب في إجراء ضبط دقيق للنموذج لتحسين الأداء؟ (نعم/لا): \")\n",
    "    \n",
    "    if fine_tune_option.lower() in ['نعم', 'y', 'yes']:\n",
    "        model, history_fine = fine_tune_model(model, train_generator, validation_generator)\n",
    "        print(\"\\nتقييم النموذج بعد الضبط الدقيق...\")\n",
    "        evaluate_and_plot(model, history_fine, validation_generator)\n",
    "    \n",
    "    # حفظ النموذج النهائي\n",
    "    final_model_path = \"wall_moisture_classifier_final.h5\"\n",
    "    model.save(final_model_path)\n",
    "    print(f\"\\nتم حفظ النموذج النهائي في {final_model_path}\")\n",
    "    \n",
    "    # سؤال المستخدم إذا كان يريد اختبار النموذج على صورة\n",
    "    test_option = input(\"\\nهل ترغب في اختبار النموذج على صورة واحدة؟ (نعم/لا): \")\n",
    "    \n",
    "    if test_option.lower() in ['نعم', 'y', 'yes']:\n",
    "        image_path = input(\"أدخل مسار الصورة التي تريد اختبارها: \")\n",
    "        if os.path.exists(image_path):\n",
    "            predict_single_image(model, image_path)\n",
    "        else:\n",
    "            print(\"مسار الصورة غير صحيح!\")\n",
    "    \n",
    "    # سؤال المستخدم إذا كان يريد التنبؤ بمجموعة صور\n",
    "    batch_test_option = input(\"\\nهل ترغب في اختبار النموذج على مجلد كامل من الصور؟ (نعم/لا): \")\n",
    "    \n",
    "    if batch_test_option.lower() in ['نعم', 'y', 'yes']:\n",
    "        images_dir = input(\"أدخل مسار المجلد الذي يحتوي على الصور التي تريد تصنيفها: \")\n",
    "        if os.path.exists(images_dir):\n",
    "            batch_predict(model, images_dir)\n",
    "        else:\n",
    "            print(\"مسار المجلد غير صحيح!\")\n",
    "    \n",
    "    print(\"\\nانتهى البرنامج. يمكنك استخدام النموذج المحفوظ لاحقًا باستدعائه:\")\n",
    "    print(f\"model = tf.keras.models.load_model('{final_model_path}')\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
