{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8542f79-1a19-49d8-92a6-bef68dcf4b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select main category:\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter category number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected category: Metals\n",
      "\n",
      "Select instrument:\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter instrument number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected instrument: XAUUSD\n",
      "\n",
      "1. Candlestick\n",
      "2. Tick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose data type (number):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select timeframe:  3\n",
      "Enter start date (YYYY-MM-DD):  2020-01-01\n",
      "Enter end date   (YYYY-MM-DD):  2020-01-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2020-01-01...\n",
      "âš ï¸ ØªØ®Ø·Ù‰ 15m_candles.bi5: HTTP 404\n",
      "\n",
      "Processing 2020-01-02...\n",
      "âš ï¸ ØªØ®Ø·Ù‰ 15m_candles.bi5: HTTP 404\n",
      "\n",
      "Processing 2020-01-03...\n",
      "âš ï¸ ØªØ®Ø·Ù‰ 15m_candles.bi5: HTTP 404\n",
      "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª CSV Ù„Ø¯Ù…Ø¬Ù‡Ø§.\n",
      "\n",
      "All files stored in: C:\\Users\\Access\\downloads\\XAUUSD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "BASE_URL = 'https://datafeed.dukascopy.com/datafeed'\n",
    "CATEGORIES = {\n",
    "    'Metals':  ['XAUUSD', 'XAGUSD'],\n",
    "    'Forex':   ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDUSD'],\n",
    "    'Indices': ['DAX', 'SP500'],\n",
    "}\n",
    "TIMEFRAMES = {\n",
    "    '1m':  '1m', \n",
    "    '5m':  '5m', \n",
    "    '15m': '15m', \n",
    "    '1h':  '1h', \n",
    "    '4h':  '4h', \n",
    "    '1d':  '1d',\n",
    "}\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ù…Ø¹ Ø±Ø¤ÙˆØ³ Ù…ØªØµÙØ­ ÙØ¹Ù„ÙŠØ©\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/115.0.0.0 Safari/537.36',\n",
    "    'Referer': 'https://www.dukascopy.com/trading-tools/widgets/quotes/historical_data_feed'\n",
    "})\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def select_option(options, prompt_text):\n",
    "    for idx, opt in enumerate(options, 1):\n",
    "        print(f\"{idx}. {opt}\")\n",
    "    while True:\n",
    "        choice = input(prompt_text).strip()\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return options[int(choice) - 1]\n",
    "        print(\"Ø§Ø®ØªÙŠØ§Ø± ØºÙŠØ± ØµØ§Ù„Ø­ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.\")\n",
    "\n",
    "def build_urls(symbol, date_dt, data_type, timeframe=None):\n",
    "    \"\"\"\n",
    "    ÙŠÙØ±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø±ÙˆØ§Ø¨Ø· .bi5:\n",
    "    - Candles:   [{tf_code}_candles.bi5]\n",
    "    - Ticks:     [0h_ticks.bi5, 1h_ticks.bi5, ..., 23h_ticks.bi5]\n",
    "    \"\"\"\n",
    "    y = date_dt.year\n",
    "    m = f\"{date_dt.month - 1:02d}\"\n",
    "    d = f\"{date_dt.day:02d}\"\n",
    "    base_path = f\"{symbol}/{y}/{m}/{d}\"\n",
    "    \n",
    "    urls = []\n",
    "    if data_type == 'Candlestick':\n",
    "        tf_code = timeframe\n",
    "        urls.append(f\"{BASE_URL}/{base_path}/{tf_code}_candles.bi5\")\n",
    "    else:\n",
    "        # Ù„ÙƒÙ„ Ø³Ø§Ø¹Ø© Ù…Ù„Ù ticks\n",
    "        for hour in range(24):\n",
    "            urls.append(f\"{BASE_URL}/{base_path}/{hour:02d}h_ticks.bi5\")\n",
    "    return urls\n",
    "\n",
    "def download_bi5(url, dest_path):\n",
    "    resp = session.get(url, stream=True)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f\"HTTP {resp.status_code}\")\n",
    "    total = resp.headers.get('content-length')\n",
    "    total = int(total) if total and total.isdigit() else None\n",
    "\n",
    "    with open(dest_path, 'wb') as f, tqdm(\n",
    "        total=total, unit='iB', unit_scale=True,\n",
    "        desc=os.path.basename(dest_path),\n",
    "        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\"\n",
    "    ) as bar:\n",
    "        for chunk in resp.iter_content(1024):\n",
    "            if not chunk:\n",
    "                break\n",
    "            f.write(chunk)\n",
    "            bar.update(len(chunk))\n",
    "\n",
    "    if os.path.getsize(dest_path) == 0:\n",
    "        os.remove(dest_path)\n",
    "        raise RuntimeError(\"Ø§Ù„Ù…Ù„Ù ÙØ§Ø±Øº\")\n",
    "\n",
    "def bi5_to_csv(bi5_path, csv_path, data_type, timeframe=None):\n",
    "    \"\"\"\n",
    "    ÙÙƒ Ø¶ØºØ· .bi5 ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ CSV.\n",
    "    â€¢ Ù„Ù„Ø´Ù…ÙˆØ¹: ÙŠÙÙƒÙ‘ Ø­Ø³Ø¨ tf_ms\n",
    "    â€¢ Ù„Ù„ØªÙŠÙƒ: ÙŠØ­ÙˆÙ‘Ù„ ÙƒÙ„ Ø³Ø·Ø± Ø¥Ù„Ù‰ ØµÙ Ù…Ø³ØªÙ‚Ù„ (ÙƒÙ„ Ø³Ø¬Ù„ 20 Ø¨Ø§ÙŠØª ÙŠØ¸Ù‡Ø± Ù†Ù‚Ø·Ø© ØªÙŠÙƒ)\n",
    "    \"\"\"\n",
    "    # Ù…ØµÙÙˆÙØ© Ø²Ù…Ù†ÙŠØ© Ù„Ù„Ø´Ù…ÙˆØ¹\n",
    "    tf_ms = {\n",
    "        '1m': 60_000, '5m': 5*60_000, '15m': 15*60_000,\n",
    "        '1h': 3600_000, '4h': 4*3600_000, '1d': 86400_000\n",
    "    }.get(timeframe, None)\n",
    "\n",
    "    with lzma.open(bi5_path) as fin, open(csv_path, 'w', newline='') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        # Ø£Ø¹Ù…Ø¯Ø© Ù…Ø´ØªØ±ÙƒØ©\n",
    "        if data_type == 'Candlestick':\n",
    "            writer.writerow(['Gmt time','Open','High','Low','Close','Volume'])\n",
    "        else:\n",
    "            writer.writerow(['Gmt time','Bid','Ask','BidVolume','AskVolume'])\n",
    "        \n",
    "        record_size = 8 + (5*4 if data_type=='Candlestick' else 4*4)\n",
    "        while True:\n",
    "            chunk = fin.read(record_size)\n",
    "            if len(chunk) < record_size:\n",
    "                break\n",
    "            if data_type == 'Candlestick':\n",
    "                t_ms, o, h, l, c, v = struct.unpack('>Qffffi', chunk)\n",
    "                row = [t_ms, o, h, l, c, v]\n",
    "            else:\n",
    "                # Ù‡ÙŠÙƒÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠÙƒ: Q f f i i  \n",
    "                t_ms, bid, ask, biv, av = struct.unpack('>Qffii', chunk)\n",
    "                row = [t_ms, bid, ask, biv, av]\n",
    "\n",
    "            # Ø­ÙˆÙ„ Ø§Ù„Ø²Ù…Ù† Ø¥Ù„Ù‰ Ù†Øµ\n",
    "            row[0] = datetime.utcfromtimestamp(row[0]/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            writer.writerow(row)\n",
    "\n",
    "def merge_csv(csv_files, out_path):\n",
    "    if not csv_files:\n",
    "        print(\"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª CSV Ù„Ø¯Ù…Ø¬Ù‡Ø§.\")\n",
    "        return\n",
    "    dfs = [pd.read_csv(f, parse_dates=[0]) for f in csv_files]\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "    all_df.sort_values(all_df.columns[0], inplace=True)\n",
    "    all_df.to_csv(out_path, index=False)\n",
    "    print(f\"\\nâœ”ï¸ ØªÙ… Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {out_path}\")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def main():\n",
    "    print(\"Select main category:\")\n",
    "    category = select_option(list(CATEGORIES.keys()), \"Enter category number: \")\n",
    "    print(f\"Selected category: {category}\\n\")\n",
    "\n",
    "    print(\"Select instrument:\")\n",
    "    symbol = select_option(CATEGORIES[category], \"Enter instrument number: \")\n",
    "    print(f\"Selected instrument: {symbol}\\n\")\n",
    "\n",
    "    data_type = select_option(['Candlestick', 'Tick'], \"Choose data type (number): \")\n",
    "    timeframe = None\n",
    "    if data_type == 'Candlestick':\n",
    "        timeframe = select_option(list(TIMEFRAMES.keys()), \"Select timeframe: \")\n",
    "\n",
    "    start_dt = datetime.strptime(input(\"Enter start date (YYYY-MM-DD): \").strip(), '%Y-%m-%d')\n",
    "    end_dt   = datetime.strptime(input(\"Enter end date   (YYYY-MM-DD): \").strip(), '%Y-%m-%d')\n",
    "\n",
    "    out_dir = os.path.join(os.getcwd(), 'downloads', symbol)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    csv_files = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        print(f\"\\nProcessing {current.strftime('%Y-%m-%d')}...\")\n",
    "        urls = build_urls(symbol, current, data_type, timeframe)\n",
    "        for url in urls:\n",
    "            filename = os.path.basename(url)\n",
    "            bi5_path = os.path.join(out_dir, filename)\n",
    "            try:\n",
    "                download_bi5(url, bi5_path)\n",
    "                csv_name = filename.replace('.bi5', '.csv')\n",
    "                csv_path = os.path.join(out_dir, csv_name)\n",
    "                bi5_to_csv(bi5_path, csv_path, data_type, timeframe)\n",
    "                csv_files.append(csv_path)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ ØªØ®Ø·Ù‰ {filename}: {e}\")\n",
    "\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "    merged_name = f\"{symbol}_{start_dt.date()}_{end_dt.date()}_merged.csv\"\n",
    "    merge_csv(csv_files, os.path.join(out_dir, merged_name))\n",
    "    print(f\"\\nAll files stored in: {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6287a84-b5f7-4d44-bbb3-9da175ace15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Dukascopy Downloader Tool\n",
      "========================================\n",
      "\n",
      "ğŸ”¹ Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2020-01-01\n",
      "End date (e.g. 2020-01-01):  2020-01-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Config: XAUUSD, Tick, 2020-01-01â€“2020-01-02, GMT0\n",
      "\n",
      "ğŸ”¹ Select price type\n",
      "1. Bid ÙÙ‚Ø·\n",
      "2. Ask ÙÙ‚Ø·\n",
      "3. ÙƒÙ„Ø§Ù‡Ù…Ø§\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Starting tick download for XAUUSD...\n",
      "ğŸ“… Date range: 2020-01-01 to 2020-01-02\n",
      "â° GMT offset: 0\n",
      "[==================================================] 100.00% |   0.45MB of   1.41MB | ETA: 0h 0m 0s\n",
      "\n",
      "ğŸ“Š Summary: Hours 48, Success 24, Ticks 122574\n",
      "âœ… Saved: C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_tick_merged.csv (6.20 MB)\n",
      "\n",
      "âœ… Download process finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ==========\n",
    "DEFAULT_SAVE_PATH = os.getcwd()\n",
    "CATEGORIES = {\n",
    "    \"Metals\":  [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\":   [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"60\",\n",
    "    \"5m\": \"300\",\n",
    "    \"15m\": \"900\",\n",
    "    \"1h\": \"3600\",\n",
    "    \"4h\": \"14400\",\n",
    "    \"1d\": \"86400\"\n",
    "}\n",
    "\n",
    "# ========== ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\nğŸ”¹ {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            print(\"âŒ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"âŒ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"âŒ Invalid date format.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "def format_seconds(seconds):\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„ ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total) if total else 0\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = downloaded_bytes / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(\n",
    "        f\"\\r[{bar}] {percent:6.2f}% | \"\n",
    "        f\"{downloaded_mb:6.2f}MB of {total_est_mb:6.2f}MB | \"\n",
    "        f\"ETA: {format_seconds(remaining)}\"\n",
    "    )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Tick ==========\n",
    "def download_tick(symbol, start, end, price_type, gmt_offset, save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024\n",
    "    successful = 0\n",
    "\n",
    "    print(f\"\\nğŸ”„ Starting tick download for {symbol}...\")\n",
    "    print(f\"ğŸ“… Date range: {start.date()} to {end.date()}\")\n",
    "    print(f\"â° GMT offset: {gmt_offset}\")\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = (\n",
    "                f\"https://datafeed.dukascopy.com/datafeed/\"\n",
    "                f\"{symbol}/{day.year}/{day.month-1:02d}/{day.day:02d}/\"\n",
    "                f\"{hour:02d}h_ticks.bi5\"\n",
    "            )\n",
    "            try:\n",
    "                r = requests.get(url, timeout=15)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    successful += 1\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    for i in range(0, len(data), 20):\n",
    "                        chunk = data[i:i+20]\n",
    "                        if len(chunk) < 20: continue\n",
    "                        t_off, ask, bid, ask_vol, bid_vol = struct.unpack(\">IffII\", chunk)\n",
    "                        tick_time = day + timedelta(hours=hour, milliseconds=t_off) + timedelta(hours=gmt_offset)\n",
    "                        ts = tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                        if price_type == \"Bid ÙÙ‚Ø·\":\n",
    "                            row = [ts, round(bid,5), bid_vol]\n",
    "                        elif price_type == \"Ask ÙÙ‚Ø·\":\n",
    "                            row = [ts, round(ask,5), ask_vol]\n",
    "                        else:\n",
    "                            row = [ts, round(bid,5), round(ask,5), bid_vol, ask_vol]\n",
    "                        all_ticks.append(row)\n",
    "                # else skip silently\n",
    "            except Exception as e:\n",
    "                print(f\"\\nâš ï¸ Warning: {day.date()} {hour}h -> {e}\")\n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\nğŸ“Š Summary: Hours {count}, Success {successful}, Ticks {len(all_ticks)}\")\n",
    "    out_file = os.path.join(save_path, f\"{symbol}_tick_merged.csv\")\n",
    "    with open(out_file, \"w\", newline='', encoding='utf-8') as f:\n",
    "        w = csv.writer(f)\n",
    "        if price_type==\"Bid ÙÙ‚Ø·\":\n",
    "            w.writerow([\"datetime\",\"bid\",\"bid_volume\"])\n",
    "        elif price_type==\"Ask ÙÙ‚Ø·\":\n",
    "            w.writerow([\"datetime\",\"ask\",\"ask_volume\"])\n",
    "        else:\n",
    "            w.writerow([\"datetime\",\"bid\",\"ask\",\"bid_volume\",\"ask_volume\"])\n",
    "        if all_ticks:\n",
    "            all_ticks.sort(key=lambda x: x[0])\n",
    "            w.writerows(all_ticks)\n",
    "    size = os.path.getsize(out_file)/(1024*1024)\n",
    "    print(f\"âœ… Saved: {out_file} ({size:.2f} MB)\")\n",
    "\n",
    "# ========== ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Candlestick ==========\n",
    "def download_candles(symbol, tf_code, start, end, gmt_offset, save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024\n",
    "    successful = 0\n",
    "\n",
    "    print(f\"\\nğŸ”„ Starting candle download for {symbol}...\")\n",
    "    print(f\"ğŸ“… Date range: {start.date()} to {end.date()}\")\n",
    "    print(f\"â° GMT offset: {gmt_offset}, Code: {tf_code}\")\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = (\n",
    "            f\"https://datafeed.dukascopy.com/datafeed/\"\n",
    "            f\"{symbol}/{day.year}/{day.month-1:02d}/{day.day:02d}/\"\n",
    "            f\"{tf_code}_candles.bi5\"\n",
    "        )\n",
    "        try:\n",
    "            r = requests.get(url, timeout=15)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                successful += 1\n",
    "                downloaded_bytes += len(r.content)\n",
    "                data = lzma.decompress(r.content)\n",
    "                for i in range(0, len(data), 24):\n",
    "                    chunk = data[i:i+24]\n",
    "                    if len(chunk) < 24: continue\n",
    "                    utc_off, o, h, l, c, v = struct.unpack(\">IffffI\", chunk)\n",
    "                    tm = day + timedelta(seconds=utc_off) + timedelta(hours=gmt_offset)\n",
    "                    ts = tm.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    all_data.append([ts, round(o,5), round(h,5), round(l,5), round(c,5), v])\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸ Warning: {day.date()} -> {e}\")\n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\nğŸ“Š Summary: Days {count}, Success {successful}, Candles {len(all_data)}\")\n",
    "    out_file = os.path.join(save_path, f\"{symbol}_candles_{tf_code}_merged.csv\")\n",
    "    with open(out_file, \"w\", newline='', encoding='utf-8') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"datetime\",\"open\",\"high\",\"low\",\"close\",\"volume\"])\n",
    "        if all_data:\n",
    "            all_data.sort(key=lambda x: x[0])\n",
    "            w.writerows(all_data)\n",
    "    size = os.path.getsize(out_file)/(1024*1024)\n",
    "    print(f\"âœ… Saved: {out_file} ({size:.2f} MB)\")\n",
    "\n",
    "# ========== Main ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nğŸ“Š Dukascopy Downloader Tool\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    data_type = show_menu([\"Tick\",\"Candlestick\"], \"Select data type\")\n",
    "    category  = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "    symbol    = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "    gmt_off   = get_gmt_offset()\n",
    "    start     = get_date_input(\"Start date\")\n",
    "    end       = get_date_input(\"End date\")\n",
    "    if start > end:\n",
    "        print(\"âŒ End date must be on or after start date.\"); sys.exit(1)\n",
    "    save_dir = os.path.join(DEFAULT_SAVE_PATH, \"downloads\", symbol)\n",
    "\n",
    "    print(f\"\\nğŸ“ Config: {symbol}, {data_type}, {start.date()}â€“{end.date()}, GMT{gmt_off}\")\n",
    "    if data_type == \"Tick\":\n",
    "        price = show_menu([\"Bid ÙÙ‚Ø·\",\"Ask ÙÙ‚Ø·\",\"ÙƒÙ„Ø§Ù‡Ù…Ø§\"], \"Select price type\")\n",
    "        download_tick(symbol, start, end, price, gmt_off, save_dir)\n",
    "    else:\n",
    "        tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "        code = CANDLE_FRAME_CODES[tf]\n",
    "        download_candles(symbol, code, start, end, gmt_off, save_dir)\n",
    "\n",
    "    print(\"\\nâœ… Download process finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ec0b9e-19fe-48d0-ad00-fb06e49d3c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select main category:\n",
      "  1. Metals\n",
      "  2. Forex\n",
      "  3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select instrument:\n",
      "  1. XAUUSD\n",
      "  2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose data type:\n",
      "  1. Candlestick\n",
      "  2. Tick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select timeframe:\n",
      "  1. 1m\n",
      "  2. 5m\n",
      "  3. 15m\n",
      "  4. 1h\n",
      "  5. 4h\n",
      "  6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  2\n",
      "Start date (YYYYâ€‘MMâ€‘DD):  2020-01-01\n",
      "End date (YYYYâ€‘MMâ€‘DD):  2020-01-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2020-01-01 (1/2)...\n",
      "[####################--------------------]  50.0%  0.00MB/20.00MB ETA 0h0m1s\n",
      "Processing 2020-01-02 (2/2)...\n",
      "[########################################] 100.0%  0.00MB/20.00MB ETA 0h0m0s\n",
      "âš ï¸ No data to merge.\n",
      "\n",
      "âœ… Saved merged CSV: C:\\Users\\Access\\downloads\\XAGUSD\\XAGUSD_2020-01-01_2020-01-02_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 1) Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©: ØªØµÙ†ÙŠÙØ§Øª ÙˆØ£Ø¯ÙˆØ§Øª ÙˆØ£Ø·Ø± Ø²Ù…Ù†ÙŠØ©\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "CATEGORIES = {\n",
    "    \"Metals\":  [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\":   [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "\n",
    "BASE_URL = \"https://datafeed.dukascopy.com/datafeed\"\n",
    "SAVE_DIR = os.path.join(os.getcwd(), \"downloads\")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ù‚ÙˆØ§Ø¦Ù… ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ®\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def show_menu(options, prompt):\n",
    "    print(f\"\\n{prompt}\")\n",
    "    for i, opt in enumerate(options, 1):\n",
    "        print(f\"  {i}. {opt}\")\n",
    "    while True:\n",
    "        choice = input(\"Enter number: \").strip()\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return options[int(choice) - 1]\n",
    "        print(\"Invalid selection, try again.\")\n",
    "\n",
    "def get_date(prompt):\n",
    "    while True:\n",
    "        s = input(f\"{prompt} (YYYYâ€‘MMâ€‘DD): \").strip()\n",
    "        try:\n",
    "            return datetime.strptime(s, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid date format. Please use YYYY-MM-DD.\")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 7) Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù… Ù…Ø¹ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ ÙˆØ§Ù„Ø­Ø¬Ù… ÙˆØ§Ù„Ø³Ø±Ø¹Ø©\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def progress_bar(done, total, start_ts, downloaded_bytes, estimated_bytes):\n",
    "    pct = done / total if total else 1\n",
    "    elapsed = time.time() - start_ts\n",
    "    rate = downloaded_bytes / elapsed if elapsed>0 else 0\n",
    "    rem = (total - done) / (rate if rate>0 else 1)\n",
    "    bar = \"#\" * int(pct*40) + \"-\" * (40 - int(pct*40))\n",
    "    sys.stdout.write(\n",
    "        f\"\\r[{bar}] {pct*100:5.1f}% \"\n",
    "        f\"{downloaded_bytes/1024/1024:5.2f}MB/\"\n",
    "        f\"{estimated_bytes/1024/1024:5.2f}MB \"\n",
    "        f\"ETA {int(rem//3600)}h{int((rem%3600)//60)}m{int(rem%60)}s\"\n",
    "    )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Ø¨Ù†Ø§Ø¡ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def build_urls(symbol, date, data_type, timeframe=None):\n",
    "    y, m0, d = date.year, date.month - 1, date.day\n",
    "    base = f\"{symbol}/{y}/{m0:02d}/{d:02d}\"\n",
    "    urls = []\n",
    "    if data_type == \"Candlestick\":\n",
    "        code = {\"1m\":\"60\",\"5m\":\"300\",\"15m\":\"900\",\"1h\":\"3600\",\"4h\":\"14400\",\"1d\":\"86400\"}[timeframe]\n",
    "        urls.append(f\"{BASE_URL}/{base}/{code}_candles.bi5\")\n",
    "    else:  # Tick: 24 Ù…Ù„ÙØ§Ù‹ Ù„ÙƒÙ„ Ø³Ø§Ø¹Ø©\n",
    "        for h in range(24):\n",
    "            urls.append(f\"{BASE_URL}/{base}/{h:02d}h_ticks.bi5\")\n",
    "    return urls\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# ØªÙ†Ø²ÙŠÙ„ ÙˆÙÙƒ Ø§Ù„Ø¶ØºØ· ÙˆØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ CSV\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def process_day(symbol, date, data_type, timeframe, out_dir):\n",
    "    csvs = []\n",
    "    for url in build_urls(symbol, date, data_type, timeframe):\n",
    "        fname = url.rsplit(\"/\",1)[-1]\n",
    "        bi5 = os.path.join(out_dir, fname)\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            if r.status_code != 200 or not r.content:\n",
    "                continue\n",
    "            open(bi5,\"wb\").write(r.content)\n",
    "            # ÙÙƒ ÙˆØªØ­ÙˆÙŠÙ„\n",
    "            csv_f = bi5.replace(\".bi5\",\".csv\")\n",
    "            with lzma.open(bi5) as fin, open(csv_f,\"w\",newline=\"\") as fout:\n",
    "                w = csv.writer(fout)\n",
    "                if data_type==\"Candlestick\":\n",
    "                    w.writerow([\"Gmt time\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"])\n",
    "                    rec = 8 + 5*4\n",
    "                    unpack = \">IffffI\"\n",
    "                else:\n",
    "                    w.writerow([\"Gmt time\",\"Bid\",\"Ask\",\"BidVolume\",\"AskVolume\"])\n",
    "                    rec = 20\n",
    "                    unpack = \">IffII\"\n",
    "                data = fin.read()\n",
    "                for i in range(0,len(data),rec):\n",
    "                    chunk = data[i:i+rec]\n",
    "                    if len(chunk)<rec: break\n",
    "                    vals = struct.unpack(unpack, chunk)\n",
    "                    # Ø§Ù„ÙˆÙ‚Øª Ø¨Ø§Ù„Ù…ÙŠÙ„Ù„ÙŠØ«Ø§Ù†ÙŠØ© Ø£Ùˆ Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ\n",
    "                    ms = vals[0]\n",
    "                    t = (date + timedelta(milliseconds=ms) if data_type==\"Tick\"\n",
    "                         else date + timedelta(seconds=ms))\n",
    "                    t_str = t.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                    row = [t_str] + list(vals[1:])\n",
    "                    w.writerow(row)\n",
    "            csvs.append(csv_f)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return csvs\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 8) Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª Ø­Ø³Ø¨ Ø¹Ù…ÙˆØ¯ Gmt time\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def merge_all(csv_list, out_file):\n",
    "    if not csv_list:\n",
    "        print(\"âš ï¸ No data to merge.\")\n",
    "        return\n",
    "    df = pd.concat(\n",
    "        [pd.read_csv(f, parse_dates=[\"Gmt time\"]) for f in csv_list],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    df.sort_values(\"Gmt time\", inplace=True)\n",
    "    df.to_csv(out_file, index=False)\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 2-9) Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def main():\n",
    "    # 1) Ø§Ù„Ù‚ÙˆØ§Ø¦Ù…\n",
    "    cat = show_menu(list(CATEGORIES), \"Select main category:\")\n",
    "    sym = show_menu(CATEGORIES[cat], \"Select instrument:\")\n",
    "    # 3) Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "    dtype = show_menu([\"Candlestick\",\"Tick\"], \"Choose data type:\")\n",
    "    tf = None\n",
    "    if dtype==\"Candlestick\":\n",
    "        tf = show_menu(TIMEFRAMES, \"Select timeframe:\")\n",
    "    # 6) ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ©\n",
    "    start = get_date(\"Start date\")\n",
    "    end   = get_date(\"End date\")\n",
    "    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø®Ø±ÙˆØ¬\n",
    "    out_dir = os.path.join(SAVE_DIR, sym)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # ØªØ­Ù…ÙŠÙ„ ÙŠÙˆÙ…ÙŠ Ù…Ø¹ Ø´Ø±ÙŠØ· ØªÙ‚Ø¯Ù…\n",
    "    total_days = (end - start).days + 1\n",
    "    downloaded_bytes = 0\n",
    "    # ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨ÙŠ: 10MB per candles-day or 30MB per tick-day\n",
    "    est = total_days * (10 if dtype==\"Candlestick\" else 30)\n",
    "    start_ts = time.time()\n",
    "    all_csvs = []\n",
    "    for idx, day in enumerate((start + timedelta(d) for d in range(total_days)), 1):\n",
    "        print(f\"\\nProcessing {day.date()} ({idx}/{total_days})...\")\n",
    "        cs = process_day(sym, day, dtype, tf, out_dir)\n",
    "        all_csvs.extend(cs)\n",
    "        progress_bar(idx, total_days, start_ts, downloaded_bytes, est*1024*1024)\n",
    "    print()\n",
    "\n",
    "    # 8) Ø¯Ù…Ø¬ ÙˆØ­ÙØ¸\n",
    "    merged = os.path.join(out_dir, f\"{sym}_{start.date()}_{end.date()}_merged.csv\")\n",
    "    merge_all(all_csvs, merged)\n",
    "\n",
    "    # 9) Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ\n",
    "    print(f\"\\nâœ… Saved merged CSV: {merged}\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7de8fe-affd-447b-a323-4993d705a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200101.csv: Missing column provided to 'parse_dates': 'Gmt time'\n",
      "âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200102.csv: Missing column provided to 'parse_dates': 'Gmt time'\n",
      "âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200103.csv: Missing column provided to 'parse_dates': 'Gmt time'\n",
      "âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_tick_merged.csv: Missing column provided to 'parse_dates': 'Gmt time'\n",
      "âš ï¸ Ù„Ù… ÙŠÙÙ‚Ø±Ø£ Ø£ÙŠ Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_folder(input_folder, output_path, time_column):\n",
    "    # Ø§Ø¬Ù…Ø¹ ÙƒÙ„ Ù…Ø³Ø§Ø±Ø§Øª CSV ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯\n",
    "    csv_files = [\n",
    "        os.path.join(input_folder, f)\n",
    "        for f in os.listdir(input_folder)\n",
    "        if f.lower().endswith('.csv')\n",
    "    ]\n",
    "    if not csv_files:\n",
    "        print(\"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª CSV ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯.\")\n",
    "        return\n",
    "\n",
    "    # Ø§Ù‚Ø±Ø£ ÙˆØ§Ø¯Ù…Ø¬\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file, parse_dates=[time_column])\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© {file}: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"âš ï¸ Ù„Ù… ÙŠÙÙ‚Ø±Ø£ Ø£ÙŠ Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­.\")\n",
    "        return\n",
    "\n",
    "    merged = pd.concat(dfs, ignore_index=True)\n",
    "    merged.sort_values(time_column, inplace=True)\n",
    "    merged.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ù…Ø¬ Ø¥Ù„Ù‰: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ø¹Ø¯Ù‘Ù„ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù‡Ù†Ø§:\n",
    "    folder = r\"C:\\Users\\Access\\downloads\\XAUUSD\"  \n",
    "    out_file = os.path.join(folder, \"XAUUSD_merged.csv\")\n",
    "    time_col = \"Gmt time\"      # Ø£Ùˆ \"datetime\" Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ù…ÙˆØ¯Ùƒ Ù‡ÙƒØ°Ø§\n",
    "    merge_csv_folder(folder, out_file, time_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da118b81-d517-4d92-b087-dbf6034115d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200101.csv: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n",
      "\n",
      "âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200102.csv: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n",
      "\n",
      "âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200103.csv: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n",
      "\n",
      "âš ï¸ Ù„Ù… ÙŠÙÙ‚Ø±Ø£ Ø£ÙŠ Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_folder(input_folder, output_path, time_column):\n",
    "    # Ø§Ø¬Ù…Ø¹ ÙƒÙ„ Ù…Ø³Ø§Ø±Ø§Øª CSV ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯\n",
    "    csv_files = [\n",
    "        os.path.join(input_folder, f)\n",
    "        for f in os.listdir(input_folder)\n",
    "        if f.lower().endswith('.csv')\n",
    "    ]\n",
    "    if not csv_files:\n",
    "        print(\"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª CSV ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯.\")\n",
    "        return\n",
    "\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            # Ø§Ù‚Ø±Ø£ Ø¨Ø¯ÙˆÙ† parse_dates\n",
    "            df = pd.read_csv(file)\n",
    "            # Ø­ÙˆÙ„ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†ØµÙŠ Ø¥Ù„Ù‰ ØªØ§Ø±ÙŠØ®/ÙˆÙ‚Øª\n",
    "            df[time_column] = pd.to_datetime(df[time_column], errors='coerce')\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© {file}: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"âš ï¸ Ù„Ù… ÙŠÙÙ‚Ø±Ø£ Ø£ÙŠ Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­.\")\n",
    "        return\n",
    "\n",
    "    # Ø§Ø¯Ù…Ø¬ ÙˆÙØ±Ø² Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„\n",
    "    merged = pd.concat(dfs, ignore_index=True)\n",
    "    merged.sort_values(time_column, inplace=True)\n",
    "    # Ø§Ø­ÙØ¸\n",
    "    merged.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ù…Ø¬ Ø¥Ù„Ù‰: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder   = r\"C:\\Users\\Access\\downloads\\XAUUSD\"\n",
    "    out_file = os.path.join(folder, \"XAUUSD_merged.csv\")\n",
    "    time_col = \"Gmt time\"   # Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ ÙƒÙ…Ø§ ÙÙŠ Ù…Ù„ÙØ§ØªÙƒ\n",
    "    merge_csv_folder(folder, out_file, time_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ad23e3-6db6-41fd-b42f-79061179064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ØªØ¬Ø§Ù‡Ù„ XAUUSD_20200101.csv: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Gmt time'\n",
      "âš ï¸ ØªØ¬Ø§Ù‡Ù„ XAUUSD_20200102.csv: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Gmt time'\n",
      "âš ï¸ ØªØ¬Ø§Ù‡Ù„ XAUUSD_20200103.csv: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Gmt time'\n",
      "âš ï¸ Ù„Ù… ÙŠÙÙ‚Ø±Ø£ Ø£ÙŠ Ù…Ù„Ù ØµØ§Ù„Ø­.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_folder(input_folder, output_path, time_column):\n",
    "    # 1) Ø§Ø¬Ù…Ø¹ ÙƒÙ„ Ù…Ù„ÙØ§Øª CSV\n",
    "    csv_files = [\n",
    "        os.path.join(input_folder, f)\n",
    "        for f in os.listdir(input_folder)\n",
    "        if f.lower().endswith('.csv')\n",
    "    ]\n",
    "    if not csv_files:\n",
    "        print(\"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª CSV ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯.\")\n",
    "        return\n",
    "\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            # 2) Ø§Ù‚Ø±Ø£ Ù…Ø¹ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø£Ø³Ø·Ø± ØºÙŠØ± Ø§Ù„ØµØ§Ù„Ø­Ø©\n",
    "            df = pd.read_csv(\n",
    "                file,\n",
    "                sep=',',\n",
    "                engine='python',\n",
    "                on_bad_lines='skip'\n",
    "            )\n",
    "            # 3) Ø¥Ø°Ø§ ÙˆØ¬Ø¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ ÙˆÙ‚Ù… Ø¨ØªØ­ÙˆÙŠÙ„Ù‡\n",
    "            if time_column in df.columns:\n",
    "                df[time_column] = pd.to_datetime(df[time_column], errors='coerce')\n",
    "                dfs.append(df)\n",
    "            else:\n",
    "                print(f\"âš ï¸ ØªØ¬Ø§Ù‡Ù„ {os.path.basename(file)}: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ '{time_column}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© {os.path.basename(file)}: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"âš ï¸ Ù„Ù… ÙŠÙÙ‚Ø±Ø£ Ø£ÙŠ Ù…Ù„Ù ØµØ§Ù„Ø­.\")\n",
    "        return\n",
    "\n",
    "    # 4) Ø¯Ù…Ø¬ ÙˆÙØ±Ø² ÙˆØ­ÙØ¸\n",
    "    merged = pd.concat(dfs, ignore_index=True)\n",
    "    merged.sort_values(time_column, inplace=True)\n",
    "    merged.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ù…Ø¬ Ø¥Ù„Ù‰: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder   = r\"C:\\Users\\Access\\downloads\\XAUUSD\"\n",
    "    out_file = os.path.join(folder, \"XAUUSD_merged.csv\")\n",
    "    time_col = \"Gmt time\"  # Ø¹Ø¯Ù‘Ù„Ù‡ Ø¥Ø°Ø§ Ø¹Ù…ÙˆØ¯Ùƒ Ø§Ø³Ù…Ù‡ \"datetime\"\n",
    "    merge_csv_folder(folder, out_file, time_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4daf5e19-504e-484b-98f7-72d25cb203f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select main category:\n",
      "  1. Metals\n",
      "  2. Forex\n",
      "  3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select instrument:\n",
      "  1. XAUUSD\n",
      "  2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose data type:\n",
      "  1. Candlestick\n",
      "  2. Tick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select timeframe:\n",
      "  1. 1m\n",
      "  2. 5m\n",
      "  3. 15m\n",
      "  4. 1h\n",
      "  5. 4h\n",
      "  6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  3\n",
      "Start date (YYYYâ€‘MMâ€‘DD):  2020-01-01\n",
      "End date (YYYYâ€‘MMâ€‘DD):  2020-01-03\n",
      "Enter GMT offset [default 0]:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸ No CSVs to merge.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 1) Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©: ØªØµÙ†ÙŠÙØ§Øª ÙˆØ£Ø¯ÙˆØ§Øª ÙˆØ£Ø·Ø± Ø²Ù…Ù†ÙŠØ©\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "CATEGORIES = {\n",
    "    \"Metals\":  [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\":   [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_CODES = {\"1m\":\"60\",\"5m\":\"300\",\"15m\":\"900\",\"1h\":\"3600\",\"4h\":\"14400\",\"1d\":\"86400\"}\n",
    "\n",
    "BASE_URL = \"https://datafeed.dukascopy.com/datafeed\"\n",
    "SAVE_ROOT = os.path.join(os.getcwd(), \"downloads\")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ®\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def show_menu(options, prompt):\n",
    "    print(f\"\\n{prompt}\")\n",
    "    for i, opt in enumerate(options, 1):\n",
    "        print(f\"  {i}. {opt}\")\n",
    "    while True:\n",
    "        choice = input(\"Enter number: \").strip()\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return options[int(choice) - 1]\n",
    "        print(\"Invalid selection, try again.\")\n",
    "\n",
    "def get_date(prompt):\n",
    "    while True:\n",
    "        s = input(f\"{prompt} (YYYYâ€‘MMâ€‘DD): \").strip()\n",
    "        try:\n",
    "            return datetime.strptime(s, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid format. Use YYYY-MM-DD.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    s = input(\"Enter GMT offset [default 0]: \").strip()\n",
    "    try:\n",
    "        return int(s) if s else 0\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 7) Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def progress_bar(done, total, start_ts, downloaded, estimated_bytes):\n",
    "    pct = done/total if total else 1\n",
    "    elapsed = time.time() - start_ts\n",
    "    rate = downloaded/elapsed if elapsed>0 else 0\n",
    "    rem = (total-done)/(rate if rate>0 else 1)\n",
    "    bar = \"#\" * int(pct*40) + \"-\" * (40-int(pct*40))\n",
    "    sys.stdout.write(\n",
    "        f\"\\r[{bar}] {pct*100:5.1f}% \"\n",
    "        f\"{downloaded/1024/1024:6.2f}MB/\"\n",
    "        f\"{estimated_bytes/1024/1024:6.2f}MB \"\n",
    "        f\"ETA {int(rem//3600)}h{int((rem%3600)//60)}m{int(rem%60)}s\"\n",
    "    )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 2â€“6) Ø¨Ù†Ø§Ø¡ Ø±ÙˆØ§Ø¨Ø· ÙˆØªÙ†Ø²ÙŠÙ„ ÙˆÙÙƒ Ø¶ØºØ·\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def build_urls(symbol, date, dtype, tf=None):\n",
    "    y, m0, d = date.year, date.month-1, date.day\n",
    "    base = f\"{symbol}/{y}/{m0:02d}/{d:02d}\"\n",
    "    urls = []\n",
    "    if dtype==\"Candlestick\":\n",
    "        code = CANDLE_CODES[tf]\n",
    "        urls.append(f\"{BASE_URL}/{base}/{code}_candles.bi5\")\n",
    "    else:\n",
    "        for h in range(24):\n",
    "            urls.append(f\"{BASE_URL}/{base}/{h:02d}h_ticks.bi5\")\n",
    "    return urls\n",
    "\n",
    "def process_day(symbol, date, dtype, tf, out_dir, downloaded, total_units, start_ts, est_bytes):\n",
    "    csvs = []\n",
    "    for url in build_urls(symbol, date, dtype, tf):\n",
    "        fn = os.path.basename(url)\n",
    "        bi5 = os.path.join(out_dir, fn)\n",
    "        try:\n",
    "            r = requests.get(url, timeout=15)\n",
    "            if r.status_code != 200 or not r.content:\n",
    "                continue\n",
    "            downloaded += len(r.content)\n",
    "            open(bi5, \"wb\").write(r.content)\n",
    "            # ÙÙƒÙ‘ ÙˆØ¶ØºØ· Ø¥Ù„Ù‰ CSV\n",
    "            csvf = bi5.replace(\".bi5\", \".csv\")\n",
    "            with lzma.open(bi5) as fin, open(csvf, \"w\", newline=\"\") as fout:\n",
    "                w = csv.writer(fout)\n",
    "                if dtype==\"Candlestick\":\n",
    "                    w.writerow([\"Gmt time\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"])\n",
    "                    rec, unpack = 24, \">IffffI\"\n",
    "                else:\n",
    "                    w.writerow([\"Gmt time\",\"Bid\",\"Ask\",\"BidVolume\",\"AskVolume\"])\n",
    "                    rec, unpack = 20, \">IffII\"\n",
    "                data = fin.read()\n",
    "                for i in range(0, len(data), rec):\n",
    "                    chunk = data[i:i+rec]\n",
    "                    if len(chunk)<rec: break\n",
    "                    vals = struct.unpack(unpack, chunk)\n",
    "                    ms = vals[0]\n",
    "                    t = date + (timedelta(milliseconds=ms) if dtype==\"Tick\" else timedelta(seconds=ms))\n",
    "                    t_str = t.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                    row = [t_str] + list(vals[1:])\n",
    "                    w.writerow(row)\n",
    "            csvs.append(csvf)\n",
    "        except Exception:\n",
    "            pass\n",
    "        total_units += 1\n",
    "        progress_bar(total_units, day_count* (24 if dtype==\"Tick\" else 1),\n",
    "                     start_ts, downloaded, est_bytes)\n",
    "    return csvs, downloaded, total_units\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 8) Ø¯Ù…Ø¬ CSVØ§Øª Ù…Ø¹ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ø®Ø§Ø·Ø¦Ø©\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def merge_csv_folder(folder, out_path, time_col):\n",
    "    files = [os.path.join(folder,f) for f in os.listdir(folder) if f.endswith(\".csv\")]\n",
    "    if not files:\n",
    "        print(\"âš ï¸ No CSVs to merge.\"); return\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            df = pd.read_csv(f, sep=\",\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "            if time_col in df.columns:\n",
    "                df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "                dfs.append(df)\n",
    "        except:\n",
    "            pass\n",
    "    if not dfs:\n",
    "        print(\"âš ï¸ Nothing to merge.\"); return\n",
    "    merged = pd.concat(dfs, ignore_index=True).sort_values(time_col)\n",
    "    merged.to_csv(out_path, index=False)\n",
    "    print(f\"\\nâœ… Saved merged CSV: {out_path}\")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 9) ØªÙ†ÙÙŠØ° Ø±Ø¦ÙŠØ³ÙŠ\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "if __name__==\"__main__\":\n",
    "    # 1â€“6: Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ®\n",
    "    cat = show_menu(list(CATEGORIES), \"Select main category:\")\n",
    "    sym = show_menu(CATEGORIES[cat], \"Select instrument:\")\n",
    "    dtype = show_menu([\"Candlestick\",\"Tick\"], \"Choose data type:\")\n",
    "    tf = show_menu(TIMEFRAMES, \"Select timeframe:\") if dtype==\"Candlestick\" else None\n",
    "    start = get_date(\"Start date\")\n",
    "    end   = get_date(\"End date\")\n",
    "    gmt   = get_gmt_offset()\n",
    "\n",
    "    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„\n",
    "    out_dir = os.path.join(SAVE_ROOT, sym)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    day_count = (end-start).days+1\n",
    "    total_units = 0\n",
    "    downloaded_bytes = 0\n",
    "    est_bytes = day_count * (10*1024*1024 if dtype==\"Candlestick\" else 30*1024*1024)\n",
    "    start_ts = time.time()\n",
    "\n",
    "    all_csv = []\n",
    "    for date in (start + timedelta(i) for i in range(day_count)):\n",
    "        cs, downloaded_bytes, total_units = process_day(\n",
    "            sym, date, dtype, tf, out_dir,\n",
    "            downloaded_bytes, total_units, start_ts, est_bytes\n",
    "        )\n",
    "        all_csv.extend(cs)\n",
    "    print()\n",
    "\n",
    "    # 8â€“9: Ø¯Ù…Ø¬ ÙˆØ§Ø­ÙØ¸\n",
    "    merged_file = os.path.join(out_dir, f\"{sym}_{start.date()}_{end.date()}_merged.csv\")\n",
    "    merge_csv_folder(out_dir, merged_file, \"Gmt time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6bc2733-d9fa-4def-ae50-61bbdcff65f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Access\\AppData\\Local\\Temp\\ipykernel_28588\\1066112427.py:46: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  today = datetime.utcnow().date()\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 163\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    162\u001b[0m     root \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mTk()\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mApp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m     root\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m, in \u001b[0;36mApp.__init__\u001b[1;34m(self, root)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpack(fill\u001b[38;5;241m=\u001b[39mtk\u001b[38;5;241m.\u001b[39mBOTH, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_widgets()\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_symbols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 63\u001b[0m, in \u001b[0;36mApp.fetch_symbols\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_symbols\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     62\u001b[0m     resp \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(BASE)\n\u001b[1;32m---> 63\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Ù†Ø³Ù‚: [{\"instrumentType\": \"...\", \"instruments\": [...]}, ...]\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes \u001b[38;5;241m=\u001b[39m {d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstrumentType\u001b[39m\u001b[38;5;124m\"\u001b[39m]: d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstruments\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data}\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, filedialog\n",
    "import requests, threading, time, csv\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "\n",
    "BASE = \"https://www.dukascopy.com/trading-tools/widgets/quotes/historical_data_feed\"\n",
    "\n",
    "class App(ttk.Frame):\n",
    "    def __init__(self, root):\n",
    "        super().__init__(root)\n",
    "        self.root = root\n",
    "        self.root.title(\"Dukascopy Data Downloader\")\n",
    "        self.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.fetch_symbols()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        # Ø£Ø¯Ø§Ø© + Ø£Ø¯Ø§Ø© ÙØ±Ø¹ÙŠØ©\n",
    "        ttk.Label(self, text=\"Instrument type:\").grid(row=0, column=0, sticky=tk.W)\n",
    "        self.inst_type = ttk.Combobox(self, state=\"readonly\")\n",
    "        self.inst_type.grid(row=0, column=1)\n",
    "        self.inst_type.bind(\"<<ComboboxSelected>>\", self.on_inst_type)\n",
    "\n",
    "        ttk.Label(self, text=\"Instrument:\").grid(row=1, column=0, sticky=tk.W)\n",
    "        self.inst = ttk.Combobox(self, state=\"readonly\")\n",
    "        self.inst.grid(row=1, column=1)\n",
    "\n",
    "        # Ø§Ù„Ø´Ù…ÙˆØ¹ vs ØªÙŠÙƒ\n",
    "        self.mode = tk.StringVar(value=\"candles\")\n",
    "        ttk.Radiobutton(self, text=\"Candles\", variable=self.mode, value=\"candles\",\n",
    "                        command=self.on_mode).grid(row=2, column=0)\n",
    "        ttk.Radiobutton(self, text=\"Ticks\",   variable=self.mode, value=\"ticks\",\n",
    "                        command=self.on_mode).grid(row=2, column=1)\n",
    "\n",
    "        # ÙØ±ÙŠÙ… Ø£Ùˆ Ø¹Ø¯Ø¯ ØªÙŠÙƒ\n",
    "        ttk.Label(self, text=\"Timeframe / Tick count:\").grid(row=3, column=0, sticky=tk.W)\n",
    "        self.tf = ttk.Combobox(self, state=\"readonly\")\n",
    "        self.tf.grid(row=3, column=1)\n",
    "\n",
    "        # ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©â€“Ø§Ù„Ù†Ù‡Ø§ÙŠØ©\n",
    "        today = datetime.utcnow().date()\n",
    "        ttk.Label(self, text=\"From (YYYY-mm-dd):\").grid(row=4, column=0, sticky=tk.W)\n",
    "        self.from_e = ttk.Entry(self); self.from_e.grid(row=4, column=1); self.from_e.insert(0, today)\n",
    "        ttk.Label(self, text=\"To (YYYY-mm-dd):\").grid(row=5, column=0, sticky=tk.W)\n",
    "        self.to_e = ttk.Entry(self); self.to_e.grid(row=5, column=1); self.to_e.insert(0, today)\n",
    "\n",
    "        # ØªÙ†Ø²ÙŠÙ„ + Ø´Ø±ÙŠØ· ØªÙ‚Ø¯Ù…\n",
    "        self.download_btn = ttk.Button(self, text=\"Download\", command=self.on_download)\n",
    "        self.download_btn.grid(row=6, column=0, columnspan=2, pady=5)\n",
    "\n",
    "        self.progress = ttk.Progressbar(self, mode=\"determinate\", length=300)\n",
    "        self.progress.grid(row=7, column=0, columnspan=2, pady=5)\n",
    "        self.status = ttk.Label(self, text=\"Status: Idle\")\n",
    "        self.status.grid(row=8, column=0, columnspan=2)\n",
    "\n",
    "    def fetch_symbols(self):\n",
    "        resp = requests.get(BASE)\n",
    "        data = resp.json()\n",
    "        # Ù†Ø³Ù‚: [{\"instrumentType\": \"...\", \"instruments\": [...]}, ...]\n",
    "        self.types = {d[\"instrumentType\"]: d[\"instruments\"] for d in data}\n",
    "        tt = list(self.types.keys())\n",
    "        self.inst_type[\"values\"] = tt\n",
    "        if tt:\n",
    "            self.inst_type.current(0)\n",
    "            self.on_inst_type()\n",
    "\n",
    "    def on_inst_type(self, *_):\n",
    "        t = self.inst_type.get()\n",
    "        self.inst[\"values\"] = self.types[t]\n",
    "        if self.types[t]:\n",
    "            self.inst.current(0)\n",
    "\n",
    "    def on_mode(self):\n",
    "        if self.mode.get() == \"candles\":\n",
    "            self.tf[\"values\"] = [\"MINUTE\", \"HOUR\", \"DAY\", \"WEEK\", \"MONTH\"]\n",
    "            self.tf.current(0)\n",
    "        else:\n",
    "            self.tf[\"values\"] = [\"1\", \"10\", \"100\", \"1000\"]\n",
    "            self.tf.current(0)\n",
    "\n",
    "    def on_download(self):\n",
    "        try:\n",
    "            start = datetime.strptime(self.from_e.get().strip(), \"%Y-%m-%d\")\n",
    "            end   = datetime.strptime(self.to_e.get().strip(), \"%Y-%m-%d\")\n",
    "        except:\n",
    "            messagebox.showerror(\"Date error\", \"Invalid date format!\")\n",
    "            return\n",
    "\n",
    "        inst = self.inst.get().upper()\n",
    "        mode = self.mode.get()\n",
    "        tf = self.tf.get()\n",
    "\n",
    "        path = filedialog.asksaveasfilename(defaultextension=\".csv\",\n",
    "                                            filetypes=[(\"CSV\",\"*.csv\")])\n",
    "        if not path: return\n",
    "\n",
    "        t = threading.Thread(target=self.download_thread, args=(inst, mode, tf, start, end, path))\n",
    "        t.start()\n",
    "\n",
    "    def download_thread(self, inst, mode, tf, start, end, path):\n",
    "        self.download_btn.config(state=tk.DISABLED)\n",
    "        total_days = (end - start).days + 1\n",
    "        chunk_days = 5  # ØªÙ‚Ø³ÙŠÙ… Ù„ÙƒÙ„ ØªØ­Ù…ÙŠÙ„\n",
    "        urls = []\n",
    "        for i in range(0, total_days, chunk_days):\n",
    "            s = start + timedelta(days=i)\n",
    "            e = min(s + timedelta(days=chunk_days-1), end)\n",
    "            urls.append((s, e))\n",
    "        all_rows = []\n",
    "        downloaded = 0\n",
    "        total = len(urls)\n",
    "        start_t0 = time.time()\n",
    "\n",
    "        for idx, (s, e) in enumerate(urls):\n",
    "            params = {\n",
    "                \"instrument\": inst,\n",
    "                \"type\": mode,\n",
    "                \"timeFrame\": tf if mode==\"candles\" else \"\",\n",
    "                \"startDate\": s.strftime(\"%Y-%m-%d\"),\n",
    "                \"endDate\":   e.strftime(\"%Y-%m-%d\"),\n",
    "                \"tickPrecision\": tf if mode==\"ticks\" else \"\"\n",
    "            }\n",
    "            t0 = time.time()\n",
    "            r = requests.get(BASE, params=params, stream=True)\n",
    "            size = 0\n",
    "            data = StringIO()\n",
    "            for chunk in r.iter_content(chunk_size=1024*10):\n",
    "                if not chunk: break\n",
    "                data.write(chunk.decode())\n",
    "                size += len(chunk)\n",
    "                elapsed = time.time() - t0\n",
    "                speed = size / elapsed if elapsed>0 else 0\n",
    "                done = (idx + size/len(r.content if r.content else b\"\")) / total\n",
    "                self.progress[\"value\"] = min(100, done*100)\n",
    "                rem = elapsed * ((total-idx) - (size/len(r.content if r.content else b\"\")))\n",
    "                self.status.config(text=f\"Chunk {idx+1}/{total}, {size//1024} KB, {int(speed)} B/s, ETA {int(rem)}s\")\n",
    "                self.root.update_idletasks()\n",
    "            # Ù…Ø¹Ø§Ù„Ø¬Ø© CSV\n",
    "            data.seek(0)\n",
    "            reader = csv.reader(data)\n",
    "            rows = list(reader)\n",
    "            all_rows.extend(rows[1:] if all_rows else rows)\n",
    "            downloaded += 1\n",
    "\n",
    "        # Ø¯Ù…Ø¬ Ø­Ø³Ø¨ GMT time (Ø£ÙÙ‚ÙŠ)\n",
    "        all_rows.sort(key=lambda r: r[0])\n",
    "        with open(path, \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(all_rows)\n",
    "\n",
    "        total_time = time.time() - start_t0\n",
    "        self.status.config(text=f\"Completed in {int(total_time)}s, saved to {path}\")\n",
    "        messagebox.showinfo(\"Done\", f\"Saved to:\\n{path}\")\n",
    "        self.download_btn.config(state=tk.NORMAL)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    root = tk.Tk()\n",
    "    App(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d9cc0c1-3e18-40d2-8194-a87969cd6be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø£Ø¯Ø§Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Dukascopy!\n",
      "âš¡ Ø¨Ù†Ø§Ø¡ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\n",
      "\n",
      "==================================================\n",
      "ğŸ† Ø£Ø¯Ø§Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Dukascopy\n",
      "==================================================\n",
      "\n",
      "Ø§Ø®ØªØ± ÙØ¦Ø© Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©:\n",
      "1. Ø§Ù„Ø¹Ù…Ù„Ø§Øª (Forex)\n",
      "2. Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª (Indices)\n",
      "3. Ø§Ù„Ø³Ù„Ø¹ (Commodities)\n",
      "4. Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø© (Crypto)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ø£Ø¯Ø®Ù„ Ø±Ù‚Ù… Ø§Ù„ÙØ¦Ø©:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© ÙÙŠ ÙØ¦Ø©: Ø§Ù„Ø¹Ù…Ù„Ø§Øª (Forex)\n",
      "----------------------------------------\n",
      "1. EUR/USD (EURUSD)\n",
      "2. GBP/USD (GBPUSD)\n",
      "3. USD/JPY (USDJPY)\n",
      "4. USD/CHF (USDCHF)\n",
      "5. AUD/USD (AUDUSD)\n",
      "6. USD/CAD (USDCAD)\n",
      "7. NZD/USD (NZDUSD)\n",
      "8. EUR/GBP (EURGBP)\n",
      "9. EUR/JPY (EURJPY)\n",
      "10. GBP/JPY (GBPJPY)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ø£Ø¯Ø®Ù„ Ø±Ù‚Ù… Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n",
      "1. Ø´Ù…ÙˆØ¹ ÙŠØ§Ø¨Ø§Ù†ÙŠØ© (Candlesticks)\n",
      "2. Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠÙƒ (Tick Data)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ø£Ø¯Ø®Ù„ Ø§Ø®ØªÙŠØ§Ø±Ùƒ (1 Ø£Ùˆ 2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ Ø§Ø®ØªØ± Ø¹Ø¯Ø¯ Ø§Ù„ØªÙŠÙƒ:\n",
      "1. 100 ØªÙŠÙƒ\n",
      "2. 500 ØªÙŠÙƒ\n",
      "3. 1,000 ØªÙŠÙƒ\n",
      "4. 5,000 ØªÙŠÙƒ\n",
      "5. 10,000 ØªÙŠÙƒ\n",
      "6. 50,000 ØªÙŠÙƒ\n",
      "7. 100,000 ØªÙŠÙƒ\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ø£Ø¯Ø®Ù„ Ø±Ù‚Ù… Ø§Ù„Ø®ÙŠØ§Ø±:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©\n",
      "Ø§Ù„ØµÙŠØºØ©: YYYY-MM-DD (Ù…Ø«Ø§Ù„: 2024-01-15)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ø£Ø¯Ø®Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®:  2025-01-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ù‡Ø§ÙŠØ©\n",
      "Ø§Ù„ØµÙŠØºØ©: YYYY-MM-DD (Ù…Ø«Ø§Ù„: 2024-01-15)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ø£Ø¯Ø®Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®:  2025-01-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\n",
      "ğŸ“Š Ø§Ù„Ø£Ø¯Ø§Ø©: EURUSD\n",
      "ğŸ“ˆ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: ticks\n",
      "ğŸ¯ Ø­Ø¬Ù… Ø§Ù„ØªÙŠÙƒ: 100\n",
      "ğŸ“… Ù…Ù†: 2025-01-01 Ø¥Ù„Ù‰: 2025-01-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Ø§Ù„ØªØ­Ù…ÙŠÙ„: 3ÙŠÙˆÙ… [00:00,  9.42ÙŠÙˆÙ…/s, Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù=26.3 KB, Ø§Ù„Ø³Ø±Ø¹Ø©=82.2 KB/s, Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ=-1:59:59]                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ 300 Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­!\n",
      "\n",
      "ğŸ”„ Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙˆÙ‚Øª GMT...\n",
      "ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ğŸ“ Ù…Ø³Ø§Ø± Ø§Ù„Ø­ÙØ¸: C:\\Users\\Access\\Dukascopy_Data\\EURUSD_ticks_20250702_054930.csv\n",
      "ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: 300\n",
      "ğŸ’¾ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: 13.71 KB\n",
      "\n",
      "ğŸ‰ ØªÙ…Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ğŸš€ Ø§Ù„Ù…Ù„Ù Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: EURUSD_ticks_20250702_054930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from urllib.parse import urlencode\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "class DukascopyDownloader:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.dukascopy.com/trading-tools/widgets/quotes/historical_data_feed\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "        \n",
    "        # Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n",
    "        self.instruments = {\n",
    "            'Ø§Ù„Ø¹Ù…Ù„Ø§Øª (Forex)': {\n",
    "                'EURUSD': 'EUR/USD',\n",
    "                'GBPUSD': 'GBP/USD', \n",
    "                'USDJPY': 'USD/JPY',\n",
    "                'USDCHF': 'USD/CHF',\n",
    "                'AUDUSD': 'AUD/USD',\n",
    "                'USDCAD': 'USD/CAD',\n",
    "                'NZDUSD': 'NZD/USD',\n",
    "                'EURGBP': 'EUR/GBP',\n",
    "                'EURJPY': 'EUR/JPY',\n",
    "                'GBPJPY': 'GBP/JPY'\n",
    "            },\n",
    "            'Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª (Indices)': {\n",
    "                'SPX500': 'S&P 500',\n",
    "                'NAS100': 'NASDAQ 100',\n",
    "                'DJ30': 'Dow Jones 30',\n",
    "                'GER30': 'DAX 30',\n",
    "                'UK100': 'FTSE 100',\n",
    "                'FRA40': 'CAC 40',\n",
    "                'JPN225': 'Nikkei 225'\n",
    "            },\n",
    "            'Ø§Ù„Ø³Ù„Ø¹ (Commodities)': {\n",
    "                'XAUUSD': 'Gold/USD',\n",
    "                'XAGUSD': 'Silver/USD',\n",
    "                'WTIUSD': 'WTI Oil/USD',\n",
    "                'BRENTUSD': 'Brent Oil/USD',\n",
    "                'NATGASUSD': 'Natural Gas/USD'\n",
    "            },\n",
    "            'Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø© (Crypto)': {\n",
    "                'BTCUSD': 'Bitcoin/USD',\n",
    "                'ETHUSD': 'Ethereum/USD',\n",
    "                'LTCUSD': 'Litecoin/USD',\n",
    "                'XRPUSD': 'Ripple/USD'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Ø§Ù„ØªØ§ÙŠÙ… ÙØ±ÙŠÙ… Ø§Ù„Ù…ØªØ§Ø­Ø©\n",
    "        self.timeframes = {\n",
    "            '1 Ø¯Ù‚ÙŠÙ‚Ø©': 'm1',\n",
    "            '5 Ø¯Ù‚Ø§Ø¦Ù‚': 'm5',\n",
    "            '15 Ø¯Ù‚ÙŠÙ‚Ø©': 'm15',\n",
    "            '30 Ø¯Ù‚ÙŠÙ‚Ø©': 'm30',\n",
    "            '1 Ø³Ø§Ø¹Ø©': 'h1',\n",
    "            '4 Ø³Ø§Ø¹Ø§Øª': 'h4',\n",
    "            '1 ÙŠÙˆÙ…': 'd1',\n",
    "            '1 Ø£Ø³Ø¨ÙˆØ¹': 'w1',\n",
    "            '1 Ø´Ù‡Ø±': 'mn1'\n",
    "        }\n",
    "        \n",
    "        # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªÙŠÙƒ\n",
    "        self.tick_options = [100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "\n",
    "    def display_categories(self):\n",
    "        \"\"\"Ø¹Ø±Ø¶ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ğŸ† Ø£Ø¯Ø§Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Dukascopy\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"\\nØ§Ø®ØªØ± ÙØ¦Ø© Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©:\")\n",
    "        \n",
    "        categories = list(self.instruments.keys())\n",
    "        for i, category in enumerate(categories, 1):\n",
    "            print(f\"{i}. {category}\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nØ£Ø¯Ø®Ù„ Ø±Ù‚Ù… Ø§Ù„ÙØ¦Ø©: \")) - 1\n",
    "                if 0 <= choice < len(categories):\n",
    "                    return categories[choice]\n",
    "                else:\n",
    "                    print(\"âŒ Ø®ÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.\")\n",
    "            except ValueError:\n",
    "                print(\"âŒ ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… ØµØ­ÙŠØ­.\")\n",
    "\n",
    "    def display_instruments(self, category):\n",
    "        \"\"\"Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© ÙÙŠ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©\"\"\"\n",
    "        print(f\"\\nğŸ“Š Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© ÙÙŠ ÙØ¦Ø©: {category}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        instruments = list(self.instruments[category].items())\n",
    "        for i, (symbol, name) in enumerate(instruments, 1):\n",
    "            print(f\"{i}. {name} ({symbol})\")\n",
    "            \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nØ£Ø¯Ø®Ù„ Ø±Ù‚Ù… Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©: \")) - 1\n",
    "                if 0 <= choice < len(instruments):\n",
    "                    return instruments[choice][0]\n",
    "                else:\n",
    "                    print(\"âŒ Ø®ÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.\")\n",
    "            except ValueError:\n",
    "                print(\"âŒ ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… ØµØ­ÙŠØ­.\")\n",
    "\n",
    "    def choose_data_type(self):\n",
    "        \"\"\"Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: Ø´Ù…ÙˆØ¹ ÙŠØ§Ø¨Ø§Ù†ÙŠØ© Ø£Ù… ØªÙŠÙƒ\"\"\"\n",
    "        print(\"\\nğŸ“ˆ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\")\n",
    "        print(\"1. Ø´Ù…ÙˆØ¹ ÙŠØ§Ø¨Ø§Ù†ÙŠØ© (Candlesticks)\")\n",
    "        print(\"2. Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠÙƒ (Tick Data)\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nØ£Ø¯Ø®Ù„ Ø§Ø®ØªÙŠØ§Ø±Ùƒ (1 Ø£Ùˆ 2): \"))\n",
    "                if choice == 1:\n",
    "                    return 'candlesticks'\n",
    "                elif choice == 2:\n",
    "                    return 'ticks'\n",
    "                else:\n",
    "                    print(\"âŒ Ø®ÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­. Ø§Ø®ØªØ± 1 Ø£Ùˆ 2.\")\n",
    "            except ValueError:\n",
    "                print(\"âŒ ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… ØµØ­ÙŠØ­.\")\n",
    "\n",
    "    def choose_timeframe(self):\n",
    "        \"\"\"Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØªØ§ÙŠÙ… ÙØ±ÙŠÙ… Ù„Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ©\"\"\"\n",
    "        print(\"\\nâ° Ø§Ø®ØªØ± Ø§Ù„ØªØ§ÙŠÙ… ÙØ±ÙŠÙ…:\")\n",
    "        \n",
    "        timeframes = list(self.timeframes.items())\n",
    "        for i, (name, code) in enumerate(timeframes, 1):\n",
    "            print(f\"{i}. {name}\")\n",
    "            \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nØ£Ø¯Ø®Ù„ Ø±Ù‚Ù… Ø§Ù„ØªØ§ÙŠÙ… ÙØ±ÙŠÙ…: \")) - 1\n",
    "                if 0 <= choice < len(timeframes):\n",
    "                    return timeframes[choice][1]\n",
    "                else:\n",
    "                    print(\"âŒ Ø®ÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.\")\n",
    "            except ValueError:\n",
    "                print(\"âŒ ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… ØµØ­ÙŠØ­.\")\n",
    "\n",
    "    def choose_tick_size(self):\n",
    "        \"\"\"Ø§Ø®ØªÙŠØ§Ø± Ø­Ø¬Ù… Ø§Ù„ØªÙŠÙƒ\"\"\"\n",
    "        print(\"\\nğŸ¯ Ø§Ø®ØªØ± Ø¹Ø¯Ø¯ Ø§Ù„ØªÙŠÙƒ:\")\n",
    "        \n",
    "        for i, size in enumerate(self.tick_options, 1):\n",
    "            print(f\"{i}. {size:,} ØªÙŠÙƒ\")\n",
    "            \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nØ£Ø¯Ø®Ù„ Ø±Ù‚Ù… Ø§Ù„Ø®ÙŠØ§Ø±: \")) - 1\n",
    "                if 0 <= choice < len(self.tick_options):\n",
    "                    return self.tick_options[choice]\n",
    "                else:\n",
    "                    print(\"âŒ Ø®ÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.\")\n",
    "            except ValueError:\n",
    "                print(\"âŒ ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… ØµØ­ÙŠØ­.\")\n",
    "\n",
    "    def get_date_input(self, prompt):\n",
    "        \"\"\"Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…\"\"\"\n",
    "        print(f\"\\nğŸ“… {prompt}\")\n",
    "        print(\"Ø§Ù„ØµÙŠØºØ©: YYYY-MM-DD (Ù…Ø«Ø§Ù„: 2024-01-15)\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                date_str = input(\"Ø£Ø¯Ø®Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®: \")\n",
    "                date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "                return date_obj\n",
    "            except ValueError:\n",
    "                print(\"âŒ ØªØ§Ø±ÙŠØ® ØºÙŠØ± ØµØ­ÙŠØ­. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØµÙŠØºØ©: YYYY-MM-DD\")\n",
    "\n",
    "    def download_data(self, symbol, data_type, timeframe=None, tick_size=None, start_date=None, end_date=None):\n",
    "        \"\"\"ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…\"\"\"\n",
    "        print(f\"\\nğŸš€ Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\")\n",
    "        print(f\"ğŸ“Š Ø§Ù„Ø£Ø¯Ø§Ø©: {symbol}\")\n",
    "        print(f\"ğŸ“ˆ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {data_type}\")\n",
    "        if timeframe:\n",
    "            print(f\"â° Ø§Ù„ØªØ§ÙŠÙ… ÙØ±ÙŠÙ…: {timeframe}\")\n",
    "        if tick_size:\n",
    "            print(f\"ğŸ¯ Ø­Ø¬Ù… Ø§Ù„ØªÙŠÙƒ: {tick_size:,}\")\n",
    "        print(f\"ğŸ“… Ù…Ù†: {start_date.strftime('%Y-%m-%d')} Ø¥Ù„Ù‰: {end_date.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # Ù…Ø­Ø§ÙƒØ§Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "        total_days = (end_date - start_date).days\n",
    "        downloaded_data = []\n",
    "        \n",
    "        start_time = time.time()\n",
    "        file_size = 0\n",
    "        \n",
    "        with tqdm(total=total_days, desc=\"ğŸ“¥ Ø§Ù„ØªØ­Ù…ÙŠÙ„\", unit=\"ÙŠÙˆÙ…\") as pbar:\n",
    "            current_date = start_date\n",
    "            while current_date <= end_date:\n",
    "                # Ù…Ø­Ø§ÙƒØ§Ø© ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯\n",
    "                time.sleep(0.1)  # Ù…Ø­Ø§ÙƒØ§Ø© Ø²Ù…Ù† Ø§Ù„ØªØ­Ù…ÙŠÙ„\n",
    "                \n",
    "                # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„Ù…Ø«Ø§Ù„\n",
    "                if data_type == 'candlesticks':\n",
    "                    daily_data = self.generate_sample_candlestick_data(current_date, timeframe)\n",
    "                else:\n",
    "                    daily_data = self.generate_sample_tick_data(current_date, tick_size)\n",
    "                \n",
    "                downloaded_data.extend(daily_data)\n",
    "                file_size += len(str(daily_data))\n",
    "                \n",
    "                # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ\n",
    "                elapsed_time = time.time() - start_time\n",
    "                days_done = (current_date - start_date).days + 1\n",
    "                if days_done > 0:\n",
    "                    avg_time_per_day = elapsed_time / days_done\n",
    "                    remaining_days = total_days - days_done\n",
    "                    remaining_time = avg_time_per_day * remaining_days\n",
    "                    \n",
    "                    hours = int(remaining_time // 3600)\n",
    "                    minutes = int((remaining_time % 3600) // 60)\n",
    "                    seconds = int(remaining_time % 60)\n",
    "                    \n",
    "                    speed = file_size / elapsed_time / 1024  # KB/s\n",
    "                    \n",
    "                    pbar.set_postfix({\n",
    "                        'Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù': f'{file_size/1024:.1f} KB',\n",
    "                        'Ø§Ù„Ø³Ø±Ø¹Ø©': f'{speed:.1f} KB/s',\n",
    "                        'Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ': f'{hours:02d}:{minutes:02d}:{seconds:02d}'\n",
    "                    })\n",
    "                \n",
    "                pbar.update(1)\n",
    "                current_date += timedelta(days=1)\n",
    "        \n",
    "        print(f\"\\nâœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(downloaded_data)} Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "        return downloaded_data\n",
    "\n",
    "    def generate_sample_candlestick_data(self, date, timeframe):\n",
    "        \"\"\"Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ù…ÙˆØ¹ ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„Ù…Ø«Ø§Ù„\"\"\"\n",
    "        import random\n",
    "        \n",
    "        # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ù…ÙˆØ¹ Ø­Ø³Ø¨ Ø§Ù„ØªØ§ÙŠÙ… ÙØ±ÙŠÙ…\n",
    "        candles_per_day = {\n",
    "            'm1': 1440, 'm5': 288, 'm15': 96, 'm30': 48,\n",
    "            'h1': 24, 'h4': 6, 'd1': 1, 'w1': 1, 'mn1': 1\n",
    "        }\n",
    "        \n",
    "        num_candles = candles_per_day.get(timeframe, 24)\n",
    "        data = []\n",
    "        \n",
    "        base_price = random.uniform(1.0, 2.0)\n",
    "        \n",
    "        for i in range(num_candles):\n",
    "            timestamp = date + timedelta(minutes=i * (1440 // num_candles))\n",
    "            open_price = base_price + random.uniform(-0.01, 0.01)\n",
    "            close_price = open_price + random.uniform(-0.005, 0.005)\n",
    "            high_price = max(open_price, close_price) + random.uniform(0, 0.003)\n",
    "            low_price = min(open_price, close_price) - random.uniform(0, 0.003)\n",
    "            volume = random.randint(100, 10000)\n",
    "            \n",
    "            data.append({\n",
    "                'GMT Time': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'Open': round(open_price, 5),\n",
    "                'High': round(high_price, 5),\n",
    "                'Low': round(low_price, 5),\n",
    "                'Close': round(close_price, 5),\n",
    "                'Volume': volume\n",
    "            })\n",
    "            \n",
    "            base_price = close_price\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def generate_sample_tick_data(self, date, tick_size):\n",
    "        \"\"\"Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªÙŠÙƒ ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„Ù…Ø«Ø§Ù„\"\"\"\n",
    "        import random\n",
    "        \n",
    "        data = []\n",
    "        base_price = random.uniform(1.0, 2.0)\n",
    "        \n",
    "        for i in range(min(tick_size, 1000)):  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 1000 ØªÙŠÙƒ Ù„Ù„Ù…Ø«Ø§Ù„\n",
    "            timestamp = date + timedelta(seconds=i * 60)\n",
    "            bid = base_price + random.uniform(-0.001, 0.001)\n",
    "            ask = bid + random.uniform(0.0001, 0.0005)\n",
    "            \n",
    "            data.append({\n",
    "                'GMT Time': timestamp.strftime('%Y-%m-%d %H:%M:%S.%f'),\n",
    "                'Bid': round(bid, 5),\n",
    "                'Ask': round(ask, 5),\n",
    "                'Volume': random.randint(1, 100)\n",
    "            })\n",
    "            \n",
    "            base_price = bid\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def merge_and_save_data(self, data, symbol, data_type, timeframe=None):\n",
    "        \"\"\"Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ Ù…Ù„Ù CSV\"\"\"\n",
    "        print(f\"\\nğŸ”„ Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙˆÙ‚Øª GMT...\")\n",
    "        \n",
    "        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ÙˆÙ‚Øª\n",
    "        df = df.sort_values('GMT Time')\n",
    "        \n",
    "        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù„Ù„Ø­ÙØ¸\n",
    "        save_dir = Path(\"Dukascopy_Data\")\n",
    "        save_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # ØªØ­Ø¯ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù\n",
    "        current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if data_type == 'candlesticks':\n",
    "            filename = f\"{symbol}_{timeframe}_{current_time}.csv\"\n",
    "        else:\n",
    "            filename = f\"{symbol}_ticks_{current_time}.csv\"\n",
    "        \n",
    "        file_path = save_dir / filename\n",
    "        \n",
    "        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù\n",
    "        df.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "        print(f\"ğŸ“ Ù…Ø³Ø§Ø± Ø§Ù„Ø­ÙØ¸: {file_path.absolute()}\")\n",
    "        print(f\"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {len(df):,}\")\n",
    "        print(f\"ğŸ’¾ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: {file_path.stat().st_size / 1024:.2f} KB\")\n",
    "        \n",
    "        return file_path\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\"\"\"\n",
    "        try:\n",
    "            print(\"ğŸ”¥ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø£Ø¯Ø§Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Dukascopy!\")\n",
    "            print(\"âš¡ Ø¨Ù†Ø§Ø¡ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\")\n",
    "            \n",
    "            # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙØ¦Ø©\n",
    "            category = self.display_categories()\n",
    "            \n",
    "            # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©\n",
    "            symbol = self.display_instruments(category)\n",
    "            \n",
    "            # Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "            data_type = self.choose_data_type()\n",
    "            \n",
    "            timeframe = None\n",
    "            tick_size = None\n",
    "            \n",
    "            if data_type == 'candlesticks':\n",
    "                timeframe = self.choose_timeframe()\n",
    "            else:\n",
    "                tick_size = self.choose_tick_size()\n",
    "            \n",
    "            # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®\n",
    "            start_date = self.get_date_input(\"ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©\")\n",
    "            end_date = self.get_date_input(\"ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ù‡Ø§ÙŠØ©\")\n",
    "            \n",
    "            if start_date >= end_date:\n",
    "                print(\"âŒ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù‚Ø¨Ù„ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ù‡Ø§ÙŠØ©!\")\n",
    "                return\n",
    "            \n",
    "            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "            data = self.download_data(symbol, data_type, timeframe, tick_size, start_date, end_date)\n",
    "            \n",
    "            # Ø¯Ù…Ø¬ ÙˆØ­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "            file_path = self.merge_and_save_data(data, symbol, data_type, timeframe)\n",
    "            \n",
    "            print(f\"\\nğŸ‰ ØªÙ…Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "            print(f\"ğŸš€ Ø§Ù„Ù…Ù„Ù Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: {file_path.name}\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n\\nâ¹ï¸  ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\"\"\"\n",
    "    downloader = DukascopyDownloader()\n",
    "    downloader.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103caca-66bb-424e-ab68-ceaded276fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb23c2-2c3e-4450-8cec-16186222d0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
