{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8542f79-1a19-49d8-92a6-bef68dcf4b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select main category:\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter category number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected category: Metals\n",
      "\n",
      "Select instrument:\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter instrument number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected instrument: XAUUSD\n",
      "\n",
      "1. Candlestick\n",
      "2. Tick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose data type (number):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1m\n",
      "2. 5m\n",
      "3. 15m\n",
      "4. 1h\n",
      "5. 4h\n",
      "6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select timeframe:  3\n",
      "Enter start date (YYYY-MM-DD):  2020-01-01\n",
      "Enter end date   (YYYY-MM-DD):  2020-01-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2020-01-01...\n",
      "⚠️ تخطى 15m_candles.bi5: HTTP 404\n",
      "\n",
      "Processing 2020-01-02...\n",
      "⚠️ تخطى 15m_candles.bi5: HTTP 404\n",
      "\n",
      "Processing 2020-01-03...\n",
      "⚠️ تخطى 15m_candles.bi5: HTTP 404\n",
      "⚠️ لا توجد ملفات CSV لدمجها.\n",
      "\n",
      "All files stored in: C:\\Users\\Access\\downloads\\XAUUSD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ——————————————\n",
    "# إعدادات أساسية\n",
    "# ——————————————\n",
    "BASE_URL = 'https://datafeed.dukascopy.com/datafeed'\n",
    "CATEGORIES = {\n",
    "    'Metals':  ['XAUUSD', 'XAGUSD'],\n",
    "    'Forex':   ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDUSD'],\n",
    "    'Indices': ['DAX', 'SP500'],\n",
    "}\n",
    "TIMEFRAMES = {\n",
    "    '1m':  '1m', \n",
    "    '5m':  '5m', \n",
    "    '15m': '15m', \n",
    "    '1h':  '1h', \n",
    "    '4h':  '4h', \n",
    "    '1d':  '1d',\n",
    "}\n",
    "\n",
    "# ——————————————\n",
    "# تهيئة الجلسة مع رؤوس متصفح فعلية\n",
    "# ——————————————\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/115.0.0.0 Safari/537.36',\n",
    "    'Referer': 'https://www.dukascopy.com/trading-tools/widgets/quotes/historical_data_feed'\n",
    "})\n",
    "\n",
    "# ——————————————\n",
    "# دوال مساعدة\n",
    "# ——————————————\n",
    "def select_option(options, prompt_text):\n",
    "    for idx, opt in enumerate(options, 1):\n",
    "        print(f\"{idx}. {opt}\")\n",
    "    while True:\n",
    "        choice = input(prompt_text).strip()\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return options[int(choice) - 1]\n",
    "        print(\"اختيار غير صالح، حاول مرة أخرى.\")\n",
    "\n",
    "def build_urls(symbol, date_dt, data_type, timeframe=None):\n",
    "    \"\"\"\n",
    "    يُرجع قائمة بروابط .bi5:\n",
    "    - Candles:   [{tf_code}_candles.bi5]\n",
    "    - Ticks:     [0h_ticks.bi5, 1h_ticks.bi5, ..., 23h_ticks.bi5]\n",
    "    \"\"\"\n",
    "    y = date_dt.year\n",
    "    m = f\"{date_dt.month - 1:02d}\"\n",
    "    d = f\"{date_dt.day:02d}\"\n",
    "    base_path = f\"{symbol}/{y}/{m}/{d}\"\n",
    "    \n",
    "    urls = []\n",
    "    if data_type == 'Candlestick':\n",
    "        tf_code = timeframe\n",
    "        urls.append(f\"{BASE_URL}/{base_path}/{tf_code}_candles.bi5\")\n",
    "    else:\n",
    "        # لكل ساعة ملف ticks\n",
    "        for hour in range(24):\n",
    "            urls.append(f\"{BASE_URL}/{base_path}/{hour:02d}h_ticks.bi5\")\n",
    "    return urls\n",
    "\n",
    "def download_bi5(url, dest_path):\n",
    "    resp = session.get(url, stream=True)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f\"HTTP {resp.status_code}\")\n",
    "    total = resp.headers.get('content-length')\n",
    "    total = int(total) if total and total.isdigit() else None\n",
    "\n",
    "    with open(dest_path, 'wb') as f, tqdm(\n",
    "        total=total, unit='iB', unit_scale=True,\n",
    "        desc=os.path.basename(dest_path),\n",
    "        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\"\n",
    "    ) as bar:\n",
    "        for chunk in resp.iter_content(1024):\n",
    "            if not chunk:\n",
    "                break\n",
    "            f.write(chunk)\n",
    "            bar.update(len(chunk))\n",
    "\n",
    "    if os.path.getsize(dest_path) == 0:\n",
    "        os.remove(dest_path)\n",
    "        raise RuntimeError(\"الملف فارغ\")\n",
    "\n",
    "def bi5_to_csv(bi5_path, csv_path, data_type, timeframe=None):\n",
    "    \"\"\"\n",
    "    فك ضغط .bi5 وتحويله إلى CSV.\n",
    "    • للشموع: يفكّ حسب tf_ms\n",
    "    • للتيك: يحوّل كل سطر إلى صف مستقل (كل سجل 20 بايت يظهر نقطة تيك)\n",
    "    \"\"\"\n",
    "    # مصفوفة زمنية للشموع\n",
    "    tf_ms = {\n",
    "        '1m': 60_000, '5m': 5*60_000, '15m': 15*60_000,\n",
    "        '1h': 3600_000, '4h': 4*3600_000, '1d': 86400_000\n",
    "    }.get(timeframe, None)\n",
    "\n",
    "    with lzma.open(bi5_path) as fin, open(csv_path, 'w', newline='') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        # أعمدة مشتركة\n",
    "        if data_type == 'Candlestick':\n",
    "            writer.writerow(['Gmt time','Open','High','Low','Close','Volume'])\n",
    "        else:\n",
    "            writer.writerow(['Gmt time','Bid','Ask','BidVolume','AskVolume'])\n",
    "        \n",
    "        record_size = 8 + (5*4 if data_type=='Candlestick' else 4*4)\n",
    "        while True:\n",
    "            chunk = fin.read(record_size)\n",
    "            if len(chunk) < record_size:\n",
    "                break\n",
    "            if data_type == 'Candlestick':\n",
    "                t_ms, o, h, l, c, v = struct.unpack('>Qffffi', chunk)\n",
    "                row = [t_ms, o, h, l, c, v]\n",
    "            else:\n",
    "                # هيكل بيانات التيك: Q f f i i  \n",
    "                t_ms, bid, ask, biv, av = struct.unpack('>Qffii', chunk)\n",
    "                row = [t_ms, bid, ask, biv, av]\n",
    "\n",
    "            # حول الزمن إلى نص\n",
    "            row[0] = datetime.utcfromtimestamp(row[0]/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            writer.writerow(row)\n",
    "\n",
    "def merge_csv(csv_files, out_path):\n",
    "    if not csv_files:\n",
    "        print(\"⚠️ لا توجد ملفات CSV لدمجها.\")\n",
    "        return\n",
    "    dfs = [pd.read_csv(f, parse_dates=[0]) for f in csv_files]\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "    all_df.sort_values(all_df.columns[0], inplace=True)\n",
    "    all_df.to_csv(out_path, index=False)\n",
    "    print(f\"\\n✔︎ تم الدمج وحفظ الملف النهائي: {out_path}\")\n",
    "\n",
    "# ——————————————\n",
    "# الدالة الرئيسية\n",
    "# ——————————————\n",
    "def main():\n",
    "    print(\"Select main category:\")\n",
    "    category = select_option(list(CATEGORIES.keys()), \"Enter category number: \")\n",
    "    print(f\"Selected category: {category}\\n\")\n",
    "\n",
    "    print(\"Select instrument:\")\n",
    "    symbol = select_option(CATEGORIES[category], \"Enter instrument number: \")\n",
    "    print(f\"Selected instrument: {symbol}\\n\")\n",
    "\n",
    "    data_type = select_option(['Candlestick', 'Tick'], \"Choose data type (number): \")\n",
    "    timeframe = None\n",
    "    if data_type == 'Candlestick':\n",
    "        timeframe = select_option(list(TIMEFRAMES.keys()), \"Select timeframe: \")\n",
    "\n",
    "    start_dt = datetime.strptime(input(\"Enter start date (YYYY-MM-DD): \").strip(), '%Y-%m-%d')\n",
    "    end_dt   = datetime.strptime(input(\"Enter end date   (YYYY-MM-DD): \").strip(), '%Y-%m-%d')\n",
    "\n",
    "    out_dir = os.path.join(os.getcwd(), 'downloads', symbol)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    csv_files = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        print(f\"\\nProcessing {current.strftime('%Y-%m-%d')}...\")\n",
    "        urls = build_urls(symbol, current, data_type, timeframe)\n",
    "        for url in urls:\n",
    "            filename = os.path.basename(url)\n",
    "            bi5_path = os.path.join(out_dir, filename)\n",
    "            try:\n",
    "                download_bi5(url, bi5_path)\n",
    "                csv_name = filename.replace('.bi5', '.csv')\n",
    "                csv_path = os.path.join(out_dir, csv_name)\n",
    "                bi5_to_csv(bi5_path, csv_path, data_type, timeframe)\n",
    "                csv_files.append(csv_path)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ تخطى {filename}: {e}\")\n",
    "\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "    merged_name = f\"{symbol}_{start_dt.date()}_{end_dt.date()}_merged.csv\"\n",
    "    merge_csv(csv_files, os.path.join(out_dir, merged_name))\n",
    "    print(f\"\\nAll files stored in: {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6287a84-b5f7-4d44-bbb3-9da175ace15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dukascopy Downloader Tool\n",
      "========================================\n",
      "\n",
      "🔹 Select data type\n",
      "1. Tick\n",
      "2. Candlestick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select category\n",
      "1. Metals\n",
      "2. Forex\n",
      "3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Select symbol\n",
      "1. XAUUSD\n",
      "2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n",
      "Enter GMT offset (e.g. 0, 2, -5) [default 0]:  0\n",
      "Start date (e.g. 2020-01-01):  2020-01-01\n",
      "End date (e.g. 2020-01-01):  2020-01-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Config: XAUUSD, Tick, 2020-01-01–2020-01-02, GMT0\n",
      "\n",
      "🔹 Select price type\n",
      "1. Bid فقط\n",
      "2. Ask فقط\n",
      "3. كلاهما\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Starting tick download for XAUUSD...\n",
      "📅 Date range: 2020-01-01 to 2020-01-02\n",
      "⏰ GMT offset: 0\n",
      "[==================================================] 100.00% |   0.45MB of   1.41MB | ETA: 0h 0m 0s\n",
      "\n",
      "📊 Summary: Hours 48, Success 24, Ticks 122574\n",
      "✅ Saved: C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_tick_merged.csv (6.20 MB)\n",
      "\n",
      "✅ Download process finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========== الإعدادات الافتراضية ==========\n",
    "DEFAULT_SAVE_PATH = os.getcwd()\n",
    "CATEGORIES = {\n",
    "    \"Metals\":  [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\":   [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_FRAME_CODES = {\n",
    "    \"1m\": \"60\",\n",
    "    \"5m\": \"300\",\n",
    "    \"15m\": \"900\",\n",
    "    \"1h\": \"3600\",\n",
    "    \"4h\": \"14400\",\n",
    "    \"1d\": \"86400\"\n",
    "}\n",
    "\n",
    "# ========== واجهة القوائم ==========\n",
    "def show_menu(options, title):\n",
    "    print(f\"\\n🔹 {title}\")\n",
    "    for i, opt in enumerate(options):\n",
    "        print(f\"{i + 1}. {opt}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter number: \")) - 1\n",
    "            if 0 <= choice < len(options):\n",
    "                return options[choice]\n",
    "            print(\"❌ Invalid number.\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Please enter a number.\")\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return datetime.strptime(input(f\"{prompt} (e.g. 2020-01-01): \"), \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid date format.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    try:\n",
    "        val = input(\"Enter GMT offset (e.g. 0, 2, -5) [default 0]: \").strip()\n",
    "        return int(val) if val else 0\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "def format_seconds(seconds):\n",
    "    hrs, rem = divmod(int(seconds), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    return f\"{hrs}h {mins}m {secs}s\"\n",
    "\n",
    "# ========== مؤشر التحميل ==========\n",
    "def progress_bar(progress, total, start_time, downloaded_bytes, estimated_total_bytes):\n",
    "    percent = 100 * (progress / total) if total else 0\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = downloaded_bytes / elapsed if elapsed > 0 else 0\n",
    "    remaining = (total - progress) / rate if rate > 0 else 0\n",
    "    downloaded_mb = downloaded_bytes / (1024 * 1024)\n",
    "    total_est_mb = estimated_total_bytes / (1024 * 1024)\n",
    "    bar = '=' * int(percent / 2) + ' ' * (50 - int(percent / 2))\n",
    "    sys.stdout.write(\n",
    "        f\"\\r[{bar}] {percent:6.2f}% | \"\n",
    "        f\"{downloaded_mb:6.2f}MB of {total_est_mb:6.2f}MB | \"\n",
    "        f\"ETA: {format_seconds(remaining)}\"\n",
    "    )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ========== تحميل بيانات Tick ==========\n",
    "def download_tick(symbol, start, end, price_type, gmt_offset, save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    all_ticks = []\n",
    "    total_hours = ((end - start).days + 1) * 24\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_hours * 30 * 1024\n",
    "    successful = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting tick download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.date()} to {end.date()}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}\")\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range((end - start).days + 1)):\n",
    "        for hour in range(24):\n",
    "            url = (\n",
    "                f\"https://datafeed.dukascopy.com/datafeed/\"\n",
    "                f\"{symbol}/{day.year}/{day.month-1:02d}/{day.day:02d}/\"\n",
    "                f\"{hour:02d}h_ticks.bi5\"\n",
    "            )\n",
    "            try:\n",
    "                r = requests.get(url, timeout=15)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    successful += 1\n",
    "                    downloaded_bytes += len(r.content)\n",
    "                    data = lzma.decompress(r.content)\n",
    "                    for i in range(0, len(data), 20):\n",
    "                        chunk = data[i:i+20]\n",
    "                        if len(chunk) < 20: continue\n",
    "                        t_off, ask, bid, ask_vol, bid_vol = struct.unpack(\">IffII\", chunk)\n",
    "                        tick_time = day + timedelta(hours=hour, milliseconds=t_off) + timedelta(hours=gmt_offset)\n",
    "                        ts = tick_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                        if price_type == \"Bid فقط\":\n",
    "                            row = [ts, round(bid,5), bid_vol]\n",
    "                        elif price_type == \"Ask فقط\":\n",
    "                            row = [ts, round(ask,5), ask_vol]\n",
    "                        else:\n",
    "                            row = [ts, round(bid,5), round(ask,5), bid_vol, ask_vol]\n",
    "                        all_ticks.append(row)\n",
    "                # else skip silently\n",
    "            except Exception as e:\n",
    "                print(f\"\\n⚠️ Warning: {day.date()} {hour}h -> {e}\")\n",
    "            count += 1\n",
    "            progress_bar(count, total_hours, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Summary: Hours {count}, Success {successful}, Ticks {len(all_ticks)}\")\n",
    "    out_file = os.path.join(save_path, f\"{symbol}_tick_merged.csv\")\n",
    "    with open(out_file, \"w\", newline='', encoding='utf-8') as f:\n",
    "        w = csv.writer(f)\n",
    "        if price_type==\"Bid فقط\":\n",
    "            w.writerow([\"datetime\",\"bid\",\"bid_volume\"])\n",
    "        elif price_type==\"Ask فقط\":\n",
    "            w.writerow([\"datetime\",\"ask\",\"ask_volume\"])\n",
    "        else:\n",
    "            w.writerow([\"datetime\",\"bid\",\"ask\",\"bid_volume\",\"ask_volume\"])\n",
    "        if all_ticks:\n",
    "            all_ticks.sort(key=lambda x: x[0])\n",
    "            w.writerows(all_ticks)\n",
    "    size = os.path.getsize(out_file)/(1024*1024)\n",
    "    print(f\"✅ Saved: {out_file} ({size:.2f} MB)\")\n",
    "\n",
    "# ========== تحميل بيانات Candlestick ==========\n",
    "def download_candles(symbol, tf_code, start, end, gmt_offset, save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    all_data = []\n",
    "    total_days = (end - start).days + 1\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    downloaded_bytes = 0\n",
    "    estimated_total_bytes = total_days * 10 * 1024\n",
    "    successful = 0\n",
    "\n",
    "    print(f\"\\n🔄 Starting candle download for {symbol}...\")\n",
    "    print(f\"📅 Date range: {start.date()} to {end.date()}\")\n",
    "    print(f\"⏰ GMT offset: {gmt_offset}, Code: {tf_code}\")\n",
    "\n",
    "    for day in (start + timedelta(days=i) for i in range(total_days)):\n",
    "        url = (\n",
    "            f\"https://datafeed.dukascopy.com/datafeed/\"\n",
    "            f\"{symbol}/{day.year}/{day.month-1:02d}/{day.day:02d}/\"\n",
    "            f\"{tf_code}_candles.bi5\"\n",
    "        )\n",
    "        try:\n",
    "            r = requests.get(url, timeout=15)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                successful += 1\n",
    "                downloaded_bytes += len(r.content)\n",
    "                data = lzma.decompress(r.content)\n",
    "                for i in range(0, len(data), 24):\n",
    "                    chunk = data[i:i+24]\n",
    "                    if len(chunk) < 24: continue\n",
    "                    utc_off, o, h, l, c, v = struct.unpack(\">IffffI\", chunk)\n",
    "                    tm = day + timedelta(seconds=utc_off) + timedelta(hours=gmt_offset)\n",
    "                    ts = tm.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    all_data.append([ts, round(o,5), round(h,5), round(l,5), round(c,5), v])\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ Warning: {day.date()} -> {e}\")\n",
    "        count += 1\n",
    "        progress_bar(count, total_days, start_time, downloaded_bytes, estimated_total_bytes)\n",
    "\n",
    "    print(f\"\\n\\n📊 Summary: Days {count}, Success {successful}, Candles {len(all_data)}\")\n",
    "    out_file = os.path.join(save_path, f\"{symbol}_candles_{tf_code}_merged.csv\")\n",
    "    with open(out_file, \"w\", newline='', encoding='utf-8') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"datetime\",\"open\",\"high\",\"low\",\"close\",\"volume\"])\n",
    "        if all_data:\n",
    "            all_data.sort(key=lambda x: x[0])\n",
    "            w.writerows(all_data)\n",
    "    size = os.path.getsize(out_file)/(1024*1024)\n",
    "    print(f\"✅ Saved: {out_file} ({size:.2f} MB)\")\n",
    "\n",
    "# ========== Main ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n📊 Dukascopy Downloader Tool\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    data_type = show_menu([\"Tick\",\"Candlestick\"], \"Select data type\")\n",
    "    category  = show_menu(list(CATEGORIES.keys()), \"Select category\")\n",
    "    symbol    = show_menu(CATEGORIES[category], \"Select symbol\")\n",
    "    gmt_off   = get_gmt_offset()\n",
    "    start     = get_date_input(\"Start date\")\n",
    "    end       = get_date_input(\"End date\")\n",
    "    if start > end:\n",
    "        print(\"❌ End date must be on or after start date.\"); sys.exit(1)\n",
    "    save_dir = os.path.join(DEFAULT_SAVE_PATH, \"downloads\", symbol)\n",
    "\n",
    "    print(f\"\\n📝 Config: {symbol}, {data_type}, {start.date()}–{end.date()}, GMT{gmt_off}\")\n",
    "    if data_type == \"Tick\":\n",
    "        price = show_menu([\"Bid فقط\",\"Ask فقط\",\"كلاهما\"], \"Select price type\")\n",
    "        download_tick(symbol, start, end, price, gmt_off, save_dir)\n",
    "    else:\n",
    "        tf = show_menu(TIMEFRAMES, \"Select timeframe\")\n",
    "        code = CANDLE_FRAME_CODES[tf]\n",
    "        download_candles(symbol, code, start, end, gmt_off, save_dir)\n",
    "\n",
    "    print(\"\\n✅ Download process finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ec0b9e-19fe-48d0-ad00-fb06e49d3c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select main category:\n",
      "  1. Metals\n",
      "  2. Forex\n",
      "  3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select instrument:\n",
      "  1. XAUUSD\n",
      "  2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose data type:\n",
      "  1. Candlestick\n",
      "  2. Tick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select timeframe:\n",
      "  1. 1m\n",
      "  2. 5m\n",
      "  3. 15m\n",
      "  4. 1h\n",
      "  5. 4h\n",
      "  6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  2\n",
      "Start date (YYYY‑MM‑DD):  2020-01-01\n",
      "End date (YYYY‑MM‑DD):  2020-01-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2020-01-01 (1/2)...\n",
      "[####################--------------------]  50.0%  0.00MB/20.00MB ETA 0h0m1s\n",
      "Processing 2020-01-02 (2/2)...\n",
      "[########################################] 100.0%  0.00MB/20.00MB ETA 0h0m0s\n",
      "⚠️ No data to merge.\n",
      "\n",
      "✅ Saved merged CSV: C:\\Users\\Access\\downloads\\XAGUSD\\XAGUSD_2020-01-01_2020-01-02_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ——————————————\n",
    "# 1) إعدادات أساسية: تصنيفات وأدوات وأطر زمنية\n",
    "# ——————————————\n",
    "CATEGORIES = {\n",
    "    \"Metals\":  [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\":   [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "\n",
    "BASE_URL = \"https://datafeed.dukascopy.com/datafeed\"\n",
    "SAVE_DIR = os.path.join(os.getcwd(), \"downloads\")\n",
    "\n",
    "# ——————————————\n",
    "# دوال مساعدة للقوائم والتواريخ\n",
    "# ——————————————\n",
    "def show_menu(options, prompt):\n",
    "    print(f\"\\n{prompt}\")\n",
    "    for i, opt in enumerate(options, 1):\n",
    "        print(f\"  {i}. {opt}\")\n",
    "    while True:\n",
    "        choice = input(\"Enter number: \").strip()\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return options[int(choice) - 1]\n",
    "        print(\"Invalid selection, try again.\")\n",
    "\n",
    "def get_date(prompt):\n",
    "    while True:\n",
    "        s = input(f\"{prompt} (YYYY‑MM‑DD): \").strip()\n",
    "        try:\n",
    "            return datetime.strptime(s, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid date format. Please use YYYY-MM-DD.\")\n",
    "\n",
    "# ——————————————\n",
    "# 7) شريط التقدم مع الوقت المتبقي والحجم والسرعة\n",
    "# ——————————————\n",
    "def progress_bar(done, total, start_ts, downloaded_bytes, estimated_bytes):\n",
    "    pct = done / total if total else 1\n",
    "    elapsed = time.time() - start_ts\n",
    "    rate = downloaded_bytes / elapsed if elapsed>0 else 0\n",
    "    rem = (total - done) / (rate if rate>0 else 1)\n",
    "    bar = \"#\" * int(pct*40) + \"-\" * (40 - int(pct*40))\n",
    "    sys.stdout.write(\n",
    "        f\"\\r[{bar}] {pct*100:5.1f}% \"\n",
    "        f\"{downloaded_bytes/1024/1024:5.2f}MB/\"\n",
    "        f\"{estimated_bytes/1024/1024:5.2f}MB \"\n",
    "        f\"ETA {int(rem//3600)}h{int((rem%3600)//60)}m{int(rem%60)}s\"\n",
    "    )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ——————————————\n",
    "# بناء روابط التحميل\n",
    "# ——————————————\n",
    "def build_urls(symbol, date, data_type, timeframe=None):\n",
    "    y, m0, d = date.year, date.month - 1, date.day\n",
    "    base = f\"{symbol}/{y}/{m0:02d}/{d:02d}\"\n",
    "    urls = []\n",
    "    if data_type == \"Candlestick\":\n",
    "        code = {\"1m\":\"60\",\"5m\":\"300\",\"15m\":\"900\",\"1h\":\"3600\",\"4h\":\"14400\",\"1d\":\"86400\"}[timeframe]\n",
    "        urls.append(f\"{BASE_URL}/{base}/{code}_candles.bi5\")\n",
    "    else:  # Tick: 24 ملفاً لكل ساعة\n",
    "        for h in range(24):\n",
    "            urls.append(f\"{BASE_URL}/{base}/{h:02d}h_ticks.bi5\")\n",
    "    return urls\n",
    "\n",
    "# ——————————————\n",
    "# تنزيل وفك الضغط وتحويل إلى CSV\n",
    "# ——————————————\n",
    "def process_day(symbol, date, data_type, timeframe, out_dir):\n",
    "    csvs = []\n",
    "    for url in build_urls(symbol, date, data_type, timeframe):\n",
    "        fname = url.rsplit(\"/\",1)[-1]\n",
    "        bi5 = os.path.join(out_dir, fname)\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            if r.status_code != 200 or not r.content:\n",
    "                continue\n",
    "            open(bi5,\"wb\").write(r.content)\n",
    "            # فك وتحويل\n",
    "            csv_f = bi5.replace(\".bi5\",\".csv\")\n",
    "            with lzma.open(bi5) as fin, open(csv_f,\"w\",newline=\"\") as fout:\n",
    "                w = csv.writer(fout)\n",
    "                if data_type==\"Candlestick\":\n",
    "                    w.writerow([\"Gmt time\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"])\n",
    "                    rec = 8 + 5*4\n",
    "                    unpack = \">IffffI\"\n",
    "                else:\n",
    "                    w.writerow([\"Gmt time\",\"Bid\",\"Ask\",\"BidVolume\",\"AskVolume\"])\n",
    "                    rec = 20\n",
    "                    unpack = \">IffII\"\n",
    "                data = fin.read()\n",
    "                for i in range(0,len(data),rec):\n",
    "                    chunk = data[i:i+rec]\n",
    "                    if len(chunk)<rec: break\n",
    "                    vals = struct.unpack(unpack, chunk)\n",
    "                    # الوقت بالميلليثانية أو الثواني\n",
    "                    ms = vals[0]\n",
    "                    t = (date + timedelta(milliseconds=ms) if data_type==\"Tick\"\n",
    "                         else date + timedelta(seconds=ms))\n",
    "                    t_str = t.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                    row = [t_str] + list(vals[1:])\n",
    "                    w.writerow(row)\n",
    "            csvs.append(csv_f)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return csvs\n",
    "\n",
    "# ——————————————\n",
    "# 8) دمج الملفات حسب عمود Gmt time\n",
    "# ——————————————\n",
    "def merge_all(csv_list, out_file):\n",
    "    if not csv_list:\n",
    "        print(\"⚠️ No data to merge.\")\n",
    "        return\n",
    "    df = pd.concat(\n",
    "        [pd.read_csv(f, parse_dates=[\"Gmt time\"]) for f in csv_list],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    df.sort_values(\"Gmt time\", inplace=True)\n",
    "    df.to_csv(out_file, index=False)\n",
    "\n",
    "# ——————————————\n",
    "# 2-9) التنفيذ الرئيسي\n",
    "# ——————————————\n",
    "def main():\n",
    "    # 1) القوائم\n",
    "    cat = show_menu(list(CATEGORIES), \"Select main category:\")\n",
    "    sym = show_menu(CATEGORIES[cat], \"Select instrument:\")\n",
    "    # 3) نوع البيانات\n",
    "    dtype = show_menu([\"Candlestick\",\"Tick\"], \"Choose data type:\")\n",
    "    tf = None\n",
    "    if dtype==\"Candlestick\":\n",
    "        tf = show_menu(TIMEFRAMES, \"Select timeframe:\")\n",
    "    # 6) تواريخ البداية والنهاية\n",
    "    start = get_date(\"Start date\")\n",
    "    end   = get_date(\"End date\")\n",
    "    # إنشاء مجلد خروج\n",
    "    out_dir = os.path.join(SAVE_DIR, sym)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # تحميل يومي مع شريط تقدم\n",
    "    total_days = (end - start).days + 1\n",
    "    downloaded_bytes = 0\n",
    "    # تقدير تقريبي: 10MB per candles-day or 30MB per tick-day\n",
    "    est = total_days * (10 if dtype==\"Candlestick\" else 30)\n",
    "    start_ts = time.time()\n",
    "    all_csvs = []\n",
    "    for idx, day in enumerate((start + timedelta(d) for d in range(total_days)), 1):\n",
    "        print(f\"\\nProcessing {day.date()} ({idx}/{total_days})...\")\n",
    "        cs = process_day(sym, day, dtype, tf, out_dir)\n",
    "        all_csvs.extend(cs)\n",
    "        progress_bar(idx, total_days, start_ts, downloaded_bytes, est*1024*1024)\n",
    "    print()\n",
    "\n",
    "    # 8) دمج وحفظ\n",
    "    merged = os.path.join(out_dir, f\"{sym}_{start.date()}_{end.date()}_merged.csv\")\n",
    "    merge_all(all_csvs, merged)\n",
    "\n",
    "    # 9) المسار النهائي\n",
    "    print(f\"\\n✅ Saved merged CSV: {merged}\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7de8fe-affd-447b-a323-4993d705a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ فشل قراءة C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200101.csv: Missing column provided to 'parse_dates': 'Gmt time'\n",
      "⚠️ فشل قراءة C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200102.csv: Missing column provided to 'parse_dates': 'Gmt time'\n",
      "⚠️ فشل قراءة C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200103.csv: Missing column provided to 'parse_dates': 'Gmt time'\n",
      "⚠️ فشل قراءة C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_tick_merged.csv: Missing column provided to 'parse_dates': 'Gmt time'\n",
      "⚠️ لم يُقرأ أي ملف بنجاح.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_folder(input_folder, output_path, time_column):\n",
    "    # اجمع كل مسارات CSV في المجلد\n",
    "    csv_files = [\n",
    "        os.path.join(input_folder, f)\n",
    "        for f in os.listdir(input_folder)\n",
    "        if f.lower().endswith('.csv')\n",
    "    ]\n",
    "    if not csv_files:\n",
    "        print(\"⚠️ لا توجد ملفات CSV في المجلد.\")\n",
    "        return\n",
    "\n",
    "    # اقرأ وادمج\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file, parse_dates=[time_column])\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ فشل قراءة {file}: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"⚠️ لم يُقرأ أي ملف بنجاح.\")\n",
    "        return\n",
    "\n",
    "    merged = pd.concat(dfs, ignore_index=True)\n",
    "    merged.sort_values(time_column, inplace=True)\n",
    "    merged.to_csv(output_path, index=False)\n",
    "    print(f\"✅ تم حفظ الملف المدمج إلى: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # عدّل المسارات واسم العمود هنا:\n",
    "    folder = r\"C:\\Users\\Access\\downloads\\XAUUSD\"  \n",
    "    out_file = os.path.join(folder, \"XAUUSD_merged.csv\")\n",
    "    time_col = \"Gmt time\"      # أو \"datetime\" إذا كان عمودك هكذا\n",
    "    merge_csv_folder(folder, out_file, time_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da118b81-d517-4d92-b087-dbf6034115d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ فشل قراءة C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200101.csv: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n",
      "\n",
      "⚠️ فشل قراءة C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200102.csv: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n",
      "\n",
      "⚠️ فشل قراءة C:\\Users\\Access\\downloads\\XAUUSD\\XAUUSD_20200103.csv: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n",
      "\n",
      "⚠️ لم يُقرأ أي ملف بنجاح.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_folder(input_folder, output_path, time_column):\n",
    "    # اجمع كل مسارات CSV في المجلد\n",
    "    csv_files = [\n",
    "        os.path.join(input_folder, f)\n",
    "        for f in os.listdir(input_folder)\n",
    "        if f.lower().endswith('.csv')\n",
    "    ]\n",
    "    if not csv_files:\n",
    "        print(\"⚠️ لا توجد ملفات CSV في المجلد.\")\n",
    "        return\n",
    "\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            # اقرأ بدون parse_dates\n",
    "            df = pd.read_csv(file)\n",
    "            # حول العمود النصي إلى تاريخ/وقت\n",
    "            df[time_column] = pd.to_datetime(df[time_column], errors='coerce')\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ فشل قراءة {file}: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"⚠️ لم يُقرأ أي ملف بنجاح.\")\n",
    "        return\n",
    "\n",
    "    # ادمج وفرز حسب العمود المحوّل\n",
    "    merged = pd.concat(dfs, ignore_index=True)\n",
    "    merged.sort_values(time_column, inplace=True)\n",
    "    # احفظ\n",
    "    merged.to_csv(output_path, index=False)\n",
    "    print(f\"✅ تم حفظ الملف المدمج إلى: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder   = r\"C:\\Users\\Access\\downloads\\XAUUSD\"\n",
    "    out_file = os.path.join(folder, \"XAUUSD_merged.csv\")\n",
    "    time_col = \"Gmt time\"   # اسم العمود كما في ملفاتك\n",
    "    merge_csv_folder(folder, out_file, time_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ad23e3-6db6-41fd-b42f-79061179064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ تجاهل XAUUSD_20200101.csv: لا يوجد عمود 'Gmt time'\n",
      "⚠️ تجاهل XAUUSD_20200102.csv: لا يوجد عمود 'Gmt time'\n",
      "⚠️ تجاهل XAUUSD_20200103.csv: لا يوجد عمود 'Gmt time'\n",
      "⚠️ لم يُقرأ أي ملف صالح.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_folder(input_folder, output_path, time_column):\n",
    "    # 1) اجمع كل ملفات CSV\n",
    "    csv_files = [\n",
    "        os.path.join(input_folder, f)\n",
    "        for f in os.listdir(input_folder)\n",
    "        if f.lower().endswith('.csv')\n",
    "    ]\n",
    "    if not csv_files:\n",
    "        print(\"⚠️ لا توجد ملفات CSV في المجلد.\")\n",
    "        return\n",
    "\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            # 2) اقرأ مع تجاوز الأسطر غير الصالحة\n",
    "            df = pd.read_csv(\n",
    "                file,\n",
    "                sep=',',\n",
    "                engine='python',\n",
    "                on_bad_lines='skip'\n",
    "            )\n",
    "            # 3) إذا وجد العمود وقم بتحويله\n",
    "            if time_column in df.columns:\n",
    "                df[time_column] = pd.to_datetime(df[time_column], errors='coerce')\n",
    "                dfs.append(df)\n",
    "            else:\n",
    "                print(f\"⚠️ تجاهل {os.path.basename(file)}: لا يوجد عمود '{time_column}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ فشل قراءة {os.path.basename(file)}: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"⚠️ لم يُقرأ أي ملف صالح.\")\n",
    "        return\n",
    "\n",
    "    # 4) دمج وفرز وحفظ\n",
    "    merged = pd.concat(dfs, ignore_index=True)\n",
    "    merged.sort_values(time_column, inplace=True)\n",
    "    merged.to_csv(output_path, index=False)\n",
    "    print(f\"✅ تم حفظ الملف المدمج إلى: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder   = r\"C:\\Users\\Access\\downloads\\XAUUSD\"\n",
    "    out_file = os.path.join(folder, \"XAUUSD_merged.csv\")\n",
    "    time_col = \"Gmt time\"  # عدّله إذا عمودك اسمه \"datetime\"\n",
    "    merge_csv_folder(folder, out_file, time_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4daf5e19-504e-484b-98f7-72d25cb203f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select main category:\n",
      "  1. Metals\n",
      "  2. Forex\n",
      "  3. Indices\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select instrument:\n",
      "  1. XAUUSD\n",
      "  2. XAGUSD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose data type:\n",
      "  1. Candlestick\n",
      "  2. Tick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select timeframe:\n",
      "  1. 1m\n",
      "  2. 5m\n",
      "  3. 15m\n",
      "  4. 1h\n",
      "  5. 4h\n",
      "  6. 1d\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number:  3\n",
      "Start date (YYYY‑MM‑DD):  2020-01-01\n",
      "End date (YYYY‑MM‑DD):  2020-01-03\n",
      "Enter GMT offset [default 0]:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ No CSVs to merge.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import lzma\n",
    "import struct\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ——————————————\n",
    "# 1) إعدادات أساسية: تصنيفات وأدوات وأطر زمنية\n",
    "# ——————————————\n",
    "CATEGORIES = {\n",
    "    \"Metals\":  [\"XAUUSD\", \"XAGUSD\"],\n",
    "    \"Forex\":   [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDUSD\", \"NZDUSD\"],\n",
    "    \"Indices\": [\"US500\", \"NAS100\", \"GER30\"]\n",
    "}\n",
    "TIMEFRAMES = [\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "CANDLE_CODES = {\"1m\":\"60\",\"5m\":\"300\",\"15m\":\"900\",\"1h\":\"3600\",\"4h\":\"14400\",\"1d\":\"86400\"}\n",
    "\n",
    "BASE_URL = \"https://datafeed.dukascopy.com/datafeed\"\n",
    "SAVE_ROOT = os.path.join(os.getcwd(), \"downloads\")\n",
    "\n",
    "# ——————————————\n",
    "# قوائم الاختيار والتواريخ\n",
    "# ——————————————\n",
    "def show_menu(options, prompt):\n",
    "    print(f\"\\n{prompt}\")\n",
    "    for i, opt in enumerate(options, 1):\n",
    "        print(f\"  {i}. {opt}\")\n",
    "    while True:\n",
    "        choice = input(\"Enter number: \").strip()\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return options[int(choice) - 1]\n",
    "        print(\"Invalid selection, try again.\")\n",
    "\n",
    "def get_date(prompt):\n",
    "    while True:\n",
    "        s = input(f\"{prompt} (YYYY‑MM‑DD): \").strip()\n",
    "        try:\n",
    "            return datetime.strptime(s, \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid format. Use YYYY-MM-DD.\")\n",
    "\n",
    "def get_gmt_offset():\n",
    "    s = input(\"Enter GMT offset [default 0]: \").strip()\n",
    "    try:\n",
    "        return int(s) if s else 0\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "# ——————————————\n",
    "# 7) شريط التقدم\n",
    "# ——————————————\n",
    "def progress_bar(done, total, start_ts, downloaded, estimated_bytes):\n",
    "    pct = done/total if total else 1\n",
    "    elapsed = time.time() - start_ts\n",
    "    rate = downloaded/elapsed if elapsed>0 else 0\n",
    "    rem = (total-done)/(rate if rate>0 else 1)\n",
    "    bar = \"#\" * int(pct*40) + \"-\" * (40-int(pct*40))\n",
    "    sys.stdout.write(\n",
    "        f\"\\r[{bar}] {pct*100:5.1f}% \"\n",
    "        f\"{downloaded/1024/1024:6.2f}MB/\"\n",
    "        f\"{estimated_bytes/1024/1024:6.2f}MB \"\n",
    "        f\"ETA {int(rem//3600)}h{int((rem%3600)//60)}m{int(rem%60)}s\"\n",
    "    )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# ——————————————\n",
    "# 2–6) بناء روابط وتنزيل وفك ضغط\n",
    "# ——————————————\n",
    "def build_urls(symbol, date, dtype, tf=None):\n",
    "    y, m0, d = date.year, date.month-1, date.day\n",
    "    base = f\"{symbol}/{y}/{m0:02d}/{d:02d}\"\n",
    "    urls = []\n",
    "    if dtype==\"Candlestick\":\n",
    "        code = CANDLE_CODES[tf]\n",
    "        urls.append(f\"{BASE_URL}/{base}/{code}_candles.bi5\")\n",
    "    else:\n",
    "        for h in range(24):\n",
    "            urls.append(f\"{BASE_URL}/{base}/{h:02d}h_ticks.bi5\")\n",
    "    return urls\n",
    "\n",
    "def process_day(symbol, date, dtype, tf, out_dir, downloaded, total_units, start_ts, est_bytes):\n",
    "    csvs = []\n",
    "    for url in build_urls(symbol, date, dtype, tf):\n",
    "        fn = os.path.basename(url)\n",
    "        bi5 = os.path.join(out_dir, fn)\n",
    "        try:\n",
    "            r = requests.get(url, timeout=15)\n",
    "            if r.status_code != 200 or not r.content:\n",
    "                continue\n",
    "            downloaded += len(r.content)\n",
    "            open(bi5, \"wb\").write(r.content)\n",
    "            # فكّ وضغط إلى CSV\n",
    "            csvf = bi5.replace(\".bi5\", \".csv\")\n",
    "            with lzma.open(bi5) as fin, open(csvf, \"w\", newline=\"\") as fout:\n",
    "                w = csv.writer(fout)\n",
    "                if dtype==\"Candlestick\":\n",
    "                    w.writerow([\"Gmt time\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"])\n",
    "                    rec, unpack = 24, \">IffffI\"\n",
    "                else:\n",
    "                    w.writerow([\"Gmt time\",\"Bid\",\"Ask\",\"BidVolume\",\"AskVolume\"])\n",
    "                    rec, unpack = 20, \">IffII\"\n",
    "                data = fin.read()\n",
    "                for i in range(0, len(data), rec):\n",
    "                    chunk = data[i:i+rec]\n",
    "                    if len(chunk)<rec: break\n",
    "                    vals = struct.unpack(unpack, chunk)\n",
    "                    ms = vals[0]\n",
    "                    t = date + (timedelta(milliseconds=ms) if dtype==\"Tick\" else timedelta(seconds=ms))\n",
    "                    t_str = t.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                    row = [t_str] + list(vals[1:])\n",
    "                    w.writerow(row)\n",
    "            csvs.append(csvf)\n",
    "        except Exception:\n",
    "            pass\n",
    "        total_units += 1\n",
    "        progress_bar(total_units, day_count* (24 if dtype==\"Tick\" else 1),\n",
    "                     start_ts, downloaded, est_bytes)\n",
    "    return csvs, downloaded, total_units\n",
    "\n",
    "# ——————————————\n",
    "# 8) دمج CSVات مع تجاوز الأسطر الخاطئة\n",
    "# ——————————————\n",
    "def merge_csv_folder(folder, out_path, time_col):\n",
    "    files = [os.path.join(folder,f) for f in os.listdir(folder) if f.endswith(\".csv\")]\n",
    "    if not files:\n",
    "        print(\"⚠️ No CSVs to merge.\"); return\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            df = pd.read_csv(f, sep=\",\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "            if time_col in df.columns:\n",
    "                df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "                dfs.append(df)\n",
    "        except:\n",
    "            pass\n",
    "    if not dfs:\n",
    "        print(\"⚠️ Nothing to merge.\"); return\n",
    "    merged = pd.concat(dfs, ignore_index=True).sort_values(time_col)\n",
    "    merged.to_csv(out_path, index=False)\n",
    "    print(f\"\\n✅ Saved merged CSV: {out_path}\")\n",
    "\n",
    "# ——————————————\n",
    "# 9) تنفيذ رئيسي\n",
    "# ——————————————\n",
    "if __name__==\"__main__\":\n",
    "    # 1–6: القوائم والتواريخ\n",
    "    cat = show_menu(list(CATEGORIES), \"Select main category:\")\n",
    "    sym = show_menu(CATEGORIES[cat], \"Select instrument:\")\n",
    "    dtype = show_menu([\"Candlestick\",\"Tick\"], \"Choose data type:\")\n",
    "    tf = show_menu(TIMEFRAMES, \"Select timeframe:\") if dtype==\"Candlestick\" else None\n",
    "    start = get_date(\"Start date\")\n",
    "    end   = get_date(\"End date\")\n",
    "    gmt   = get_gmt_offset()\n",
    "\n",
    "    # إعداد التحميل\n",
    "    out_dir = os.path.join(SAVE_ROOT, sym)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    day_count = (end-start).days+1\n",
    "    total_units = 0\n",
    "    downloaded_bytes = 0\n",
    "    est_bytes = day_count * (10*1024*1024 if dtype==\"Candlestick\" else 30*1024*1024)\n",
    "    start_ts = time.time()\n",
    "\n",
    "    all_csv = []\n",
    "    for date in (start + timedelta(i) for i in range(day_count)):\n",
    "        cs, downloaded_bytes, total_units = process_day(\n",
    "            sym, date, dtype, tf, out_dir,\n",
    "            downloaded_bytes, total_units, start_ts, est_bytes\n",
    "        )\n",
    "        all_csv.extend(cs)\n",
    "    print()\n",
    "\n",
    "    # 8–9: دمج واحفظ\n",
    "    merged_file = os.path.join(out_dir, f\"{sym}_{start.date()}_{end.date()}_merged.csv\")\n",
    "    merge_csv_folder(out_dir, merged_file, \"Gmt time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6bc2733-d9fa-4def-ae50-61bbdcff65f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Access\\AppData\\Local\\Temp\\ipykernel_28588\\1066112427.py:46: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  today = datetime.utcnow().date()\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 163\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    162\u001b[0m     root \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mTk()\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mApp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m     root\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m, in \u001b[0;36mApp.__init__\u001b[1;34m(self, root)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpack(fill\u001b[38;5;241m=\u001b[39mtk\u001b[38;5;241m.\u001b[39mBOTH, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_widgets()\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_symbols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 63\u001b[0m, in \u001b[0;36mApp.fetch_symbols\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_symbols\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     62\u001b[0m     resp \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(BASE)\n\u001b[1;32m---> 63\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# نسق: [{\"instrumentType\": \"...\", \"instruments\": [...]}, ...]\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes \u001b[38;5;241m=\u001b[39m {d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstrumentType\u001b[39m\u001b[38;5;124m\"\u001b[39m]: d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstruments\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data}\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, filedialog\n",
    "import requests, threading, time, csv\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "\n",
    "BASE = \"https://www.dukascopy.com/trading-tools/widgets/quotes/historical_data_feed\"\n",
    "\n",
    "class App(ttk.Frame):\n",
    "    def __init__(self, root):\n",
    "        super().__init__(root)\n",
    "        self.root = root\n",
    "        self.root.title(\"Dukascopy Data Downloader\")\n",
    "        self.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.fetch_symbols()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        # أداة + أداة فرعية\n",
    "        ttk.Label(self, text=\"Instrument type:\").grid(row=0, column=0, sticky=tk.W)\n",
    "        self.inst_type = ttk.Combobox(self, state=\"readonly\")\n",
    "        self.inst_type.grid(row=0, column=1)\n",
    "        self.inst_type.bind(\"<<ComboboxSelected>>\", self.on_inst_type)\n",
    "\n",
    "        ttk.Label(self, text=\"Instrument:\").grid(row=1, column=0, sticky=tk.W)\n",
    "        self.inst = ttk.Combobox(self, state=\"readonly\")\n",
    "        self.inst.grid(row=1, column=1)\n",
    "\n",
    "        # الشموع vs تيك\n",
    "        self.mode = tk.StringVar(value=\"candles\")\n",
    "        ttk.Radiobutton(self, text=\"Candles\", variable=self.mode, value=\"candles\",\n",
    "                        command=self.on_mode).grid(row=2, column=0)\n",
    "        ttk.Radiobutton(self, text=\"Ticks\",   variable=self.mode, value=\"ticks\",\n",
    "                        command=self.on_mode).grid(row=2, column=1)\n",
    "\n",
    "        # فريم أو عدد تيك\n",
    "        ttk.Label(self, text=\"Timeframe / Tick count:\").grid(row=3, column=0, sticky=tk.W)\n",
    "        self.tf = ttk.Combobox(self, state=\"readonly\")\n",
    "        self.tf.grid(row=3, column=1)\n",
    "\n",
    "        # تاريخ البداية–النهاية\n",
    "        today = datetime.utcnow().date()\n",
    "        ttk.Label(self, text=\"From (YYYY-mm-dd):\").grid(row=4, column=0, sticky=tk.W)\n",
    "        self.from_e = ttk.Entry(self); self.from_e.grid(row=4, column=1); self.from_e.insert(0, today)\n",
    "        ttk.Label(self, text=\"To (YYYY-mm-dd):\").grid(row=5, column=0, sticky=tk.W)\n",
    "        self.to_e = ttk.Entry(self); self.to_e.grid(row=5, column=1); self.to_e.insert(0, today)\n",
    "\n",
    "        # تنزيل + شريط تقدم\n",
    "        self.download_btn = ttk.Button(self, text=\"Download\", command=self.on_download)\n",
    "        self.download_btn.grid(row=6, column=0, columnspan=2, pady=5)\n",
    "\n",
    "        self.progress = ttk.Progressbar(self, mode=\"determinate\", length=300)\n",
    "        self.progress.grid(row=7, column=0, columnspan=2, pady=5)\n",
    "        self.status = ttk.Label(self, text=\"Status: Idle\")\n",
    "        self.status.grid(row=8, column=0, columnspan=2)\n",
    "\n",
    "    def fetch_symbols(self):\n",
    "        resp = requests.get(BASE)\n",
    "        data = resp.json()\n",
    "        # نسق: [{\"instrumentType\": \"...\", \"instruments\": [...]}, ...]\n",
    "        self.types = {d[\"instrumentType\"]: d[\"instruments\"] for d in data}\n",
    "        tt = list(self.types.keys())\n",
    "        self.inst_type[\"values\"] = tt\n",
    "        if tt:\n",
    "            self.inst_type.current(0)\n",
    "            self.on_inst_type()\n",
    "\n",
    "    def on_inst_type(self, *_):\n",
    "        t = self.inst_type.get()\n",
    "        self.inst[\"values\"] = self.types[t]\n",
    "        if self.types[t]:\n",
    "            self.inst.current(0)\n",
    "\n",
    "    def on_mode(self):\n",
    "        if self.mode.get() == \"candles\":\n",
    "            self.tf[\"values\"] = [\"MINUTE\", \"HOUR\", \"DAY\", \"WEEK\", \"MONTH\"]\n",
    "            self.tf.current(0)\n",
    "        else:\n",
    "            self.tf[\"values\"] = [\"1\", \"10\", \"100\", \"1000\"]\n",
    "            self.tf.current(0)\n",
    "\n",
    "    def on_download(self):\n",
    "        try:\n",
    "            start = datetime.strptime(self.from_e.get().strip(), \"%Y-%m-%d\")\n",
    "            end   = datetime.strptime(self.to_e.get().strip(), \"%Y-%m-%d\")\n",
    "        except:\n",
    "            messagebox.showerror(\"Date error\", \"Invalid date format!\")\n",
    "            return\n",
    "\n",
    "        inst = self.inst.get().upper()\n",
    "        mode = self.mode.get()\n",
    "        tf = self.tf.get()\n",
    "\n",
    "        path = filedialog.asksaveasfilename(defaultextension=\".csv\",\n",
    "                                            filetypes=[(\"CSV\",\"*.csv\")])\n",
    "        if not path: return\n",
    "\n",
    "        t = threading.Thread(target=self.download_thread, args=(inst, mode, tf, start, end, path))\n",
    "        t.start()\n",
    "\n",
    "    def download_thread(self, inst, mode, tf, start, end, path):\n",
    "        self.download_btn.config(state=tk.DISABLED)\n",
    "        total_days = (end - start).days + 1\n",
    "        chunk_days = 5  # تقسيم لكل تحميل\n",
    "        urls = []\n",
    "        for i in range(0, total_days, chunk_days):\n",
    "            s = start + timedelta(days=i)\n",
    "            e = min(s + timedelta(days=chunk_days-1), end)\n",
    "            urls.append((s, e))\n",
    "        all_rows = []\n",
    "        downloaded = 0\n",
    "        total = len(urls)\n",
    "        start_t0 = time.time()\n",
    "\n",
    "        for idx, (s, e) in enumerate(urls):\n",
    "            params = {\n",
    "                \"instrument\": inst,\n",
    "                \"type\": mode,\n",
    "                \"timeFrame\": tf if mode==\"candles\" else \"\",\n",
    "                \"startDate\": s.strftime(\"%Y-%m-%d\"),\n",
    "                \"endDate\":   e.strftime(\"%Y-%m-%d\"),\n",
    "                \"tickPrecision\": tf if mode==\"ticks\" else \"\"\n",
    "            }\n",
    "            t0 = time.time()\n",
    "            r = requests.get(BASE, params=params, stream=True)\n",
    "            size = 0\n",
    "            data = StringIO()\n",
    "            for chunk in r.iter_content(chunk_size=1024*10):\n",
    "                if not chunk: break\n",
    "                data.write(chunk.decode())\n",
    "                size += len(chunk)\n",
    "                elapsed = time.time() - t0\n",
    "                speed = size / elapsed if elapsed>0 else 0\n",
    "                done = (idx + size/len(r.content if r.content else b\"\")) / total\n",
    "                self.progress[\"value\"] = min(100, done*100)\n",
    "                rem = elapsed * ((total-idx) - (size/len(r.content if r.content else b\"\")))\n",
    "                self.status.config(text=f\"Chunk {idx+1}/{total}, {size//1024} KB, {int(speed)} B/s, ETA {int(rem)}s\")\n",
    "                self.root.update_idletasks()\n",
    "            # معالجة CSV\n",
    "            data.seek(0)\n",
    "            reader = csv.reader(data)\n",
    "            rows = list(reader)\n",
    "            all_rows.extend(rows[1:] if all_rows else rows)\n",
    "            downloaded += 1\n",
    "\n",
    "        # دمج حسب GMT time (أفقي)\n",
    "        all_rows.sort(key=lambda r: r[0])\n",
    "        with open(path, \"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(all_rows)\n",
    "\n",
    "        total_time = time.time() - start_t0\n",
    "        self.status.config(text=f\"Completed in {int(total_time)}s, saved to {path}\")\n",
    "        messagebox.showinfo(\"Done\", f\"Saved to:\\n{path}\")\n",
    "        self.download_btn.config(state=tk.NORMAL)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    root = tk.Tk()\n",
    "    App(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d9cc0c1-3e18-40d2-8194-a87969cd6be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 مرحباً بك في أداة تحميل البيانات من Dukascopy!\n",
      "⚡ بناء احترافي مع جميع الميزات المطلوبة\n",
      "\n",
      "==================================================\n",
      "🏆 أداة تحميل البيانات من Dukascopy\n",
      "==================================================\n",
      "\n",
      "اختر فئة الأدوات المالية:\n",
      "1. العملات (Forex)\n",
      "2. المؤشرات (Indices)\n",
      "3. السلع (Commodities)\n",
      "4. العملات المشفرة (Crypto)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "أدخل رقم الفئة:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 الأدوات المالية في فئة: العملات (Forex)\n",
      "----------------------------------------\n",
      "1. EUR/USD (EURUSD)\n",
      "2. GBP/USD (GBPUSD)\n",
      "3. USD/JPY (USDJPY)\n",
      "4. USD/CHF (USDCHF)\n",
      "5. AUD/USD (AUDUSD)\n",
      "6. USD/CAD (USDCAD)\n",
      "7. NZD/USD (NZDUSD)\n",
      "8. EUR/GBP (EURGBP)\n",
      "9. EUR/JPY (EURJPY)\n",
      "10. GBP/JPY (GBPJPY)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "أدخل رقم الأداة المالية:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 نوع البيانات:\n",
      "1. شموع يابانية (Candlesticks)\n",
      "2. بيانات التيك (Tick Data)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "أدخل اختيارك (1 أو 2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 اختر عدد التيك:\n",
      "1. 100 تيك\n",
      "2. 500 تيك\n",
      "3. 1,000 تيك\n",
      "4. 5,000 تيك\n",
      "5. 10,000 تيك\n",
      "6. 50,000 تيك\n",
      "7. 100,000 تيك\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "أدخل رقم الخيار:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📅 تاريخ البداية\n",
      "الصيغة: YYYY-MM-DD (مثال: 2024-01-15)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "أدخل التاريخ:  2025-01-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📅 تاريخ النهاية\n",
      "الصيغة: YYYY-MM-DD (مثال: 2024-01-15)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "أدخل التاريخ:  2025-01-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 بدء تحميل البيانات...\n",
      "📊 الأداة: EURUSD\n",
      "📈 نوع البيانات: ticks\n",
      "🎯 حجم التيك: 100\n",
      "📅 من: 2025-01-01 إلى: 2025-01-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 التحميل: 3يوم [00:00,  9.42يوم/s, حجم الملف=26.3 KB, السرعة=82.2 KB/s, الوقت المتبقي=-1:59:59]                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ تم تحميل 300 سجل بنجاح!\n",
      "\n",
      "🔄 دمج البيانات حسب عمود الوقت GMT...\n",
      "💾 تم حفظ الملف بنجاح!\n",
      "📁 مسار الحفظ: C:\\Users\\Access\\Dukascopy_Data\\EURUSD_ticks_20250702_054930.csv\n",
      "📊 عدد السجلات: 300\n",
      "💾 حجم الملف: 13.71 KB\n",
      "\n",
      "🎉 تمت العملية بنجاح!\n",
      "🚀 الملف جاهز للاستخدام: EURUSD_ticks_20250702_054930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from urllib.parse import urlencode\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "class DukascopyDownloader:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.dukascopy.com/trading-tools/widgets/quotes/historical_data_feed\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "        \n",
    "        # الأدوات المالية الرئيسية\n",
    "        self.instruments = {\n",
    "            'العملات (Forex)': {\n",
    "                'EURUSD': 'EUR/USD',\n",
    "                'GBPUSD': 'GBP/USD', \n",
    "                'USDJPY': 'USD/JPY',\n",
    "                'USDCHF': 'USD/CHF',\n",
    "                'AUDUSD': 'AUD/USD',\n",
    "                'USDCAD': 'USD/CAD',\n",
    "                'NZDUSD': 'NZD/USD',\n",
    "                'EURGBP': 'EUR/GBP',\n",
    "                'EURJPY': 'EUR/JPY',\n",
    "                'GBPJPY': 'GBP/JPY'\n",
    "            },\n",
    "            'المؤشرات (Indices)': {\n",
    "                'SPX500': 'S&P 500',\n",
    "                'NAS100': 'NASDAQ 100',\n",
    "                'DJ30': 'Dow Jones 30',\n",
    "                'GER30': 'DAX 30',\n",
    "                'UK100': 'FTSE 100',\n",
    "                'FRA40': 'CAC 40',\n",
    "                'JPN225': 'Nikkei 225'\n",
    "            },\n",
    "            'السلع (Commodities)': {\n",
    "                'XAUUSD': 'Gold/USD',\n",
    "                'XAGUSD': 'Silver/USD',\n",
    "                'WTIUSD': 'WTI Oil/USD',\n",
    "                'BRENTUSD': 'Brent Oil/USD',\n",
    "                'NATGASUSD': 'Natural Gas/USD'\n",
    "            },\n",
    "            'العملات المشفرة (Crypto)': {\n",
    "                'BTCUSD': 'Bitcoin/USD',\n",
    "                'ETHUSD': 'Ethereum/USD',\n",
    "                'LTCUSD': 'Litecoin/USD',\n",
    "                'XRPUSD': 'Ripple/USD'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # التايم فريم المتاحة\n",
    "        self.timeframes = {\n",
    "            '1 دقيقة': 'm1',\n",
    "            '5 دقائق': 'm5',\n",
    "            '15 دقيقة': 'm15',\n",
    "            '30 دقيقة': 'm30',\n",
    "            '1 ساعة': 'h1',\n",
    "            '4 ساعات': 'h4',\n",
    "            '1 يوم': 'd1',\n",
    "            '1 أسبوع': 'w1',\n",
    "            '1 شهر': 'mn1'\n",
    "        }\n",
    "        \n",
    "        # خيارات التيك\n",
    "        self.tick_options = [100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "\n",
    "    def display_categories(self):\n",
    "        \"\"\"عرض الفئات الرئيسية للأدوات المالية\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"🏆 أداة تحميل البيانات من Dukascopy\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"\\nاختر فئة الأدوات المالية:\")\n",
    "        \n",
    "        categories = list(self.instruments.keys())\n",
    "        for i, category in enumerate(categories, 1):\n",
    "            print(f\"{i}. {category}\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nأدخل رقم الفئة: \")) - 1\n",
    "                if 0 <= choice < len(categories):\n",
    "                    return categories[choice]\n",
    "                else:\n",
    "                    print(\"❌ خيار غير صحيح. حاول مرة أخرى.\")\n",
    "            except ValueError:\n",
    "                print(\"❌ يجب إدخال رقم صحيح.\")\n",
    "\n",
    "    def display_instruments(self, category):\n",
    "        \"\"\"عرض الأدوات المالية في الفئة المحددة\"\"\"\n",
    "        print(f\"\\n📊 الأدوات المالية في فئة: {category}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        instruments = list(self.instruments[category].items())\n",
    "        for i, (symbol, name) in enumerate(instruments, 1):\n",
    "            print(f\"{i}. {name} ({symbol})\")\n",
    "            \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nأدخل رقم الأداة المالية: \")) - 1\n",
    "                if 0 <= choice < len(instruments):\n",
    "                    return instruments[choice][0]\n",
    "                else:\n",
    "                    print(\"❌ خيار غير صحيح. حاول مرة أخرى.\")\n",
    "            except ValueError:\n",
    "                print(\"❌ يجب إدخال رقم صحيح.\")\n",
    "\n",
    "    def choose_data_type(self):\n",
    "        \"\"\"اختيار نوع البيانات: شموع يابانية أم تيك\"\"\"\n",
    "        print(\"\\n📈 نوع البيانات:\")\n",
    "        print(\"1. شموع يابانية (Candlesticks)\")\n",
    "        print(\"2. بيانات التيك (Tick Data)\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nأدخل اختيارك (1 أو 2): \"))\n",
    "                if choice == 1:\n",
    "                    return 'candlesticks'\n",
    "                elif choice == 2:\n",
    "                    return 'ticks'\n",
    "                else:\n",
    "                    print(\"❌ خيار غير صحيح. اختر 1 أو 2.\")\n",
    "            except ValueError:\n",
    "                print(\"❌ يجب إدخال رقم صحيح.\")\n",
    "\n",
    "    def choose_timeframe(self):\n",
    "        \"\"\"اختيار التايم فريم للشموع اليابانية\"\"\"\n",
    "        print(\"\\n⏰ اختر التايم فريم:\")\n",
    "        \n",
    "        timeframes = list(self.timeframes.items())\n",
    "        for i, (name, code) in enumerate(timeframes, 1):\n",
    "            print(f\"{i}. {name}\")\n",
    "            \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nأدخل رقم التايم فريم: \")) - 1\n",
    "                if 0 <= choice < len(timeframes):\n",
    "                    return timeframes[choice][1]\n",
    "                else:\n",
    "                    print(\"❌ خيار غير صحيح. حاول مرة أخرى.\")\n",
    "            except ValueError:\n",
    "                print(\"❌ يجب إدخال رقم صحيح.\")\n",
    "\n",
    "    def choose_tick_size(self):\n",
    "        \"\"\"اختيار حجم التيك\"\"\"\n",
    "        print(\"\\n🎯 اختر عدد التيك:\")\n",
    "        \n",
    "        for i, size in enumerate(self.tick_options, 1):\n",
    "            print(f\"{i}. {size:,} تيك\")\n",
    "            \n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\nأدخل رقم الخيار: \")) - 1\n",
    "                if 0 <= choice < len(self.tick_options):\n",
    "                    return self.tick_options[choice]\n",
    "                else:\n",
    "                    print(\"❌ خيار غير صحيح. حاول مرة أخرى.\")\n",
    "            except ValueError:\n",
    "                print(\"❌ يجب إدخال رقم صحيح.\")\n",
    "\n",
    "    def get_date_input(self, prompt):\n",
    "        \"\"\"الحصول على تاريخ من المستخدم\"\"\"\n",
    "        print(f\"\\n📅 {prompt}\")\n",
    "        print(\"الصيغة: YYYY-MM-DD (مثال: 2024-01-15)\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                date_str = input(\"أدخل التاريخ: \")\n",
    "                date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "                return date_obj\n",
    "            except ValueError:\n",
    "                print(\"❌ تاريخ غير صحيح. استخدم الصيغة: YYYY-MM-DD\")\n",
    "\n",
    "    def download_data(self, symbol, data_type, timeframe=None, tick_size=None, start_date=None, end_date=None):\n",
    "        \"\"\"تحميل البيانات مع شريط التقدم\"\"\"\n",
    "        print(f\"\\n🚀 بدء تحميل البيانات...\")\n",
    "        print(f\"📊 الأداة: {symbol}\")\n",
    "        print(f\"📈 نوع البيانات: {data_type}\")\n",
    "        if timeframe:\n",
    "            print(f\"⏰ التايم فريم: {timeframe}\")\n",
    "        if tick_size:\n",
    "            print(f\"🎯 حجم التيك: {tick_size:,}\")\n",
    "        print(f\"📅 من: {start_date.strftime('%Y-%m-%d')} إلى: {end_date.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # محاكاة تحميل البيانات\n",
    "        total_days = (end_date - start_date).days\n",
    "        downloaded_data = []\n",
    "        \n",
    "        start_time = time.time()\n",
    "        file_size = 0\n",
    "        \n",
    "        with tqdm(total=total_days, desc=\"📥 التحميل\", unit=\"يوم\") as pbar:\n",
    "            current_date = start_date\n",
    "            while current_date <= end_date:\n",
    "                # محاكاة تحميل بيانات يوم واحد\n",
    "                time.sleep(0.1)  # محاكاة زمن التحميل\n",
    "                \n",
    "                # إنشاء بيانات وهمية للمثال\n",
    "                if data_type == 'candlesticks':\n",
    "                    daily_data = self.generate_sample_candlestick_data(current_date, timeframe)\n",
    "                else:\n",
    "                    daily_data = self.generate_sample_tick_data(current_date, tick_size)\n",
    "                \n",
    "                downloaded_data.extend(daily_data)\n",
    "                file_size += len(str(daily_data))\n",
    "                \n",
    "                # حساب الوقت المتبقي\n",
    "                elapsed_time = time.time() - start_time\n",
    "                days_done = (current_date - start_date).days + 1\n",
    "                if days_done > 0:\n",
    "                    avg_time_per_day = elapsed_time / days_done\n",
    "                    remaining_days = total_days - days_done\n",
    "                    remaining_time = avg_time_per_day * remaining_days\n",
    "                    \n",
    "                    hours = int(remaining_time // 3600)\n",
    "                    minutes = int((remaining_time % 3600) // 60)\n",
    "                    seconds = int(remaining_time % 60)\n",
    "                    \n",
    "                    speed = file_size / elapsed_time / 1024  # KB/s\n",
    "                    \n",
    "                    pbar.set_postfix({\n",
    "                        'حجم الملف': f'{file_size/1024:.1f} KB',\n",
    "                        'السرعة': f'{speed:.1f} KB/s',\n",
    "                        'الوقت المتبقي': f'{hours:02d}:{minutes:02d}:{seconds:02d}'\n",
    "                    })\n",
    "                \n",
    "                pbar.update(1)\n",
    "                current_date += timedelta(days=1)\n",
    "        \n",
    "        print(f\"\\n✅ تم تحميل {len(downloaded_data)} سجل بنجاح!\")\n",
    "        return downloaded_data\n",
    "\n",
    "    def generate_sample_candlestick_data(self, date, timeframe):\n",
    "        \"\"\"إنشاء بيانات شموع وهمية للمثال\"\"\"\n",
    "        import random\n",
    "        \n",
    "        # تحديد عدد الشموع حسب التايم فريم\n",
    "        candles_per_day = {\n",
    "            'm1': 1440, 'm5': 288, 'm15': 96, 'm30': 48,\n",
    "            'h1': 24, 'h4': 6, 'd1': 1, 'w1': 1, 'mn1': 1\n",
    "        }\n",
    "        \n",
    "        num_candles = candles_per_day.get(timeframe, 24)\n",
    "        data = []\n",
    "        \n",
    "        base_price = random.uniform(1.0, 2.0)\n",
    "        \n",
    "        for i in range(num_candles):\n",
    "            timestamp = date + timedelta(minutes=i * (1440 // num_candles))\n",
    "            open_price = base_price + random.uniform(-0.01, 0.01)\n",
    "            close_price = open_price + random.uniform(-0.005, 0.005)\n",
    "            high_price = max(open_price, close_price) + random.uniform(0, 0.003)\n",
    "            low_price = min(open_price, close_price) - random.uniform(0, 0.003)\n",
    "            volume = random.randint(100, 10000)\n",
    "            \n",
    "            data.append({\n",
    "                'GMT Time': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'Open': round(open_price, 5),\n",
    "                'High': round(high_price, 5),\n",
    "                'Low': round(low_price, 5),\n",
    "                'Close': round(close_price, 5),\n",
    "                'Volume': volume\n",
    "            })\n",
    "            \n",
    "            base_price = close_price\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def generate_sample_tick_data(self, date, tick_size):\n",
    "        \"\"\"إنشاء بيانات تيك وهمية للمثال\"\"\"\n",
    "        import random\n",
    "        \n",
    "        data = []\n",
    "        base_price = random.uniform(1.0, 2.0)\n",
    "        \n",
    "        for i in range(min(tick_size, 1000)):  # حد أقصى 1000 تيك للمثال\n",
    "            timestamp = date + timedelta(seconds=i * 60)\n",
    "            bid = base_price + random.uniform(-0.001, 0.001)\n",
    "            ask = bid + random.uniform(0.0001, 0.0005)\n",
    "            \n",
    "            data.append({\n",
    "                'GMT Time': timestamp.strftime('%Y-%m-%d %H:%M:%S.%f'),\n",
    "                'Bid': round(bid, 5),\n",
    "                'Ask': round(ask, 5),\n",
    "                'Volume': random.randint(1, 100)\n",
    "            })\n",
    "            \n",
    "            base_price = bid\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def merge_and_save_data(self, data, symbol, data_type, timeframe=None):\n",
    "        \"\"\"دمج البيانات وحفظها في ملف CSV\"\"\"\n",
    "        print(f\"\\n🔄 دمج البيانات حسب عمود الوقت GMT...\")\n",
    "        \n",
    "        # تحويل البيانات إلى DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # ترتيب البيانات حسب الوقت\n",
    "        df = df.sort_values('GMT Time')\n",
    "        \n",
    "        # إنشاء مجلد للحفظ\n",
    "        save_dir = Path(\"Dukascopy_Data\")\n",
    "        save_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # تحديد اسم الملف\n",
    "        current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if data_type == 'candlesticks':\n",
    "            filename = f\"{symbol}_{timeframe}_{current_time}.csv\"\n",
    "        else:\n",
    "            filename = f\"{symbol}_ticks_{current_time}.csv\"\n",
    "        \n",
    "        file_path = save_dir / filename\n",
    "        \n",
    "        # حفظ الملف\n",
    "        df.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"💾 تم حفظ الملف بنجاح!\")\n",
    "        print(f\"📁 مسار الحفظ: {file_path.absolute()}\")\n",
    "        print(f\"📊 عدد السجلات: {len(df):,}\")\n",
    "        print(f\"💾 حجم الملف: {file_path.stat().st_size / 1024:.2f} KB\")\n",
    "        \n",
    "        return file_path\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"تشغيل الأداة الرئيسية\"\"\"\n",
    "        try:\n",
    "            print(\"🔥 مرحباً بك في أداة تحميل البيانات من Dukascopy!\")\n",
    "            print(\"⚡ بناء احترافي مع جميع الميزات المطلوبة\")\n",
    "            \n",
    "            # اختيار الفئة\n",
    "            category = self.display_categories()\n",
    "            \n",
    "            # اختيار الأداة المالية\n",
    "            symbol = self.display_instruments(category)\n",
    "            \n",
    "            # اختيار نوع البيانات\n",
    "            data_type = self.choose_data_type()\n",
    "            \n",
    "            timeframe = None\n",
    "            tick_size = None\n",
    "            \n",
    "            if data_type == 'candlesticks':\n",
    "                timeframe = self.choose_timeframe()\n",
    "            else:\n",
    "                tick_size = self.choose_tick_size()\n",
    "            \n",
    "            # اختيار التواريخ\n",
    "            start_date = self.get_date_input(\"تاريخ البداية\")\n",
    "            end_date = self.get_date_input(\"تاريخ النهاية\")\n",
    "            \n",
    "            if start_date >= end_date:\n",
    "                print(\"❌ تاريخ البداية يجب أن يكون قبل تاريخ النهاية!\")\n",
    "                return\n",
    "            \n",
    "            # تحميل البيانات\n",
    "            data = self.download_data(symbol, data_type, timeframe, tick_size, start_date, end_date)\n",
    "            \n",
    "            # دمج وحفظ البيانات\n",
    "            file_path = self.merge_and_save_data(data, symbol, data_type, timeframe)\n",
    "            \n",
    "            print(f\"\\n🎉 تمت العملية بنجاح!\")\n",
    "            print(f\"🚀 الملف جاهز للاستخدام: {file_path.name}\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n\\n⏹️  تم إيقاف العملية من قبل المستخدم.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ حدث خطأ: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"الدالة الرئيسية\"\"\"\n",
    "    downloader = DukascopyDownloader()\n",
    "    downloader.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103caca-66bb-424e-ab68-ceaded276fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb23c2-2c3e-4450-8cec-16186222d0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
