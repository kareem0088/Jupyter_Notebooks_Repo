{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd0c0f1-3452-4c43-b4eb-0c69fb2bde22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\n",
      "Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame...\n",
      "ØªÙ… Ø¬Ù„Ø¨ 94 Ø®Ø¨Ø±\n",
      "\n",
      "Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:\n",
      "['title', 'country', 'date', 'impact', 'forecast', 'previous']\n",
      "\n",
      "Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 Ø£Ø®Ø¨Ø§Ø±:\n",
      "                                  title country                      date  \\\n",
      "0                          Bank Holiday     JPY 2025-08-10 19:00:00-04:00   \n",
      "1                 Italian Trade Balance     EUR 2025-08-11 05:00:00-04:00   \n",
      "2  Cleveland Fed Inflation Expectations     USD 2025-08-11 09:35:00-04:00   \n",
      "3                President Trump Speaks     USD 2025-08-11 10:00:00-04:00   \n",
      "4          BRC Retail Sales Monitor y/y     GBP 2025-08-11 19:01:00-04:00   \n",
      "\n",
      "    impact forecast previous  \n",
      "0  Holiday                    \n",
      "1      Low    7.12B    6.16B  \n",
      "2      Low              3.9%  \n",
      "3   Medium                    \n",
      "4      Low     2.1%     2.7%  \n",
      "\n",
      "Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n",
      "title                          object\n",
      "country                        object\n",
      "date        datetime64[ns, UTC-04:00]\n",
      "impact                         object\n",
      "forecast                       object\n",
      "previous                       object\n",
      "dtype: object\n",
      "\n",
      "Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©:\n",
      "title: 82 Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\n",
      "country: 9 Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\n",
      "  Ø§Ù„Ù‚ÙŠÙ…: ['JPY', 'EUR', 'USD', 'GBP', 'AUD', 'CAD', 'CNY', 'CHF', 'NZD']\n",
      "impact: 4 Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\n",
      "  Ø§Ù„Ù‚ÙŠÙ…: ['Holiday', 'Low', 'Medium', 'High']\n",
      "forecast: 40 Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\n",
      "previous: 56 Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\n",
      "\n",
      "==================================================\n",
      "Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙÙ„ØªØ±Ø©:\n",
      "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù€ USD: 34\n",
      "Ø¹Ø¯Ø¯ Ø£Ø®Ø¨Ø§Ø± GDP: 5\n",
      "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: 19\n",
      "\n",
      "Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¯ÙˆÙ„Ø§Ø± Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© (19 Ø®Ø¨Ø±):\n",
      "------------------------------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-12 00:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Cash Rate\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-12 00:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: RBA Monetary Policy Statement\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-12 00:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: RBA Rate Statement\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-12 01:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: RBA Press Conference\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-12 08:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Core CPI m/m\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-12 08:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: CPI m/m\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-12 08:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: CPI y/y\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-12 21:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Wage Price Index q/q\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-13 21:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Employment Change\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-13 21:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Unemployment Rate\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-14 02:00:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: GDP m/m\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-14 08:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Core PPI m/m\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-14 08:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: PPI m/m\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-14 08:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Unemployment Claims\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-15 08:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Core Retail Sales m/m\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-15 08:30:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Retail Sales m/m\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-15 10:00:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Prelim UoM Consumer Sentiment\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-15 10:00:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Prelim UoM Inflation Expectations\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n",
      "Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-08-15 18:55:00-04:00\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: President Trump Speaks\n",
      "Ø§Ù„Ø¹Ù…Ù„Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯\n",
      "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: High\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def fetch_economic_calendar():\n",
    "    \"\"\"\n",
    "    ÙŠÙ‚ÙˆÙ… Ø¨Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† API Ø§Ù„ØªÙ‚ÙˆÙŠÙ… Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ\n",
    "    \"\"\"\n",
    "    url = \"https://nfs.faireconomy.media/ff_calendar_thisweek.json\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # ÙŠØ±Ù…ÙŠ Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø·Ù„Ø¨ ÙØ§Ø´Ù„Ø§Ù‹\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_dataframe(data):\n",
    "    \"\"\"\n",
    "    ÙŠØ­ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ datetime Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_news(df, filters=None):\n",
    "    \"\"\"\n",
    "    ÙŠÙ‚ÙˆÙ… Ø¨ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "    filters: dict ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ÙÙ„ØªØ±Ø©\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    if not filters:\n",
    "        return filtered_df\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…Ù„Ø© (Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø£ÙˆÙ„Ø§Ù‹)\n",
    "    if 'currency' in filters and filters['currency'] and 'currency' in filtered_df.columns:\n",
    "        filtered_df = filtered_df[filtered_df['currency'].str.contains(filters['currency'], case=False, na=False)]\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\n",
    "    if 'impact' in filters and filters['impact'] and 'impact' in filtered_df.columns:\n",
    "        filtered_df = filtered_df[filtered_df['impact'] == filters['impact']]\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªÙˆÙØ±Ø§Ù‹)\n",
    "    if 'date_from' in filters and filters['date_from'] and 'date' in filtered_df.columns:\n",
    "        filtered_df = filtered_df[filtered_df['date'] >= filters['date_from']]\n",
    "    \n",
    "    if 'date_to' in filters and filters['date_to'] and 'date' in filtered_df.columns:\n",
    "        filtered_df = filtered_df[filtered_df['date'] <= filters['date_to']]\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø£Ùˆ Ø§Ù„ÙˆØµÙ\n",
    "    if 'keyword' in filters and filters['keyword']:\n",
    "        keyword_filter = pd.Series([False] * len(filtered_df))\n",
    "        \n",
    "        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ title Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹\n",
    "        if 'title' in filtered_df.columns:\n",
    "            keyword_filter |= filtered_df['title'].str.contains(filters['keyword'], case=False, na=False)\n",
    "        \n",
    "        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ description Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹\n",
    "        if 'description' in filtered_df.columns:\n",
    "            keyword_filter |= filtered_df['description'].str.contains(filters['keyword'], case=False, na=False)\n",
    "        \n",
    "        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø£ÙŠ Ø¹Ù…ÙˆØ¯ Ù†ØµÙŠ Ø¢Ø®Ø±\n",
    "        for col in filtered_df.columns:\n",
    "            if filtered_df[col].dtype == 'object':\n",
    "                keyword_filter |= filtered_df[col].astype(str).str.contains(filters['keyword'], case=False, na=False)\n",
    "        \n",
    "        filtered_df = filtered_df[keyword_filter]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n",
    "    \"\"\"\n",
    "    print(\"Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\")\n",
    "    data = fetch_economic_calendar()\n",
    "    \n",
    "    if data is None:\n",
    "        print(\"ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\")\n",
    "        return\n",
    "    \n",
    "    print(\"Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame...\")\n",
    "    df = create_dataframe(data)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø©\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ØªÙ… Ø¬Ù„Ø¨ {len(df)} Ø®Ø¨Ø±\")\n",
    "    print(\"\\nØ£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    print(\"\\nØ¹Ø±Ø¶ Ø£ÙˆÙ„ 5 Ø£Ø®Ø¨Ø§Ø±:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Ù…Ø¹Ø§ÙŠÙ†Ø© Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "    print(\"\\nØ£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©\n",
    "    print(\"\\nØ¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©:\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            unique_count = df[col].nunique()\n",
    "            print(f\"{col}: {unique_count} Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\")\n",
    "            if unique_count <= 10:  # Ø¹Ø±Ø¶ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚Ù„ÙŠÙ„Ø©\n",
    "                print(f\"  Ø§Ù„Ù‚ÙŠÙ…: {df[col].unique()[:10].tolist()}\")\n",
    "    \n",
    "    # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„ÙÙ„ØªØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙÙ„ØªØ±Ø©:\")\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø¨ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© ÙÙ‚Ø· (Ù„Ø£Ù†Ù‡Ø§ Ø³ØªØ¹Ù…Ù„ Ù…Ø¹ Ø£ÙŠ Ù†ÙˆØ¹ Ø¨ÙŠØ§Ù†Ø§Øª)\n",
    "    keyword_filters = {'keyword': 'USD'}\n",
    "    usd_related_news = filter_news(df, keyword_filters)\n",
    "    print(f\"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù€ USD: {len(usd_related_news)}\")\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø£Ø®Ø±Ù‰ Ø¨ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ©\n",
    "    gdp_filters = {'keyword': 'GDP'}\n",
    "    gdp_news = filter_news(df, gdp_filters)\n",
    "    print(f\"Ø¹Ø¯Ø¯ Ø£Ø®Ø¨Ø§Ø± GDP: {len(gdp_news)}\")\n",
    "    \n",
    "    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¹Ù…ÙˆØ¯ impact\n",
    "    if 'impact' in df.columns:\n",
    "        high_impact_filters = {'impact': 'High'}\n",
    "        high_impact_news = filter_news(df, high_impact_filters)\n",
    "        print(f\"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: {len(high_impact_news)}\")\n",
    "    \n",
    "    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¹Ù…ÙˆØ¯ currency\n",
    "    if 'currency' in df.columns:\n",
    "        usd_filters = {'currency': 'USD'}\n",
    "        usd_news = filter_news(df, usd_filters)\n",
    "        print(f\"Ø¹Ø¯Ø¯ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¯ÙˆÙ„Ø§Ø± Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ: {len(usd_news)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ÙÙ„ØªØ±Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ù†Ø¸Ù…Ø©\n",
    "def display_filtered_news(df, title=\"Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\"):\n",
    "    \"\"\"\n",
    "    ÙŠØ¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ÙÙ„ØªØ±Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ù†Ø¸Ù…Ø©\n",
    "    \"\"\"\n",
    "    print(f\"\\n{title} ({len(df)} Ø®Ø¨Ø±):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        print(f\"Ø§Ù„ØªØ§Ø±ÙŠØ®: {row.get('date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "        print(f\"Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {row.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "        print(f\"Ø§Ù„Ø¹Ù…Ù„Ø©: {row.get('currency', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "        print(f\"Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: {row.get('impact', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ\n",
    "    df = main()\n",
    "    \n",
    "    # ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØµØµØ© Ù‡Ù†Ø§\n",
    "    if df is not None and not df.empty:\n",
    "        # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ ÙÙ„ØªØ±Ø© Ù…Ø®ØµØµØ©\n",
    "        custom_filters = {\n",
    "            'currency': 'USD',\n",
    "            'impact': 'High',\n",
    "            # 'keyword': 'inflation',\n",
    "            # 'date_from': datetime.now().date(),\n",
    "            # 'date_to': datetime.now().date() + timedelta(days=7)\n",
    "        }\n",
    "        \n",
    "        filtered_news = filter_news(df, custom_filters)\n",
    "        display_filtered_news(filtered_news, \"Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¯ÙˆÙ„Ø§Ø± Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb763f0c-e73c-4d3b-853e-9b09698e9962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\n",
      "ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame...\n",
      "âœ… ØªÙ… Ø¬Ù„Ø¨ 94 Ø®Ø¨Ø±\n",
      "\n",
      "ğŸ“Š Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:\n",
      "['title', 'country', 'date', 'impact', 'forecast', 'previous']\n",
      "\n",
      "ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©:\n",
      "â€¢ title: 82 Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\n",
      "â€¢ country: 9 Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\n",
      "â€¢ impact: 4 Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\n",
      "â€¢ forecast: 40 Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\n",
      "â€¢ previous: 56 Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\n",
      "\n",
      "==================================================\n",
      "ğŸ”§ Ø£Ø¯ÙˆØ§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©\n",
      "1. Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\n",
      "2. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø®Ø¨Ø± Ù…Ø¹ÙŠÙ†\n",
      "3. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø®Ø¨Ø± Ù…Ø¹ÙŠÙ†\n",
      "4. ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­Ø³Ø¨ Ù…Ø¹Ø§ÙŠÙŠØ± Ù…Ø­Ø¯Ø¯Ø©\n",
      "5. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­ÙˆÙ„ ÙˆÙ‚Øª Ù…Ø¹ÙŠÙ†\n",
      "6. Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\n",
      "0. Ø®Ø±ÙˆØ¬\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© (19 Ø®Ø¨Ø±):\n",
      "â€¢ 2025-08-12 00:30:00-04:00 - Cash Rate - AUD\n",
      "â€¢ 2025-08-12 00:30:00-04:00 - RBA Monetary Policy Statement - AUD\n",
      "â€¢ 2025-08-12 00:30:00-04:00 - RBA Rate Statement - AUD\n",
      "â€¢ 2025-08-12 01:30:00-04:00 - RBA Press Conference - AUD\n",
      "â€¢ 2025-08-12 08:30:00-04:00 - Core CPI m/m - USD\n",
      "â€¢ 2025-08-12 08:30:00-04:00 - CPI m/m - USD\n",
      "â€¢ 2025-08-12 08:30:00-04:00 - CPI y/y - USD\n",
      "â€¢ 2025-08-12 21:30:00-04:00 - Wage Price Index q/q - AUD\n",
      "â€¢ 2025-08-13 21:30:00-04:00 - Employment Change - AUD\n",
      "â€¢ 2025-08-13 21:30:00-04:00 - Unemployment Rate - AUD\n",
      "â€¢ 2025-08-14 02:00:00-04:00 - GDP m/m - GBP\n",
      "â€¢ 2025-08-14 08:30:00-04:00 - Unemployment Claims - USD\n",
      "â€¢ 2025-08-14 08:30:00-04:00 - PPI m/m - USD\n",
      "â€¢ 2025-08-14 08:30:00-04:00 - Core PPI m/m - USD\n",
      "â€¢ 2025-08-15 08:30:00-04:00 - Retail Sales m/m - USD\n",
      "â€¢ 2025-08-15 08:30:00-04:00 - Core Retail Sales m/m - USD\n",
      "â€¢ 2025-08-15 10:00:00-04:00 - Prelim UoM Inflation Expectations - USD\n",
      "â€¢ 2025-08-15 10:00:00-04:00 - Prelim UoM Consumer Sentiment - USD\n",
      "â€¢ 2025-08-15 18:55:00-04:00 - President Trump Speaks - USD\n",
      "\n",
      "==================================================\n",
      "ğŸ”§ Ø£Ø¯ÙˆØ§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©\n",
      "1. Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\n",
      "2. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø®Ø¨Ø± Ù…Ø¹ÙŠÙ†\n",
      "3. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø®Ø¨Ø± Ù…Ø¹ÙŠÙ†\n",
      "4. ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­Ø³Ø¨ Ù…Ø¹Ø§ÙŠÙŠØ± Ù…Ø­Ø¯Ø¯Ø©\n",
      "5. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­ÙˆÙ„ ÙˆÙ‚Øª Ù…Ø¹ÙŠÙ†\n",
      "6. Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\n",
      "0. Ø®Ø±ÙˆØ¬\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:  3\n",
      "Ø£Ø¯Ø®Ù„ Ø¬Ø²Ø¡ Ù…Ù† Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ:  08:30:00-04:00\n",
      "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 3):  2\n",
      "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 3):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø®Ø¨Ø± ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰: '08:30:00-04:00'\n",
      "\n",
      "================================================================================\n",
      "Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø­ÙŠØ·Ø© Ø¨Ù€: 08:30:00-04:00\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”§ Ø£Ø¯ÙˆØ§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©\n",
      "1. Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\n",
      "2. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø®Ø¨Ø± Ù…Ø¹ÙŠÙ†\n",
      "3. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø®Ø¨Ø± Ù…Ø¹ÙŠÙ†\n",
      "4. ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­Ø³Ø¨ Ù…Ø¹Ø§ÙŠÙŠØ± Ù…Ø­Ø¯Ø¯Ø©\n",
      "5. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­ÙˆÙ„ ÙˆÙ‚Øª Ù…Ø¹ÙŠÙ†\n",
      "6. Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\n",
      "0. Ø®Ø±ÙˆØ¬\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 351\u001b[39m\n\u001b[32m    345\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâŒ Ø§Ø®ØªÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;66;03m# ÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨Ø·Ø±ÙŠÙ‚ØªÙŠÙ†:\u001b[39;00m\n\u001b[32m    349\u001b[39m \n\u001b[32m    350\u001b[39m     \u001b[38;5;66;03m# 1. ØªØ´ØºÙŠÙ„ ØªÙØ§Ø¹Ù„ÙŠ\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[43minteractive_news_analyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m     \u001b[38;5;66;03m# Ø£Ùˆ 2. Ù…Ø«Ø§Ù„ Ù…Ø¨Ø§Ø´Ø±\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;66;03m# df = main()\u001b[39;00m\n\u001b[32m    355\u001b[39m     \u001b[38;5;66;03m# if df is not None:\u001b[39;00m\n\u001b[32m    356\u001b[39m     \u001b[38;5;66;03m#     # Ù…Ø«Ø§Ù„: Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø®Ø¨Ø± CPI\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;66;03m#     result = get_news_around_event(df, \"CPI\", before_count=2, after_count=2)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;66;03m#     display_news_around_event(result, \"CPI\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 267\u001b[39m, in \u001b[36minteractive_news_analyzer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m0. Ø®Ø±ÙˆØ¬\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    265\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m choice = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mØ§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ©: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.strip()\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m choice == \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mØ´ÙƒØ±Ø§Ù‹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ùƒ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬! ğŸ‘‹\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1280\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1323\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1324\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1327\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def fetch_economic_calendar():\n",
    "    \"\"\"\n",
    "    ÙŠÙ‚ÙˆÙ… Ø¨Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† API Ø§Ù„ØªÙ‚ÙˆÙŠÙ… Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ\n",
    "    \"\"\"\n",
    "    url = \"https://nfs.faireconomy.media/ff_calendar_thisweek.json\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_dataframe(data):\n",
    "    \"\"\"\n",
    "    ÙŠØ­ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ datetime Ù…Ø¹ Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø²Ù…Ù†ÙŠ\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_news(df, filters=None):\n",
    "    \"\"\"\n",
    "    ÙŠÙ‚ÙˆÙ… Ø¨ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    if not filters:\n",
    "        return filtered_df\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…Ù„Ø©/Ø§Ù„Ø¨Ù„Ø¯\n",
    "    if 'country' in filters and filters['country'] and 'country' in filtered_df.columns:\n",
    "        filtered_df = filtered_df[filtered_df['country'].str.contains(filters['country'], case=False, na=False)]\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\n",
    "    if 'impact' in filters and filters['impact'] and 'impact' in filtered_df.columns:\n",
    "        filtered_df = filtered_df[filtered_df['impact'] == filters['impact']]\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ®\n",
    "    if 'date_from' in filters and filters['date_from'] and 'date' in filtered_df.columns:\n",
    "        filtered_df = filtered_df[filtered_df['date'] >= filters['date_from']]\n",
    "    \n",
    "    if 'date_to' in filters and filters['date_to'] and 'date' in filtered_df.columns:\n",
    "        filtered_df = filtered_df[filtered_df['date'] <= filters['date_to']]\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†\n",
    "    if 'keyword' in filters and filters['keyword']:\n",
    "        keyword_filter = pd.Series([False] * len(filtered_df))\n",
    "        \n",
    "        if 'title' in filtered_df.columns:\n",
    "            keyword_filter |= filtered_df['title'].str.contains(filters['keyword'], case=False, na=False)\n",
    "        \n",
    "        for col in filtered_df.columns:\n",
    "            if filtered_df[col].dtype == 'object':\n",
    "                keyword_filter |= filtered_df[col].astype(str).str.contains(filters['keyword'], case=False, na=False)\n",
    "        \n",
    "        filtered_df = filtered_df[keyword_filter]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def get_news_around_event(df, reference_news_title, before_count=3, after_count=3):\n",
    "    \"\"\"\n",
    "    ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø®Ø¨Ø± Ù…Ø¹ÙŠÙ†\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "    reference_news_title: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    before_count: Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    after_count: Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    \n",
    "    Returns:\n",
    "    dict: ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    \"\"\"\n",
    "    if df.empty or 'title' not in df.columns:\n",
    "        return {'before': pd.DataFrame(), 'reference': pd.DataFrame(), 'after': pd.DataFrame()}\n",
    "    \n",
    "    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    reference_mask = df['title'].str.contains(reference_news_title, case=False, na=False)\n",
    "    reference_indices = df[reference_mask].index.tolist()\n",
    "    \n",
    "    if not reference_indices:\n",
    "        print(f\"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø®Ø¨Ø± ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰: '{reference_news_title}'\")\n",
    "        return {'before': pd.DataFrame(), 'reference': pd.DataFrame(), 'after': pd.DataFrame()}\n",
    "    \n",
    "    # Ø£Ø®Ø° Ø£ÙˆÙ„ Ø®Ø¨Ø± Ù…Ø·Ø§Ø¨Ù‚\n",
    "    reference_index = reference_indices[0]\n",
    "    \n",
    "    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    before_start = max(0, reference_index - before_count)\n",
    "    before_df = df.iloc[before_start:reference_index]\n",
    "    \n",
    "    # Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    reference_df = df.iloc[reference_index:reference_index+1]\n",
    "    \n",
    "    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    after_end = min(len(df), reference_index + 1 + after_count)\n",
    "    after_df = df.iloc[reference_index+1:after_end]\n",
    "    \n",
    "    return {\n",
    "        'before': before_df,\n",
    "        'reference': reference_df,\n",
    "        'after': after_df\n",
    "    }\n",
    "\n",
    "def get_news_around_time(df, reference_time, hours_before=2, hours_after=2):\n",
    "    \"\"\"\n",
    "    ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ ÙˆÙ‚Øª Ù…Ø¹ÙŠÙ†\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "    reference_time: Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (datetime object Ø£Ùˆ string)\n",
    "    hours_before: Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    hours_after: Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    \"\"\"\n",
    "    if df.empty or 'date' not in df.columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ Ø¥Ù„Ù‰ datetime Ø¥Ø°Ø§ ÙƒØ§Ù† string\n",
    "    if isinstance(reference_time, str):\n",
    "        reference_time = pd.to_datetime(reference_time)\n",
    "    \n",
    "    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ\n",
    "    time_before = reference_time - timedelta(hours=hours_before)\n",
    "    time_after = reference_time + timedelta(hours=hours_after)\n",
    "    \n",
    "    # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ\n",
    "    filtered_df = df[(df['date'] >= time_before) & (df['date'] <= time_after)]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def display_news_around_event(result_dict, reference_title):\n",
    "    \"\"\"\n",
    "    ÙŠØ¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø­Ø¯Ø« Ù…Ø¹ÙŠÙ† Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ù†Ø¸Ù…Ø©\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø­ÙŠØ·Ø© Ø¨Ù€: {reference_title}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø¯Ø«\n",
    "    if not result_dict['before'].empty:\n",
    "        print(f\"\\nğŸ“… Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø¯Ø« ({len(result_dict['before'])} Ø®Ø¨Ø±):\")\n",
    "        print(\"-\" * 60)\n",
    "        for i, row in result_dict['before'].iterrows():\n",
    "            print(f\"â° {row.get('date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "            print(f\"ğŸ“° {row.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "            print(f\"ğŸŒ {row.get('country', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} | ğŸ¯ {row.get('impact', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "            if pd.notna(row.get('forecast')) or pd.notna(row.get('previous')):\n",
    "                print(f\"ğŸ“Š Ø§Ù„ØªÙˆÙ‚Ø¹: {row.get('forecast', 'N/A')} | Ø§Ù„Ø³Ø§Ø¨Ù‚: {row.get('previous', 'N/A')}\")\n",
    "            print(\"-\" * 40)\n",
    "    \n",
    "    # Ø¹Ø±Ø¶ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "    if not result_dict['reference'].empty:\n",
    "        print(f\"\\nğŸ¯ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ:\")\n",
    "        print(\"=\" * 60)\n",
    "        row = result_dict['reference'].iloc[0]\n",
    "        print(f\"â° {row.get('date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "        print(f\"ğŸ“° {row.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "        print(f\"ğŸŒ {row.get('country', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} | ğŸ¯ {row.get('impact', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "        if pd.notna(row.get('forecast')) or pd.notna(row.get('previous')):\n",
    "            print(f\"ğŸ“Š Ø§Ù„ØªÙˆÙ‚Ø¹: {row.get('forecast', 'N/A')} | Ø§Ù„Ø³Ø§Ø¨Ù‚: {row.get('previous', 'N/A')}\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø¯Ø«\n",
    "    if not result_dict['after'].empty:\n",
    "        print(f\"\\nğŸ“… Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø¯Ø« ({len(result_dict['after'])} Ø®Ø¨Ø±):\")\n",
    "        print(\"-\" * 60)\n",
    "        for i, row in result_dict['after'].iterrows():\n",
    "            print(f\"â° {row.get('date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "            print(f\"ğŸ“° {row.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "            print(f\"ğŸŒ {row.get('country', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} | ğŸ¯ {row.get('impact', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "            if pd.notna(row.get('forecast')) or pd.notna(row.get('previous')):\n",
    "                print(f\"ğŸ“Š Ø§Ù„ØªÙˆÙ‚Ø¹: {row.get('forecast', 'N/A')} | Ø§Ù„Ø³Ø§Ø¨Ù‚: {row.get('previous', 'N/A')}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "def search_news_titles(df, search_term):\n",
    "    \"\"\"\n",
    "    ÙŠØ¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…ØµØ·Ù„Ø­ Ù…Ø¹ÙŠÙ† ÙÙŠ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†\n",
    "    \"\"\"\n",
    "    if df.empty or 'title' not in df.columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    mask = df['title'].str.contains(search_term, case=False, na=False)\n",
    "    results = df[mask]\n",
    "    \n",
    "    if not results.empty:\n",
    "        print(f\"\\nğŸ” Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† '{search_term}' ({len(results)} Ù†ØªÙŠØ¬Ø©):\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, row in results.iterrows():\n",
    "            print(f\"{i}: {row.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} - {row.get('date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "        print(\"-\" * 50)\n",
    "    else:\n",
    "        print(f\"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø£Ø®Ø¨Ø§Ø± ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ '{search_term}'\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\")\n",
    "    data = fetch_economic_calendar()\n",
    "    \n",
    "    if data is None:\n",
    "        print(\"âŒ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\")\n",
    "        return None\n",
    "    \n",
    "    print(\"ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame...\")\n",
    "    df = create_dataframe(data)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø©\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(df)} Ø®Ø¨Ø±\")\n",
    "    print(\"\\nğŸ“Š Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©:\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            unique_count = df[col].nunique()\n",
    "            print(f\"â€¢ {col}: {unique_count} Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def interactive_news_analyzer():\n",
    "    \"\"\"\n",
    "    ÙˆØ§Ø¬Ù‡Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\n",
    "    \"\"\"\n",
    "    df = main()\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"ğŸ”§ Ø£Ø¯ÙˆØ§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©\")\n",
    "        print(\"1. Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\")\n",
    "        print(\"2. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø®Ø¨Ø± Ù…Ø¹ÙŠÙ†\")\n",
    "        print(\"3. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø®Ø¨Ø± Ù…Ø¹ÙŠÙ†\")\n",
    "        print(\"4. ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­Ø³Ø¨ Ù…Ø¹Ø§ÙŠÙŠØ± Ù…Ø­Ø¯Ø¯Ø©\")\n",
    "        print(\"5. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­ÙˆÙ„ ÙˆÙ‚Øª Ù…Ø¹ÙŠÙ†\")\n",
    "        print(\"6. Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\")\n",
    "        print(\"0. Ø®Ø±ÙˆØ¬\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        choice = input(\"Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ©: \").strip()\n",
    "        \n",
    "        if choice == \"0\":\n",
    "            print(\"Ø´ÙƒØ±Ø§Ù‹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ùƒ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬! ğŸ‘‹\")\n",
    "            break\n",
    "        \n",
    "        elif choice == \"1\":\n",
    "            print(f\"\\nğŸ“‹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ({len(df)} Ø®Ø¨Ø±):\")\n",
    "            for i, row in df.head(10).iterrows():\n",
    "                print(f\"{i+1}. {row.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} - {row.get('date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "            if len(df) > 10:\n",
    "                print(f\"... Ùˆ {len(df) - 10} Ø®Ø¨Ø± Ø¢Ø®Ø±\")\n",
    "        \n",
    "        elif choice == \"2\":\n",
    "            search_term = input(\"Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø© Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: \").strip()\n",
    "            if search_term:\n",
    "                search_news_titles(df, search_term)\n",
    "        \n",
    "        elif choice == \"3\":\n",
    "            reference_title = input(\"Ø£Ø¯Ø®Ù„ Ø¬Ø²Ø¡ Ù…Ù† Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ: \").strip()\n",
    "            if reference_title:\n",
    "                try:\n",
    "                    before_count = int(input(\"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 3): \").strip() or \"3\")\n",
    "                    after_count = int(input(\"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 3): \").strip() or \"3\")\n",
    "                    \n",
    "                    result = get_news_around_event(df, reference_title, before_count, after_count)\n",
    "                    display_news_around_event(result, reference_title)\n",
    "                except ValueError:\n",
    "                    print(\"âŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø£Ø±Ù‚Ø§Ù… ØµØ­ÙŠØ­Ø©\")\n",
    "        \n",
    "        elif choice == \"4\":\n",
    "            print(\"\\nğŸ” Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙÙ„ØªØ±Ø©:\")\n",
    "            country = input(\"Ø§Ù„Ø¹Ù…Ù„Ø©/Ø§Ù„Ø¨Ù„Ø¯ (Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±Øº Ù„Ù„ØªØ¬Ø§Ù‡Ù„): \").strip() or None\n",
    "            impact = input(\"Ø§Ù„Ø£Ù‡Ù…ÙŠØ© (High/Medium/Low - Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±Øº Ù„Ù„ØªØ¬Ø§Ù‡Ù„): \").strip() or None\n",
    "            keyword = input(\"ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© (Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±Øº Ù„Ù„ØªØ¬Ø§Ù‡Ù„): \").strip() or None\n",
    "            \n",
    "            filters = {}\n",
    "            if country: filters['country'] = country\n",
    "            if impact: filters['impact'] = impact\n",
    "            if keyword: filters['keyword'] = keyword\n",
    "            \n",
    "            filtered_df = filter_news(df, filters)\n",
    "            print(f\"\\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙÙ„ØªØ±Ø©: {len(filtered_df)} Ø®Ø¨Ø±\")\n",
    "            \n",
    "            if not filtered_df.empty:\n",
    "                for i, row in filtered_df.head(10).iterrows():\n",
    "                    print(f\"â€¢ {row.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} - {row.get('country', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} - {row.get('impact', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "                if len(filtered_df) > 10:\n",
    "                    print(f\"... Ùˆ {len(filtered_df) - 10} Ø®Ø¨Ø± Ø¢Ø®Ø±\")\n",
    "        \n",
    "        elif choice == \"5\":\n",
    "            reference_time_str = input(\"Ø£Ø¯Ø®Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª (YYYY-MM-DD HH:MM Ø£Ùˆ Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±Øº Ù„Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ): \").strip()\n",
    "            try:\n",
    "                if reference_time_str:\n",
    "                    reference_time = pd.to_datetime(reference_time_str)\n",
    "                else:\n",
    "                    reference_time = pd.Timestamp.now()\n",
    "                \n",
    "                hours_before = int(input(\"Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 2): \").strip() or \"2\")\n",
    "                hours_after = int(input(\"Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 2): \").strip() or \"2\")\n",
    "                \n",
    "                result = get_news_around_time(df, reference_time, hours_before, hours_after)\n",
    "                print(f\"\\nğŸ“… Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­ÙˆÙ„ Ø§Ù„ÙˆÙ‚Øª {reference_time} ({len(result)} Ø®Ø¨Ø±):\")\n",
    "                \n",
    "                for i, row in result.iterrows():\n",
    "                    print(f\"â€¢ {row.get('date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} - {row.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "            \n",
    "            except (ValueError, pd.errors.ParserError):\n",
    "                print(\"âŒ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ø±ÙŠØ® ØºÙŠØ± ØµØ­ÙŠØ­\")\n",
    "        \n",
    "        elif choice == \"6\":\n",
    "            high_impact_news = filter_news(df, {'impact': 'High'})\n",
    "            print(f\"\\nğŸ¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© ({len(high_impact_news)} Ø®Ø¨Ø±):\")\n",
    "            \n",
    "            for i, row in high_impact_news.iterrows():\n",
    "                print(f\"â€¢ {row.get('date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} - {row.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')} - {row.get('country', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\")\n",
    "        \n",
    "        else:\n",
    "            print(\"âŒ Ø§Ø®ØªÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨Ø·Ø±ÙŠÙ‚ØªÙŠÙ†:\n",
    "    \n",
    "    # 1. ØªØ´ØºÙŠÙ„ ØªÙØ§Ø¹Ù„ÙŠ\n",
    "    interactive_news_analyzer()\n",
    "    \n",
    "    # Ø£Ùˆ 2. Ù…Ø«Ø§Ù„ Ù…Ø¨Ø§Ø´Ø±\n",
    "    # df = main()\n",
    "    # if df is not None:\n",
    "    #     # Ù…Ø«Ø§Ù„: Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø®Ø¨Ø± CPI\n",
    "    #     result = get_news_around_event(df, \"CPI\", before_count=2, after_count=2)\n",
    "    #     display_news_around_event(result, \"CPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312e02cb-3a9d-4054-b554-9ae15cc87b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­\n",
      "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: 92\n",
      "Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: 22\n",
      "âœ… Ø§Ù„ÙˆÙ‚Øª Ø¢Ù…Ù† Ù„Ù„ØªØ¯Ø§ÙˆÙ„\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class NewsFilter:\n",
    "    def __init__(self):\n",
    "        self.df = pd.DataFrame()\n",
    "        self.last_update = None\n",
    "    \n",
    "    def fetch_news_data(self):\n",
    "        \"\"\"Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† API\"\"\"\n",
    "        url = \"https://nfs.faireconomy.media/ff_calendar_thisweek.json\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ DataFrame\n",
    "            self.df = pd.DataFrame(data)\n",
    "            \n",
    "            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "            if not self.df.empty and 'date' in self.df.columns:\n",
    "                self.df['date'] = pd.to_datetime(self.df['date'])\n",
    "                self.df = self.df.sort_values('date').reset_index(drop=True)\n",
    "                self.last_update = datetime.now()\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching news: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_news_before_after(self, reference_title, minutes_before=30, minutes_after=30):\n",
    "        \"\"\"\n",
    "        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø®Ø¨Ø± Ù…Ø¹ÙŠÙ† Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚\n",
    "        \n",
    "        Args:\n",
    "            reference_title: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ Ø£Ùˆ Ø¬Ø²Ø¡ Ù…Ù†Ù‡\n",
    "            minutes_before: Ø¹Ø¯Ø¯ Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚ Ù‚Ø¨Ù„ Ø§Ù„Ø®Ø¨Ø±\n",
    "            minutes_after: Ø¹Ø¯Ø¯ Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚ Ø¨Ø¹Ø¯ Ø§Ù„Ø®Ø¨Ø±\n",
    "            \n",
    "        Returns:\n",
    "            dict: {'before': DataFrame, 'reference': DataFrame, 'after': DataFrame}\n",
    "        \"\"\"\n",
    "        if self.df.empty:\n",
    "            return self._empty_result()\n",
    "        \n",
    "        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ\n",
    "        reference_mask = self.df['title'].str.contains(reference_title, case=False, na=False)\n",
    "        reference_news = self.df[reference_mask]\n",
    "        \n",
    "        if reference_news.empty:\n",
    "            return self._empty_result()\n",
    "        \n",
    "        # Ø£Ø®Ø° Ø£ÙˆÙ„ Ø®Ø¨Ø± Ù…Ø·Ø§Ø¨Ù‚\n",
    "        reference_row = reference_news.iloc[0]\n",
    "        reference_time = reference_row['date']\n",
    "        \n",
    "        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ\n",
    "        time_before = reference_time - timedelta(minutes=minutes_before)\n",
    "        time_after = reference_time + timedelta(minutes=minutes_after)\n",
    "        \n",
    "        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\n",
    "        before_news = self.df[(self.df['date'] >= time_before) & (self.df['date'] < reference_time)]\n",
    "        after_news = self.df[(self.df['date'] > reference_time) & (self.df['date'] <= time_after)]\n",
    "        \n",
    "        return {\n",
    "            'before': before_news,\n",
    "            'reference': reference_news.iloc[[0]],\n",
    "            'after': after_news\n",
    "        }\n",
    "    \n",
    "    def get_high_impact_news_around_time(self, target_time, minutes_range=60):\n",
    "        \"\"\"\n",
    "        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ø­ÙˆÙ„ ÙˆÙ‚Øª Ù…Ø¹ÙŠÙ†\n",
    "        \n",
    "        Args:\n",
    "            target_time: Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù (datetime Ø£Ùˆ string)\n",
    "            minutes_range: Ø§Ù„Ù†Ø·Ø§Ù‚ Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚ Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø§Ù„ÙˆÙ‚Øª\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\n",
    "        \"\"\"\n",
    "        if self.df.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ø¥Ù„Ù‰ pandas Timestamp\n",
    "        target_time = pd.to_datetime(target_time)\n",
    "        \n",
    "        # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠØ©\n",
    "        if not self.df.empty:\n",
    "            if target_time.tz is None and self.df['date'].dt.tz is not None:\n",
    "                target_time = target_time.tz_localize(self.df['date'].dt.tz)\n",
    "            elif target_time.tz is not None and self.df['date'].dt.tz is None:\n",
    "                target_time = target_time.tz_localize(None)\n",
    "        \n",
    "        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ\n",
    "        time_start = target_time - timedelta(minutes=minutes_range)\n",
    "        time_end = target_time + timedelta(minutes=minutes_range)\n",
    "        \n",
    "        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ© ÙÙŠ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ\n",
    "        filtered_news = self.df[\n",
    "            (self.df['date'] >= time_start) & \n",
    "            (self.df['date'] <= time_end) & \n",
    "            (self.df['impact'] == 'High')\n",
    "        ]\n",
    "        \n",
    "        return filtered_news\n",
    "    \n",
    "    def get_currency_news(self, currency, impact_level=None, hours_ahead=24):\n",
    "        \"\"\"\n",
    "        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø®Ø¨Ø§Ø± Ø¹Ù…Ù„Ø© Ù…Ø¹ÙŠÙ†Ø©\n",
    "        \n",
    "        Args:\n",
    "            currency: Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© (Ù…Ø«Ù„ USD, EUR, GBP)\n",
    "            impact_level: Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ù‡Ù…ÙŠØ© (High, Medium, Low)\n",
    "            hours_ahead: Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ù…Ù† Ø§Ù„Ø¢Ù†\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¹Ù…Ù„Ø©\n",
    "        \"\"\"\n",
    "        if self.df.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…Ù„Ø©\n",
    "        currency_news = self.df[self.df['country'] == currency]\n",
    "        \n",
    "        # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ø¥Ø°Ø§ ØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡\n",
    "        if impact_level:\n",
    "            currency_news = currency_news[currency_news['impact'] == impact_level]\n",
    "        \n",
    "        # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„ÙˆÙ‚Øª (Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© ÙÙ‚Ø·)\n",
    "        if not currency_news.empty and 'date' in currency_news.columns:\n",
    "            if currency_news['date'].dt.tz is not None:\n",
    "                current_time = pd.Timestamp.now(tz=currency_news['date'].dt.tz)\n",
    "            else:\n",
    "                current_time = pd.Timestamp.now()\n",
    "            \n",
    "            future_time = current_time + timedelta(hours=hours_ahead)\n",
    "            \n",
    "            currency_news = currency_news[\n",
    "                (currency_news['date'] >= current_time) & \n",
    "                (currency_news['date'] <= future_time)\n",
    "            ]\n",
    "        \n",
    "        return currency_news\n",
    "    \n",
    "    def is_news_time_risky(self, check_time, risk_minutes_before=15, risk_minutes_after=15):\n",
    "        \"\"\"\n",
    "        ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙˆÙ‚Øª Ù…Ø­ÙÙˆÙ Ø¨Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\n",
    "        \n",
    "        Args:\n",
    "            check_time: Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø±Ø§Ø¯ ÙØ­ØµÙ‡\n",
    "            risk_minutes_before: Ø¹Ø¯Ø¯ Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚ Ù‚Ø¨Ù„ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø¹ØªØ¨Ø±Ø© Ù…Ø­ÙÙˆÙØ© Ø¨Ø§Ù„Ù…Ø®Ø§Ø·Ø±\n",
    "            risk_minutes_after: Ø¹Ø¯Ø¯ Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚ Ø¨Ø¹Ø¯ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø¹ØªØ¨Ø±Ø© Ù…Ø­ÙÙˆÙØ© Ø¨Ø§Ù„Ù…Ø®Ø§Ø·Ø±\n",
    "            \n",
    "        Returns:\n",
    "            dict: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±\n",
    "        \"\"\"\n",
    "        if self.df.empty:\n",
    "            return {'is_risky': False, 'reason': 'No news data'}\n",
    "        \n",
    "        # ØªØ­ÙˆÙŠÙ„ check_time Ø¥Ù„Ù‰ pandas Timestamp\n",
    "        if isinstance(check_time, str):\n",
    "            check_time = pd.to_datetime(check_time)\n",
    "        else:\n",
    "            check_time = pd.to_datetime(check_time)\n",
    "        \n",
    "        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠØ©\n",
    "        if not self.df.empty:\n",
    "            # Ø¥Ø°Ø§ ÙƒØ§Ù† check_time Ø¨Ø¯ÙˆÙ† timezone ÙˆØ§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ù‡Ø§ timezone\n",
    "            if check_time.tz is None and self.df['date'].dt.tz is not None:\n",
    "                check_time = check_time.tz_localize(self.df['date'].dt.tz)\n",
    "            # Ø¥Ø°Ø§ ÙƒØ§Ù† check_time Ø¨Ù€ timezone ÙˆØ§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø¯ÙˆÙ†Ù‡Ø§\n",
    "            elif check_time.tz is not None and self.df['date'].dt.tz is None:\n",
    "                check_time = check_time.tz_localize(None)\n",
    "        \n",
    "        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© ÙˆÙ…ØªÙˆØ³Ø·Ø© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\n",
    "        high_medium_news = self.df[self.df['impact'].isin(['High', 'Medium'])]\n",
    "        \n",
    "        for _, news_row in high_medium_news.iterrows():\n",
    "            news_time = news_row['date']\n",
    "            \n",
    "            try:\n",
    "                time_diff = abs((check_time - news_time).total_seconds() / 60)  # Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚\n",
    "            except TypeError:\n",
    "                # Ø¥Ø°Ø§ ÙØ´Ù„ØŒ Ø­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„ news_time\n",
    "                if news_time.tz is None and check_time.tz is not None:\n",
    "                    news_time = news_time.tz_localize(check_time.tz)\n",
    "                elif news_time.tz is not None and check_time.tz is None:\n",
    "                    news_time = news_time.tz_localize(None)\n",
    "                time_diff = abs((check_time - news_time).total_seconds() / 60)\n",
    "            \n",
    "            risk_window = risk_minutes_before if check_time >= news_time else risk_minutes_after\n",
    "            \n",
    "            if time_diff <= risk_window:\n",
    "                return {\n",
    "                    'is_risky': True,\n",
    "                    'reason': f\"News: {news_row['title']}\",\n",
    "                    'news_time': news_time,\n",
    "                    'impact': news_row['impact'],\n",
    "                    'minutes_to_news': int(time_diff)\n",
    "                }\n",
    "        \n",
    "        return {'is_risky': False, 'reason': 'No risky news found'}\n",
    "    \n",
    "    def get_next_high_impact_news(self, currency=None, hours_limit=48):\n",
    "        \"\"\"\n",
    "        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù‚Ø±Ø¨ Ø®Ø¨Ø± Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\n",
    "        \n",
    "        Args:\n",
    "            currency: Ø§Ù„Ø¹Ù…Ù„Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
    "            hours_limit: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø³Ø§Ø¹Ø§Øª\n",
    "            \n",
    "        Returns:\n",
    "            dict: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø®Ø¨Ø± Ø§Ù„ØªØ§Ù„ÙŠ\n",
    "        \"\"\"\n",
    "        if self.df.empty:\n",
    "            return None\n",
    "        \n",
    "        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ Ù…Ø¹ Ù†ÙØ³ timezone Ù„Ù„Ø£Ø®Ø¨Ø§Ø±\n",
    "        if self.df['date'].dt.tz is not None:\n",
    "            current_time = pd.Timestamp.now(tz=self.df['date'].dt.tz)\n",
    "        else:\n",
    "            current_time = pd.Timestamp.now()\n",
    "            \n",
    "        future_limit = current_time + timedelta(hours=hours_limit)\n",
    "        \n",
    "        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©\n",
    "        future_high_news = self.df[\n",
    "            (self.df['date'] > current_time) & \n",
    "            (self.df['date'] <= future_limit) & \n",
    "            (self.df['impact'] == 'High')\n",
    "        ]\n",
    "        \n",
    "        # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…Ù„Ø© Ø¥Ø°Ø§ ØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡Ø§\n",
    "        if currency:\n",
    "            future_high_news = future_high_news[future_high_news['country'] == currency]\n",
    "        \n",
    "        if future_high_news.empty:\n",
    "            return None\n",
    "        \n",
    "        # Ø£Ù‚Ø±Ø¨ Ø®Ø¨Ø±\n",
    "        next_news = future_high_news.iloc[0]\n",
    "        \n",
    "        try:\n",
    "            minutes_until_news = (next_news['date'] - current_time).total_seconds() / 60\n",
    "        except TypeError:\n",
    "            # Ø¥Ø°Ø§ ÙØ´Ù„ Ø¨Ø³Ø¨Ø¨ timezoneØŒ Ø­Ø§ÙˆÙ„ Ø§Ù„ØªÙˆØ­ÙŠØ¯\n",
    "            news_time = next_news['date']\n",
    "            if news_time.tz is None and current_time.tz is not None:\n",
    "                news_time = news_time.tz_localize(current_time.tz)\n",
    "            elif news_time.tz is not None and current_time.tz is None:\n",
    "                current_time = current_time.tz_localize(news_time.tz)\n",
    "            minutes_until_news = (news_time - current_time).total_seconds() / 60\n",
    "        \n",
    "        return {\n",
    "            'title': next_news['title'],\n",
    "            'date': next_news['date'],\n",
    "            'currency': next_news['country'],\n",
    "            'impact': next_news['impact'],\n",
    "            'minutes_until': int(minutes_until_news),\n",
    "            'forecast': next_news.get('forecast', 'N/A'),\n",
    "            'previous': next_news.get('previous', 'N/A')\n",
    "        }\n",
    "    \n",
    "    def _empty_result(self):\n",
    "        \"\"\"Ø¥Ø±Ø¬Ø§Ø¹ Ù†ØªÙŠØ¬Ø© ÙØ§Ø±ØºØ©\"\"\"\n",
    "        return {\n",
    "            'before': pd.DataFrame(),\n",
    "            'reference': pd.DataFrame(),\n",
    "            'after': pd.DataFrame()\n",
    "        }\n",
    "    \n",
    "    def get_data_summary(self):\n",
    "        \"\"\"Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\"\"\"\n",
    "        if self.df.empty:\n",
    "            return \"No data loaded\"\n",
    "        \n",
    "        total_news = len(self.df)\n",
    "        high_impact = len(self.df[self.df['impact'] == 'High'])\n",
    "        currencies = self.df['country'].unique().tolist()\n",
    "        \n",
    "        return {\n",
    "            'total_news': total_news,\n",
    "            'high_impact_news': high_impact,\n",
    "            'currencies': currencies,\n",
    "            'last_update': self.last_update\n",
    "        }\n",
    "\n",
    "# Ø¯ÙˆØ§Ù„ Ø³Ù‡Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„Ù„Ù€ DLL\n",
    "def create_news_filter():\n",
    "    \"\"\"Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø±Ø´Ø­ Ø£Ø®Ø¨Ø§Ø± Ø¬Ø¯ÙŠØ¯\"\"\"\n",
    "    return NewsFilter()\n",
    "\n",
    "def load_news_data(news_filter):\n",
    "    \"\"\"ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\"\"\"\n",
    "    return news_filter.fetch_news_data()\n",
    "\n",
    "def check_trading_safety(news_filter, trading_time, safety_minutes=15):\n",
    "    \"\"\"ÙØ­Øµ Ø£Ù…Ø§Ù† Ø§Ù„ÙˆÙ‚Øª Ù„Ù„ØªØ¯Ø§ÙˆÙ„\"\"\"\n",
    "    return news_filter.is_news_time_risky(trading_time, safety_minutes, safety_minutes)\n",
    "\n",
    "def get_next_major_news(news_filter, currency=\"USD\"):\n",
    "    \"\"\"Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù‚Ø±Ø¨ Ø®Ø¨Ø± Ù…Ù‡Ù…\"\"\"\n",
    "    return news_filter.get_next_high_impact_news(currency)\n",
    "\n",
    "def get_currency_schedule(news_filter, currency=\"USD\", hours=24):\n",
    "    \"\"\"Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¹Ù…Ù„Ø©\"\"\"\n",
    "    return news_filter.get_currency_news(currency, \"High\", hours)\n",
    "\n",
    "# Ù…Ø«Ø§Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…\n",
    "if __name__ == \"__main__\":\n",
    "    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø±Ø´Ø­ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\n",
    "    news_filter = create_news_filter()\n",
    "    \n",
    "    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "    if load_news_data(news_filter):\n",
    "        print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­\")\n",
    "\n",
    "\n",
    "        \n",
    "        # Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "        summary = news_filter.get_data_summary()\n",
    "        print(f\"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {summary['total_news']}\")\n",
    "        print(f\"Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: {summary['high_impact_news']}\")\n",
    "        \n",
    "        # ÙØ­Øµ Ø£Ù…Ø§Ù† Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„ØªØ¯Ø§ÙˆÙ„\n",
    "        current_time = datetime.now()\n",
    "        safety_check = check_trading_safety(news_filter, current_time, 15)\n",
    "        \n",
    "        if safety_check['is_risky']:\n",
    "            print(f\"âš ï¸ ØªØ­Ø°ÙŠØ±: Ø§Ù„ÙˆÙ‚Øª Ù…Ø­ÙÙˆÙ Ø¨Ø§Ù„Ù…Ø®Ø§Ø·Ø± - {safety_check['reason']}\")\n",
    "        else:\n",
    "            print(\"âœ… Ø§Ù„ÙˆÙ‚Øª Ø¢Ù…Ù† Ù„Ù„ØªØ¯Ø§ÙˆÙ„\")\n",
    "        \n",
    "        # Ø£Ù‚Ø±Ø¨ Ø®Ø¨Ø± Ù…Ù‡Ù… Ù„Ù„Ø¯ÙˆÙ„Ø§Ø±\n",
    "        next_news = get_next_major_news(news_filter, \"USD\")\n",
    "        if next_news:\n",
    "            print(f\"ğŸ”” Ø£Ù‚Ø±Ø¨ Ø®Ø¨Ø± Ù…Ù‡Ù…: {next_news['title']} Ø®Ù„Ø§Ù„ {next_news['minutes_until']} Ø¯Ù‚ÙŠÙ‚Ø©\")\n",
    "    \n",
    "    else:\n",
    "        print(\"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed7f5d-a776-45bf-8019-c1c566bcb6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
